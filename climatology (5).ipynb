{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa7d89ce-0bb0-4852-a19b-2ca17a86fc74",
   "metadata": {},
   "source": [
    "# Lara Richards Honours Project\n",
    "# Code takes a 31-year climatology of dryline variables and monsoon relationship"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf380f50-0a29-410d-8518-a8159c7a3717",
   "metadata": {},
   "source": [
    "# Common variarbles and slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d2dc680-3d58-4544-ba28-c9e85ad13a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import cartopy.crs as ccrs\n",
    "import scipy.ndimage as scind\n",
    "#lat and lon coordinates for mapping\n",
    "load = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/q/2000/q_era5_oper_pl_2000*')['q'].loc[:,925,-10:-30,110:155]\n",
    "qlat = load.latitude # lat = 81\n",
    "qlon = load.longitude # lon = 181\n",
    "lat_r = np.radians(qlat) #lat in radians\n",
    "lon_r = np.radians(qlon) #longitude in radians\n",
    "r = 6371000 #radius of earth in m\n",
    "\n",
    "#strings\n",
    "UTC = [\"0000\",\"0100\",\"0200\",\"0300\",\"0400\",\"0500\",\"0600\",\"0700\",\"0800\",\"0900\",\"1000\",\"1100\",\"1200\",\"1300\",\"1400\",\"1500\",\\\n",
    "     \"1600\",\"1700\",\"1800\",\"1900\",\"2000\",\"2100\",\"2200\",\"2300\"]\n",
    "month = [\"JAN\",\"FEB\",\"MAR\",\"APR\",\"MAY\",\"JUN\",\"JUL\",\"AUG\",\"SEP\",\"OCT\",\"NOV\",\"DEC\"]\n",
    "monthlong = [\"January\",\"February\",\"March\",\"April\",\"May\",\"June\",\"July\",\"August\",\"September\",\"October\",\"November\",\"December\"]\n",
    "\n",
    "#months with 31 days normal year, index 1 is leap year\n",
    "janstart = [0,0]\n",
    "janstop = [31,31]\n",
    "marstart = [59,60]\n",
    "marstop = [90,91]\n",
    "maystart = [120,121]\n",
    "maystop = [151,152]\n",
    "julstart = [181,182]\n",
    "julstop = [212,213]\n",
    "augstart = [212,213]\n",
    "augstop = [243,244]\n",
    "octstart = [273,274]\n",
    "octstop = [304,305]\n",
    "decstart = [334,335]\n",
    "decstop = [365,366]\n",
    "#months with 30 days normal year, index 1 is leapyear\n",
    "aprstart = [90,91]\n",
    "aprstop = [120,121]\n",
    "junstart = [151,152]\n",
    "junstop = [181,182]\n",
    "sepstart = [243,244]\n",
    "sepstop = [273,274]\n",
    "novstart = [304,305]\n",
    "novstop = [334,335]\n",
    "# feb, index 1 is leap year\n",
    "febstart = [31,31]\n",
    "febstop = [59,60]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f8017d-e0ee-4767-9f42-83379e81d187",
   "metadata": {},
   "source": [
    "# Load in data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b9d85bb-22b0-4b08-ad2b-cf209ef76a43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#specific humidity gradient data load\n",
    "q90 = xr.open_mfdataset('/g/data/rt52/era5/pressure-levels/reanalysis/q/1990/q_era5_oper_pl_1990*')['q'].loc[:,925,-10:-30,110:155]\n",
    "q91 = xr.open_mfdataset('/g/data/rt52/era5/pressure-levels/reanalysis/q/1991/q_era5_oper_pl_1991*')['q'].loc[:,925,-10:-30,110:155]\n",
    "q92 = xr.open_mfdataset('/g/data/rt52/era5/pressure-levels/reanalysis/q/1992/q_era5_oper_pl_1992*')['q'].loc[:,925,-10:-30,110:155]\n",
    "q93 = xr.open_mfdataset('/g/data/rt52/era5/pressure-levels/reanalysis/q/1993/q_era5_oper_pl_1993*')['q'].loc[:,925,-10:-30,110:155]\n",
    "q94 = xr.open_mfdataset('/g/data/rt52/era5/pressure-levels/reanalysis/q/1994/q_era5_oper_pl_1994*')['q'].loc[:,925,-10:-30,110:155]\n",
    "q95 = xr.open_mfdataset('/g/data/rt52/era5/pressure-levels/reanalysis/q/1995/q_era5_oper_pl_1995*')['q'].loc[:,925,-10:-30,110:155]\n",
    "q96 = xr.open_mfdataset('/g/data/rt52/era5/pressure-levels/reanalysis/q/1996/q_era5_oper_pl_1996*')['q'].loc[:,925,-10:-30,110:155]\n",
    "q97 = xr.open_mfdataset('/g/data/rt52/era5/pressure-levels/reanalysis/q/1997/q_era5_oper_pl_1997*')['q'].loc[:,925,-10:-30,110:155]\n",
    "q98 = xr.open_mfdataset('/g/data/rt52/era5/pressure-levels/reanalysis/q/1998/q_era5_oper_pl_1998*')['q'].loc[:,925,-10:-30,110:155]\n",
    "q99 = xr.open_mfdataset('/g/data/rt52/era5/pressure-levels/reanalysis/q/1999/q_era5_oper_pl_1999*')['q'].loc[:,925,-10:-30,110:155]\n",
    "q00 = xr.open_mfdataset('/g/data/rt52/era5/pressure-levels/reanalysis/q/2000/q_era5_oper_pl_2000*')['q'].loc[:,925,-10:-30,110:155]\n",
    "q01 = xr.open_mfdataset('/g/data/rt52/era5/pressure-levels/reanalysis/q/2001/q_era5_oper_pl_2001*')['q'].loc[:,925,-10:-30,110:155]\n",
    "q02 = xr.open_mfdataset('/g/data/rt52/era5/pressure-levels/reanalysis/q/2002/q_era5_oper_pl_2002*')['q'].loc[:,925,-10:-30,110:155]\n",
    "q03 = xr.open_mfdataset('/g/data/rt52/era5/pressure-levels/reanalysis/q/2003/q_era5_oper_pl_2003*')['q'].loc[:,925,-10:-30,110:155]\n",
    "q04 = xr.open_mfdataset('/g/data/rt52/era5/pressure-levels/reanalysis/q/2004/q_era5_oper_pl_2004*')['q'].loc[:,925,-10:-30,110:155]\n",
    "q05 = xr.open_mfdataset('/g/data/rt52/era5/pressure-levels/reanalysis/q/2005/q_era5_oper_pl_2005*')['q'].loc[:,925,-10:-30,110:155]\n",
    "q06 = xr.open_mfdataset('/g/data/rt52/era5/pressure-levels/reanalysis/q/2006/q_era5_oper_pl_2006*')['q'].loc[:,925,-10:-30,110:155]\n",
    "q07 = xr.open_mfdataset('/g/data/rt52/era5/pressure-levels/reanalysis/q/2007/q_era5_oper_pl_2007*')['q'].loc[:,925,-10:-30,110:155]\n",
    "q08 = xr.open_mfdataset('/g/data/rt52/era5/pressure-levels/reanalysis/q/2008/q_era5_oper_pl_2008*')['q'].loc[:,925,-10:-30,110:155]\n",
    "q09 = xr.open_mfdataset('/g/data/rt52/era5/pressure-levels/reanalysis/q/2009/q_era5_oper_pl_2009*')['q'].loc[:,925,-10:-30,110:155]\n",
    "q10 = xr.open_mfdataset('/g/data/rt52/era5/pressure-levels/reanalysis/q/2010/q_era5_oper_pl_2010*')['q'].loc[:,925,-10:-30,110:155]\n",
    "q11 = xr.open_mfdataset('/g/data/rt52/era5/pressure-levels/reanalysis/q/2011/q_era5_oper_pl_2011*')['q'].loc[:,925,-10:-30,110:155]\n",
    "q12 = xr.open_mfdataset('/g/data/rt52/era5/pressure-levels/reanalysis/q/2012/q_era5_oper_pl_2012*')['q'].loc[:,925,-10:-30,110:155]\n",
    "q13 = xr.open_mfdataset('/g/data/rt52/era5/pressure-levels/reanalysis/q/2013/q_era5_oper_pl_2013*')['q'].loc[:,925,-10:-30,110:155]\n",
    "q14 = xr.open_mfdataset('/g/data/rt52/era5/pressure-levels/reanalysis/q/2014/q_era5_oper_pl_2014*')['q'].loc[:,925,-10:-30,110:155]\n",
    "q15 = xr.open_mfdataset('/g/data/rt52/era5/pressure-levels/reanalysis/q/2015/q_era5_oper_pl_2015*')['q'].loc[:,925,-10:-30,110:155]\n",
    "q16 = xr.open_mfdataset('/g/data/rt52/era5/pressure-levels/reanalysis/q/2016/q_era5_oper_pl_2016*')['q'].loc[:,925,-10:-30,110:155]\n",
    "q17 = xr.open_mfdataset('/g/data/rt52/era5/pressure-levels/reanalysis/q/2017/q_era5_oper_pl_2017*')['q'].loc[:,925,-10:-30,110:155]\n",
    "q18 = xr.open_mfdataset('/g/data/rt52/era5/pressure-levels/reanalysis/q/2018/q_era5_oper_pl_2018*')['q'].loc[:,925,-10:-30,110:155]\n",
    "q19 = xr.open_mfdataset('/g/data/rt52/era5/pressure-levels/reanalysis/q/2019/q_era5_oper_pl_2019*')['q'].loc[:,925,-10:-30,110:155]\n",
    "q20 = xr.open_mfdataset('/g/data/rt52/era5/pressure-levels/reanalysis/q/2020/q_era5_oper_pl_2020*')['q'].loc[:,925,-10:-30,110:155]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9aede5f5-4860-462b-8250-a2df93e8e881",
   "metadata": {},
   "outputs": [],
   "source": [
    "#winds data dump\n",
    "#u-wind data load\n",
    "u90 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/u/1990/u_era5_oper_pl_1990*')['u'].loc[:,925,-10:-30,110:155]\n",
    "u91 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/u/1991/u_era5_oper_pl_1991*')['u'].loc[:,925,-10:-30,110:155]\n",
    "u92 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/u/1992/u_era5_oper_pl_1992*')['u'].loc[:,925,-10:-30,110:155]\n",
    "u93 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/u/1993/u_era5_oper_pl_1993*')['u'].loc[:,925,-10:-30,110:155]\n",
    "u94 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/u/1994/u_era5_oper_pl_1994*')['u'].loc[:,925,-10:-30,110:155]\n",
    "u95 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/u/1995/u_era5_oper_pl_1995*')['u'].loc[:,925,-10:-30,110:155]\n",
    "u96 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/u/1996/u_era5_oper_pl_1996*')['u'].loc[:,925,-10:-30,110:155]\n",
    "u97 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/u/1997/u_era5_oper_pl_1997*')['u'].loc[:,925,-10:-30,110:155]\n",
    "u98 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/u/1998/u_era5_oper_pl_1998*')['u'].loc[:,925,-10:-30,110:155]\n",
    "u99 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/u/1999/u_era5_oper_pl_1999*')['u'].loc[:,925,-10:-30,110:155]\n",
    "u00 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/u/2000/u_era5_oper_pl_2000*')['u'].loc[:,925,-10:-30,110:155]\n",
    "u01 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/u/2001/u_era5_oper_pl_2001*')['u'].loc[:,925,-10:-30,110:155]\n",
    "u02 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/u/2002/u_era5_oper_pl_2002*')['u'].loc[:,925,-10:-30,110:155]\n",
    "u03 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/u/2003/u_era5_oper_pl_2003*')['u'].loc[:,925,-10:-30,110:155]\n",
    "u04 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/u/2004/u_era5_oper_pl_2004*')['u'].loc[:,925,-10:-30,110:155]\n",
    "u05 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/u/2005/u_era5_oper_pl_2005*')['u'].loc[:,925,-10:-30,110:155]\n",
    "u06 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/u/2006/u_era5_oper_pl_2006*')['u'].loc[:,925,-10:-30,110:155]\n",
    "u07 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/u/2007/u_era5_oper_pl_2007*')['u'].loc[:,925,-10:-30,110:155]\n",
    "u08 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/u/2008/u_era5_oper_pl_2008*')['u'].loc[:,925,-10:-30,110:155]\n",
    "u09 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/u/2009/u_era5_oper_pl_2009*')['u'].loc[:,925,-10:-30,110:155]\n",
    "u10 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/u/2010/u_era5_oper_pl_2010*')['u'].loc[:,925,-10:-30,110:155]\n",
    "u11 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/u/2011/u_era5_oper_pl_2011*')['u'].loc[:,925,-10:-30,110:155]\n",
    "u12 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/u/2012/u_era5_oper_pl_2012*')['u'].loc[:,925,-10:-30,110:155]\n",
    "u13 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/u/2013/u_era5_oper_pl_2013*')['u'].loc[:,925,-10:-30,110:155]\n",
    "u14 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/u/2014/u_era5_oper_pl_2014*')['u'].loc[:,925,-10:-30,110:155]\n",
    "u15 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/u/2015/u_era5_oper_pl_2015*')['u'].loc[:,925,-10:-30,110:155]\n",
    "u16 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/u/2016/u_era5_oper_pl_2016*')['u'].loc[:,925,-10:-30,110:155]\n",
    "u17 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/u/2017/u_era5_oper_pl_2017*')['u'].loc[:,925,-10:-30,110:155]\n",
    "u18 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/u/2018/u_era5_oper_pl_2018*')['u'].loc[:,925,-10:-30,110:155]\n",
    "u19 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/u/2019/u_era5_oper_pl_2019*')['u'].loc[:,925,-10:-30,110:155]\n",
    "u20 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/u/2020/u_era5_oper_pl_2020*')['u'].loc[:,925,-10:-30,110:155]\n",
    "#------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "#v-wind data load\n",
    "v90 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/v/1990/v_era5_oper_pl_1990*')['v'].loc[:,925,-10:-30,110:155]\n",
    "v91 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/v/1991/v_era5_oper_pl_1991*')['v'].loc[:,925,-10:-30,110:155]\n",
    "v92 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/v/1992/v_era5_oper_pl_1992*')['v'].loc[:,925,-10:-30,110:155]\n",
    "v93 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/v/1993/v_era5_oper_pl_1993*')['v'].loc[:,925,-10:-30,110:155]\n",
    "v94 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/v/1994/v_era5_oper_pl_1994*')['v'].loc[:,925,-10:-30,110:155]\n",
    "v95 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/v/1995/v_era5_oper_pl_1995*')['v'].loc[:,925,-10:-30,110:155]\n",
    "v96 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/v/1996/v_era5_oper_pl_1996*')['v'].loc[:,925,-10:-30,110:155]\n",
    "v97 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/v/1997/v_era5_oper_pl_1997*')['v'].loc[:,925,-10:-30,110:155]\n",
    "v98 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/v/1998/v_era5_oper_pl_1998*')['v'].loc[:,925,-10:-30,110:155]\n",
    "v99 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/v/1999/v_era5_oper_pl_1999*')['v'].loc[:,925,-10:-30,110:155]\n",
    "v00 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/v/2000/v_era5_oper_pl_2000*')['v'].loc[:,925,-10:-30,110:155]\n",
    "v01 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/v/2001/v_era5_oper_pl_2001*')['v'].loc[:,925,-10:-30,110:155]\n",
    "v02 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/v/2002/v_era5_oper_pl_2002*')['v'].loc[:,925,-10:-30,110:155]\n",
    "v03 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/v/2003/v_era5_oper_pl_2003*')['v'].loc[:,925,-10:-30,110:155]\n",
    "v04 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/v/2004/v_era5_oper_pl_2004*')['v'].loc[:,925,-10:-30,110:155]\n",
    "v05 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/v/2005/v_era5_oper_pl_2005*')['v'].loc[:,925,-10:-30,110:155]\n",
    "v06 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/v/2006/v_era5_oper_pl_2006*')['v'].loc[:,925,-10:-30,110:155]\n",
    "v07 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/v/2007/v_era5_oper_pl_2007*')['v'].loc[:,925,-10:-30,110:155]\n",
    "v08 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/v/2008/v_era5_oper_pl_2008*')['v'].loc[:,925,-10:-30,110:155]\n",
    "v09 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/v/2009/v_era5_oper_pl_2009*')['v'].loc[:,925,-10:-30,110:155]\n",
    "v10 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/v/2010/v_era5_oper_pl_2010*')['v'].loc[:,925,-10:-30,110:155]\n",
    "v11 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/v/2011/v_era5_oper_pl_2011*')['v'].loc[:,925,-10:-30,110:155]\n",
    "v12 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/v/2012/v_era5_oper_pl_2012*')['v'].loc[:,925,-10:-30,110:155]\n",
    "v13 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/v/2013/v_era5_oper_pl_2013*')['v'].loc[:,925,-10:-30,110:155]\n",
    "v14 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/v/2014/v_era5_oper_pl_2014*')['v'].loc[:,925,-10:-30,110:155]\n",
    "v15 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/v/2015/v_era5_oper_pl_2015*')['v'].loc[:,925,-10:-30,110:155]\n",
    "v16 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/v/2016/v_era5_oper_pl_2016*')['v'].loc[:,925,-10:-30,110:155]\n",
    "v17 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/v/2017/v_era5_oper_pl_2017*')['v'].loc[:,925,-10:-30,110:155]\n",
    "v18 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/v/2018/v_era5_oper_pl_2018*')['v'].loc[:,925,-10:-30,110:155]\n",
    "v19 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/v/2019/v_era5_oper_pl_2019*')['v'].loc[:,925,-10:-30,110:155]\n",
    "v20 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/v/2020/v_era5_oper_pl_2020*')['v'].loc[:,925,-10:-30,110:155]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a5cadc8-c26d-485c-99d9-a3a6c7b8c293",
   "metadata": {},
   "outputs": [],
   "source": [
    "#geopotential height data load\n",
    "z90 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/z/1990/z_era5_oper_pl_1990*')['z'].loc[:,925,-10:-30,110:155]\n",
    "z91 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/z/1991/z_era5_oper_pl_1991*')['z'].loc[:,925,-10:-30,110:155]\n",
    "z92 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/z/1992/z_era5_oper_pl_1992*')['z'].loc[:,925,-10:-30,110:155]\n",
    "z93 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/z/1993/z_era5_oper_pl_1993*')['z'].loc[:,925,-10:-30,110:155]\n",
    "z94 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/z/1994/z_era5_oper_pl_1994*')['z'].loc[:,925,-10:-30,110:155]\n",
    "z95 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/z/1995/z_era5_oper_pl_1995*')['z'].loc[:,925,-10:-30,110:155]\n",
    "z96 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/z/1996/z_era5_oper_pl_1996*')['z'].loc[:,925,-10:-30,110:155]\n",
    "z97 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/z/1997/z_era5_oper_pl_1997*')['z'].loc[:,925,-10:-30,110:155]\n",
    "z98 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/z/1998/z_era5_oper_pl_1998*')['z'].loc[:,925,-10:-30,110:155]\n",
    "z99 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/z/1999/z_era5_oper_pl_1999*')['z'].loc[:,925,-10:-30,110:155]\n",
    "z00 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/z/2000/z_era5_oper_pl_2000*')['z'].loc[:,925,-10:-30,110:155]\n",
    "z01 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/z/2001/z_era5_oper_pl_2001*')['z'].loc[:,925,-10:-30,110:155]\n",
    "z02 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/z/2002/z_era5_oper_pl_2002*')['z'].loc[:,925,-10:-30,110:155]\n",
    "z03 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/z/2003/z_era5_oper_pl_2003*')['z'].loc[:,925,-10:-30,110:155]\n",
    "z04 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/z/2004/z_era5_oper_pl_2004*')['z'].loc[:,925,-10:-30,110:155]\n",
    "z05 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/z/2005/z_era5_oper_pl_2005*')['z'].loc[:,925,-10:-30,110:155]\n",
    "z06 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/z/2006/z_era5_oper_pl_2006*')['z'].loc[:,925,-10:-30,110:155]\n",
    "z07 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/z/2007/z_era5_oper_pl_2007*')['z'].loc[:,925,-10:-30,110:155]\n",
    "z08 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/z/2008/z_era5_oper_pl_2008*')['z'].loc[:,925,-10:-30,110:155]\n",
    "z09 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/z/2009/z_era5_oper_pl_2009*')['z'].loc[:,925,-10:-30,110:155]\n",
    "z10 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/z/2010/z_era5_oper_pl_2010*')['z'].loc[:,925,-10:-30,110:155]\n",
    "z11 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/z/2011/z_era5_oper_pl_2011*')['z'].loc[:,925,-10:-30,110:155]\n",
    "z12 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/z/2012/z_era5_oper_pl_2012*')['z'].loc[:,925,-10:-30,110:155]\n",
    "z13 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/z/2013/z_era5_oper_pl_2013*')['z'].loc[:,925,-10:-30,110:155]\n",
    "z14 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/z/2014/z_era5_oper_pl_2014*')['z'].loc[:,925,-10:-30,110:155]\n",
    "z15 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/z/2015/z_era5_oper_pl_2015*')['z'].loc[:,925,-10:-30,110:155]\n",
    "z16 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/z/2016/z_era5_oper_pl_2016*')['z'].loc[:,925,-10:-30,110:155]\n",
    "z17 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/z/2017/z_era5_oper_pl_2017*')['z'].loc[:,925,-10:-30,110:155]\n",
    "z18 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/z/2018/z_era5_oper_pl_2018*')['z'].loc[:,925,-10:-30,110:155]\n",
    "z19 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/z/2019/z_era5_oper_pl_2019*')['z'].loc[:,925,-10:-30,110:155]\n",
    "z20 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/z/2020/z_era5_oper_pl_2020*')['z'].loc[:,925,-10:-30,110:155]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4cb565a-19be-4ce4-b46f-3054bdebfa91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#divergence/convergence data load\n",
    "d90 = xr.open_mfdataset('/g/data/rt52/era5/pressure-levels/reanalysis/d/1990/d_era5_oper_pl_1990*')['d'].loc[:,925,-10:-30,110:155]\n",
    "d91 = xr.open_mfdataset('/g/data/rt52/era5/pressure-levels/reanalysis/d/1991/d_era5_oper_pl_1991*')['d'].loc[:,925,-10:-30,110:155]\n",
    "d92 = xr.open_mfdataset('/g/data/rt52/era5/pressure-levels/reanalysis/d/1992/d_era5_oper_pl_1992*')['d'].loc[:,925,-10:-30,110:155]\n",
    "d93 = xr.open_mfdataset('/g/data/rt52/era5/pressure-levels/reanalysis/d/1993/d_era5_oper_pl_1993*')['d'].loc[:,925,-10:-30,110:155]\n",
    "d94 = xr.open_mfdataset('/g/data/rt52/era5/pressure-levels/reanalysis/d/1994/d_era5_oper_pl_1994*')['d'].loc[:,925,-10:-30,110:155]\n",
    "d95 = xr.open_mfdataset('/g/data/rt52/era5/pressure-levels/reanalysis/d/1995/d_era5_oper_pl_1995*')['d'].loc[:,925,-10:-30,110:155]\n",
    "d96 = xr.open_mfdataset('/g/data/rt52/era5/pressure-levels/reanalysis/d/1996/d_era5_oper_pl_1996*')['d'].loc[:,925,-10:-30,110:155]\n",
    "d97 = xr.open_mfdataset('/g/data/rt52/era5/pressure-levels/reanalysis/d/1997/d_era5_oper_pl_1997*')['d'].loc[:,925,-10:-30,110:155]\n",
    "d98 = xr.open_mfdataset('/g/data/rt52/era5/pressure-levels/reanalysis/d/1998/d_era5_oper_pl_1998*')['d'].loc[:,925,-10:-30,110:155]\n",
    "d99 = xr.open_mfdataset('/g/data/rt52/era5/pressure-levels/reanalysis/d/1999/d_era5_oper_pl_1999*')['d'].loc[:,925,-10:-30,110:155]\n",
    "d00 = xr.open_mfdataset('/g/data/rt52/era5/pressure-levels/reanalysis/d/2000/d_era5_oper_pl_2000*')['d'].loc[:,925,-10:-30,110:155]\n",
    "d01 = xr.open_mfdataset('/g/data/rt52/era5/pressure-levels/reanalysis/d/2001/d_era5_oper_pl_2001*')['d'].loc[:,925,-10:-30,110:155]\n",
    "d02 = xr.open_mfdataset('/g/data/rt52/era5/pressure-levels/reanalysis/d/2002/d_era5_oper_pl_2002*')['d'].loc[:,925,-10:-30,110:155]\n",
    "d03 = xr.open_mfdataset('/g/data/rt52/era5/pressure-levels/reanalysis/d/2003/d_era5_oper_pl_2003*')['d'].loc[:,925,-10:-30,110:155]\n",
    "d04 = xr.open_mfdataset('/g/data/rt52/era5/pressure-levels/reanalysis/d/2004/d_era5_oper_pl_2004*')['d'].loc[:,925,-10:-30,110:155]\n",
    "d05 = xr.open_mfdataset('/g/data/rt52/era5/pressure-levels/reanalysis/d/2005/d_era5_oper_pl_2005*')['d'].loc[:,925,-10:-30,110:155]\n",
    "d06 = xr.open_mfdataset('/g/data/rt52/era5/pressure-levels/reanalysis/d/2006/d_era5_oper_pl_2006*')['d'].loc[:,925,-10:-30,110:155]\n",
    "d07 = xr.open_mfdataset('/g/data/rt52/era5/pressure-levels/reanalysis/d/2007/d_era5_oper_pl_2007*')['d'].loc[:,925,-10:-30,110:155]\n",
    "d08 = xr.open_mfdataset('/g/data/rt52/era5/pressure-levels/reanalysis/d/2008/d_era5_oper_pl_2008*')['d'].loc[:,925,-10:-30,110:155]\n",
    "d09 = xr.open_mfdataset('/g/data/rt52/era5/pressure-levels/reanalysis/d/2009/d_era5_oper_pl_2009*')['d'].loc[:,925,-10:-30,110:155]\n",
    "d10 = xr.open_mfdataset('/g/data/rt52/era5/pressure-levels/reanalysis/d/2010/d_era5_oper_pl_2010*')['d'].loc[:,925,-10:-30,110:155]\n",
    "d11 = xr.open_mfdataset('/g/data/rt52/era5/pressure-levels/reanalysis/d/2011/d_era5_oper_pl_2011*')['d'].loc[:,925,-10:-30,110:155]\n",
    "d12 = xr.open_mfdataset('/g/data/rt52/era5/pressure-levels/reanalysis/d/2012/d_era5_oper_pl_2012*')['d'].loc[:,925,-10:-30,110:155]\n",
    "d13 = xr.open_mfdataset('/g/data/rt52/era5/pressure-levels/reanalysis/d/2013/d_era5_oper_pl_2013*')['d'].loc[:,925,-10:-30,110:155]\n",
    "d14 = xr.open_mfdataset('/g/data/rt52/era5/pressure-levels/reanalysis/d/2014/d_era5_oper_pl_2014*')['d'].loc[:,925,-10:-30,110:155]\n",
    "d15 = xr.open_mfdataset('/g/data/rt52/era5/pressure-levels/reanalysis/d/2015/d_era5_oper_pl_2015*')['d'].loc[:,925,-10:-30,110:155]\n",
    "d16 = xr.open_mfdataset('/g/data/rt52/era5/pressure-levels/reanalysis/d/2016/d_era5_oper_pl_2016*')['d'].loc[:,925,-10:-30,110:155]\n",
    "d17 = xr.open_mfdataset('/g/data/rt52/era5/pressure-levels/reanalysis/d/2017/d_era5_oper_pl_2017*')['d'].loc[:,925,-10:-30,110:155]\n",
    "d18 = xr.open_mfdataset('/g/data/rt52/era5/pressure-levels/reanalysis/d/2018/d_era5_oper_pl_2018*')['d'].loc[:,925,-10:-30,110:155]\n",
    "d19 = xr.open_mfdataset('/g/data/rt52/era5/pressure-levels/reanalysis/d/2019/d_era5_oper_pl_2019*')['d'].loc[:,925,-10:-30,110:155]\n",
    "d20 = xr.open_mfdataset('/g/data/rt52/era5/pressure-levels/reanalysis/d/2020/d_era5_oper_pl_2020*')['d'].loc[:,925,-10:-30,110:155]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de3b0752-2c05-4d5c-aa72-16fd31c99f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SST data load *****important note this is single level data taken at the sfc not at 925hPa******\n",
    "sst90 = xr.open_mfdataset('/g/data5/rt52/era5/single-levels/reanalysis/sst/1990/sst_era5_oper_sfc_1990*')['sst'].loc[:,-10:-30,110:155]\n",
    "sst91 = xr.open_mfdataset('/g/data5/rt52/era5/single-levels/reanalysis/sst/1991/sst_era5_oper_sfc_1991*')['sst'].loc[:,-10:-30,110:155]\n",
    "sst92 = xr.open_mfdataset('/g/data5/rt52/era5/single-levels/reanalysis/sst/1992/sst_era5_oper_sfc_1992*')['sst'].loc[:,-10:-30,110:155]\n",
    "sst93 = xr.open_mfdataset('/g/data5/rt52/era5/single-levels/reanalysis/sst/1993/sst_era5_oper_sfc_1993*')['sst'].loc[:,-10:-30,110:155]\n",
    "sst94 = xr.open_mfdataset('/g/data5/rt52/era5/single-levels/reanalysis/sst/1994/sst_era5_oper_sfc_1994*')['sst'].loc[:,-10:-30,110:155]\n",
    "sst95 = xr.open_mfdataset('/g/data5/rt52/era5/single-levels/reanalysis/sst/1995/sst_era5_oper_sfc_1995*')['sst'].loc[:,-10:-30,110:155]\n",
    "sst96 = xr.open_mfdataset('/g/data5/rt52/era5/single-levels/reanalysis/sst/1996/sst_era5_oper_sfc_1996*')['sst'].loc[:,-10:-30,110:155]\n",
    "sst97 = xr.open_mfdataset('/g/data5/rt52/era5/single-levels/reanalysis/sst/1997/sst_era5_oper_sfc_1997*')['sst'].loc[:,-10:-30,110:155]\n",
    "sst98 = xr.open_mfdataset('/g/data5/rt52/era5/single-levels/reanalysis/sst/1998/sst_era5_oper_sfc_1998*')['sst'].loc[:,-10:-30,110:155]\n",
    "sst99 = xr.open_mfdataset('/g/data5/rt52/era5/single-levels/reanalysis/sst/1999/sst_era5_oper_sfc_1999*')['sst'].loc[:,-10:-30,110:155]\n",
    "sst00 = xr.open_mfdataset('/g/data5/rt52/era5/single-levels/reanalysis/sst/2000/sst_era5_oper_sfc_2000*')['sst'].loc[:,-10:-30,110:155]\n",
    "sst01 = xr.open_mfdataset('/g/data5/rt52/era5/single-levels/reanalysis/sst/2001/sst_era5_oper_sfc_2001*')['sst'].loc[:,-10:-30,110:155]\n",
    "sst02 = xr.open_mfdataset('/g/data5/rt52/era5/single-levels/reanalysis/sst/2002/sst_era5_oper_sfc_2002*')['sst'].loc[:,-10:-30,110:155]\n",
    "sst03 = xr.open_mfdataset('/g/data5/rt52/era5/single-levels/reanalysis/sst/2003/sst_era5_oper_sfc_2003*')['sst'].loc[:,-10:-30,110:155]\n",
    "sst04 = xr.open_mfdataset('/g/data5/rt52/era5/single-levels/reanalysis/sst/2004/sst_era5_oper_sfc_2004*')['sst'].loc[:,-10:-30,110:155]\n",
    "sst05 = xr.open_mfdataset('/g/data5/rt52/era5/single-levels/reanalysis/sst/2005/sst_era5_oper_sfc_2005*')['sst'].loc[:,-10:-30,110:155]\n",
    "sst06 = xr.open_mfdataset('/g/data5/rt52/era5/single-levels/reanalysis/sst/2006/sst_era5_oper_sfc_2006*')['sst'].loc[:,-10:-30,110:155]\n",
    "sst07 = xr.open_mfdataset('/g/data5/rt52/era5/single-levels/reanalysis/sst/2007/sst_era5_oper_sfc_2007*')['sst'].loc[:,-10:-30,110:155]\n",
    "sst08 = xr.open_mfdataset('/g/data5/rt52/era5/single-levels/reanalysis/sst/2008/sst_era5_oper_sfc_2008*')['sst'].loc[:,-10:-30,110:155]\n",
    "sst09 = xr.open_mfdataset('/g/data5/rt52/era5/single-levels/reanalysis/sst/2009/sst_era5_oper_sfc_2009*')['sst'].loc[:,-10:-30,110:155]\n",
    "sst10 = xr.open_mfdataset('/g/data5/rt52/era5/single-levels/reanalysis/sst/2010/sst_era5_oper_sfc_2010*')['sst'].loc[:,-10:-30,110:155]\n",
    "sst11 = xr.open_mfdataset('/g/data5/rt52/era5/single-levels/reanalysis/sst/2011/sst_era5_oper_sfc_2011*')['sst'].loc[:,-10:-30,110:155]\n",
    "sst12 = xr.open_mfdataset('/g/data5/rt52/era5/single-levels/reanalysis/sst/2012/sst_era5_oper_sfc_2012*')['sst'].loc[:,-10:-30,110:155]\n",
    "sst13 = xr.open_mfdataset('/g/data5/rt52/era5/single-levels/reanalysis/sst/2013/sst_era5_oper_sfc_2013*')['sst'].loc[:,-10:-30,110:155]\n",
    "sst14 = xr.open_mfdataset('/g/data5/rt52/era5/single-levels/reanalysis/sst/2014/sst_era5_oper_sfc_2014*')['sst'].loc[:,-10:-30,110:155]\n",
    "sst15 = xr.open_mfdataset('/g/data5/rt52/era5/single-levels/reanalysis/sst/2015/sst_era5_oper_sfc_2015*')['sst'].loc[:,-10:-30,110:155]\n",
    "sst16 = xr.open_mfdataset('/g/data5/rt52/era5/single-levels/reanalysis/sst/2016/sst_era5_oper_sfc_2016*')['sst'].loc[:,-10:-30,110:155]\n",
    "sst17 = xr.open_mfdataset('/g/data5/rt52/era5/single-levels/reanalysis/sst/2017/sst_era5_oper_sfc_2017*')['sst'].loc[:,-10:-30,110:155]\n",
    "sst18 = xr.open_mfdataset('/g/data5/rt52/era5/single-levels/reanalysis/sst/2018/sst_era5_oper_sfc_2018*')['sst'].loc[:,-10:-30,110:155]\n",
    "sst19 = xr.open_mfdataset('/g/data5/rt52/era5/single-levels/reanalysis/sst/2019/sst_era5_oper_sfc_2019*')['sst'].loc[:,-10:-30,110:155]\n",
    "sst20 = xr.open_mfdataset('/g/data5/rt52/era5/single-levels/reanalysis/sst/2020/sst_era5_oper_sfc_2020*')['sst'].loc[:,-10:-30,110:155]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b22f001b-c881-454e-9b77-55c6a69368c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean total precipitaton rate mtpr for precip climo in units Kg m**-2 s**-1\n",
    "#this is also single level data taken at the sfc not a 925hpa\n",
    "mtpr90 = xr.open_mfdataset('/g/data5/rt52/era5/single-levels/reanalysis/mtpr/1990/mtpr_era5_oper_sfc_1990*')['mtpr'].loc[:,-10:-30,110:155]\n",
    "mtpr91 = xr.open_mfdataset('/g/data5/rt52/era5/single-levels/reanalysis/mtpr/1991/mtpr_era5_oper_sfc_1991*')['mtpr'].loc[:,-10:-30,110:155]\n",
    "mtpr92 = xr.open_mfdataset('/g/data5/rt52/era5/single-levels/reanalysis/mtpr/1992/mtpr_era5_oper_sfc_1992*')['mtpr'].loc[:,-10:-30,110:155]\n",
    "mtpr93 = xr.open_mfdataset('/g/data5/rt52/era5/single-levels/reanalysis/mtpr/1993/mtpr_era5_oper_sfc_1993*')['mtpr'].loc[:,-10:-30,110:155]\n",
    "mtpr94 = xr.open_mfdataset('/g/data5/rt52/era5/single-levels/reanalysis/mtpr/1994/mtpr_era5_oper_sfc_1994*')['mtpr'].loc[:,-10:-30,110:155]\n",
    "mtpr95 = xr.open_mfdataset('/g/data5/rt52/era5/single-levels/reanalysis/mtpr/1995/mtpr_era5_oper_sfc_1995*')['mtpr'].loc[:,-10:-30,110:155]\n",
    "mtpr96 = xr.open_mfdataset('/g/data5/rt52/era5/single-levels/reanalysis/mtpr/1996/mtpr_era5_oper_sfc_1996*')['mtpr'].loc[:,-10:-30,110:155]\n",
    "mtpr97 = xr.open_mfdataset('/g/data5/rt52/era5/single-levels/reanalysis/mtpr/1997/mtpr_era5_oper_sfc_1997*')['mtpr'].loc[:,-10:-30,110:155]\n",
    "mtpr98 = xr.open_mfdataset('/g/data5/rt52/era5/single-levels/reanalysis/mtpr/1998/mtpr_era5_oper_sfc_1998*')['mtpr'].loc[:,-10:-30,110:155]\n",
    "mtpr99 = xr.open_mfdataset('/g/data5/rt52/era5/single-levels/reanalysis/mtpr/1999/mtpr_era5_oper_sfc_1999*')['mtpr'].loc[:,-10:-30,110:155]\n",
    "mtpr00 = xr.open_mfdataset('/g/data5/rt52/era5/single-levels/reanalysis/mtpr/2000/mtpr_era5_oper_sfc_2000*')['mtpr'].loc[:,-10:-30,110:155]\n",
    "mtpr01 = xr.open_mfdataset('/g/data5/rt52/era5/single-levels/reanalysis/mtpr/2001/mtpr_era5_oper_sfc_2001*')['mtpr'].loc[:,-10:-30,110:155]\n",
    "mtpr02 = xr.open_mfdataset('/g/data5/rt52/era5/single-levels/reanalysis/mtpr/2002/mtpr_era5_oper_sfc_2002*')['mtpr'].loc[:,-10:-30,110:155]\n",
    "mtpr03 = xr.open_mfdataset('/g/data5/rt52/era5/single-levels/reanalysis/mtpr/2003/mtpr_era5_oper_sfc_2003*')['mtpr'].loc[:,-10:-30,110:155]\n",
    "mtpr04 = xr.open_mfdataset('/g/data5/rt52/era5/single-levels/reanalysis/mtpr/2004/mtpr_era5_oper_sfc_2004*')['mtpr'].loc[:,-10:-30,110:155]\n",
    "mtpr05 = xr.open_mfdataset('/g/data5/rt52/era5/single-levels/reanalysis/mtpr/2005/mtpr_era5_oper_sfc_2005*')['mtpr'].loc[:,-10:-30,110:155]\n",
    "mtpr06 = xr.open_mfdataset('/g/data5/rt52/era5/single-levels/reanalysis/mtpr/2006/mtpr_era5_oper_sfc_2006*')['mtpr'].loc[:,-10:-30,110:155]\n",
    "mtpr07 = xr.open_mfdataset('/g/data5/rt52/era5/single-levels/reanalysis/mtpr/2007/mtpr_era5_oper_sfc_2007*')['mtpr'].loc[:,-10:-30,110:155]\n",
    "mtpr08 = xr.open_mfdataset('/g/data5/rt52/era5/single-levels/reanalysis/mtpr/2008/mtpr_era5_oper_sfc_2008*')['mtpr'].loc[:,-10:-30,110:155]\n",
    "mtpr09 = xr.open_mfdataset('/g/data5/rt52/era5/single-levels/reanalysis/mtpr/2009/mtpr_era5_oper_sfc_2009*')['mtpr'].loc[:,-10:-30,110:155]\n",
    "mtpr10 = xr.open_mfdataset('/g/data5/rt52/era5/single-levels/reanalysis/mtpr/2010/mtpr_era5_oper_sfc_2010*')['mtpr'].loc[:,-10:-30,110:155]\n",
    "mtpr11 = xr.open_mfdataset('/g/data5/rt52/era5/single-levels/reanalysis/mtpr/2011/mtpr_era5_oper_sfc_2011*')['mtpr'].loc[:,-10:-30,110:155]\n",
    "mtpr12 = xr.open_mfdataset('/g/data5/rt52/era5/single-levels/reanalysis/mtpr/2012/mtpr_era5_oper_sfc_2012*')['mtpr'].loc[:,-10:-30,110:155]\n",
    "mtpr13 = xr.open_mfdataset('/g/data5/rt52/era5/single-levels/reanalysis/mtpr/2013/mtpr_era5_oper_sfc_2013*')['mtpr'].loc[:,-10:-30,110:155]\n",
    "mtpr14 = xr.open_mfdataset('/g/data5/rt52/era5/single-levels/reanalysis/mtpr/2014/mtpr_era5_oper_sfc_2014*')['mtpr'].loc[:,-10:-30,110:155]\n",
    "mtpr15 = xr.open_mfdataset('/g/data5/rt52/era5/single-levels/reanalysis/mtpr/2015/mtpr_era5_oper_sfc_2015*')['mtpr'].loc[:,-10:-30,110:155]\n",
    "mtpr16 = xr.open_mfdataset('/g/data5/rt52/era5/single-levels/reanalysis/mtpr/2016/mtpr_era5_oper_sfc_2016*')['mtpr'].loc[:,-10:-30,110:155]\n",
    "mtpr17 = xr.open_mfdataset('/g/data5/rt52/era5/single-levels/reanalysis/mtpr/2017/mtpr_era5_oper_sfc_2017*')['mtpr'].loc[:,-10:-30,110:155]\n",
    "mtpr18 = xr.open_mfdataset('/g/data5/rt52/era5/single-levels/reanalysis/mtpr/2018/mtpr_era5_oper_sfc_2018*')['mtpr'].loc[:,-10:-30,110:155]\n",
    "mtpr19 = xr.open_mfdataset('/g/data5/rt52/era5/single-levels/reanalysis/mtpr/2019/mtpr_era5_oper_sfc_2019*')['mtpr'].loc[:,-10:-30,110:155]\n",
    "mtpr20 = xr.open_mfdataset('/g/data5/rt52/era5/single-levels/reanalysis/mtpr/2020/mtpr_era5_oper_sfc_2020*')['mtpr'].loc[:,-10:-30,110:155]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2031ae3-aedd-4a5d-bb09-c95597abb60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is altered for the monsoon box in northern Aus\n",
    "# mean total precipitaton rate mtpr for precip climo in units Kg m**-2 s**-1\n",
    "#this is also single level data taken at the sfc not a 925hpa\n",
    "mtpr90 = xr.open_mfdataset('/g/data5/rt52/era5/single-levels/reanalysis/mtpr/1990/mtpr_era5_oper_sfc_1990*')['mtpr'].loc[:,-10:-20,120:150]\n",
    "mtpr91 = xr.open_mfdataset('/g/data5/rt52/era5/single-levels/reanalysis/mtpr/1991/mtpr_era5_oper_sfc_1991*')['mtpr'].loc[:,-10:-20,120:150]\n",
    "mtpr92 = xr.open_mfdataset('/g/data5/rt52/era5/single-levels/reanalysis/mtpr/1992/mtpr_era5_oper_sfc_1992*')['mtpr'].loc[:,-10:-20,120:150]\n",
    "mtpr93 = xr.open_mfdataset('/g/data5/rt52/era5/single-levels/reanalysis/mtpr/1993/mtpr_era5_oper_sfc_1993*')['mtpr'].loc[:,-10:-20,120:150]\n",
    "mtpr94 = xr.open_mfdataset('/g/data5/rt52/era5/single-levels/reanalysis/mtpr/1994/mtpr_era5_oper_sfc_1994*')['mtpr'].loc[:,-10:-20,120:150]\n",
    "mtpr95 = xr.open_mfdataset('/g/data5/rt52/era5/single-levels/reanalysis/mtpr/1995/mtpr_era5_oper_sfc_1995*')['mtpr'].loc[:,-10:-20,120:150]\n",
    "mtpr96 = xr.open_mfdataset('/g/data5/rt52/era5/single-levels/reanalysis/mtpr/1996/mtpr_era5_oper_sfc_1996*')['mtpr'].loc[:,-10:-20,120:150]\n",
    "mtpr97 = xr.open_mfdataset('/g/data5/rt52/era5/single-levels/reanalysis/mtpr/1997/mtpr_era5_oper_sfc_1997*')['mtpr'].loc[:,-10:-20,120:150]\n",
    "mtpr98 = xr.open_mfdataset('/g/data5/rt52/era5/single-levels/reanalysis/mtpr/1998/mtpr_era5_oper_sfc_1998*')['mtpr'].loc[:,-10:-20,120:150]\n",
    "mtpr99 = xr.open_mfdataset('/g/data5/rt52/era5/single-levels/reanalysis/mtpr/1999/mtpr_era5_oper_sfc_1999*')['mtpr'].loc[:,-10:-20,120:150]\n",
    "mtpr00 = xr.open_mfdataset('/g/data5/rt52/era5/single-levels/reanalysis/mtpr/2000/mtpr_era5_oper_sfc_2000*')['mtpr'].loc[:,-10:-20,120:150]\n",
    "mtpr01 = xr.open_mfdataset('/g/data5/rt52/era5/single-levels/reanalysis/mtpr/2001/mtpr_era5_oper_sfc_2001*')['mtpr'].loc[:,-10:-20,120:150]\n",
    "mtpr02 = xr.open_mfdataset('/g/data5/rt52/era5/single-levels/reanalysis/mtpr/2002/mtpr_era5_oper_sfc_2002*')['mtpr'].loc[:,-10:-20,120:150]\n",
    "mtpr03 = xr.open_mfdataset('/g/data5/rt52/era5/single-levels/reanalysis/mtpr/2003/mtpr_era5_oper_sfc_2003*')['mtpr'].loc[:,-10:-20,120:150]\n",
    "mtpr04 = xr.open_mfdataset('/g/data5/rt52/era5/single-levels/reanalysis/mtpr/2004/mtpr_era5_oper_sfc_2004*')['mtpr'].loc[:,-10:-20,120:150]\n",
    "mtpr05 = xr.open_mfdataset('/g/data5/rt52/era5/single-levels/reanalysis/mtpr/2005/mtpr_era5_oper_sfc_2005*')['mtpr'].loc[:,-10:-20,120:150]\n",
    "mtpr06 = xr.open_mfdataset('/g/data5/rt52/era5/single-levels/reanalysis/mtpr/2006/mtpr_era5_oper_sfc_2006*')['mtpr'].loc[:,-10:-20,120:150]\n",
    "mtpr07 = xr.open_mfdataset('/g/data5/rt52/era5/single-levels/reanalysis/mtpr/2007/mtpr_era5_oper_sfc_2007*')['mtpr'].loc[:,-10:-20,120:150]\n",
    "mtpr08 = xr.open_mfdataset('/g/data5/rt52/era5/single-levels/reanalysis/mtpr/2008/mtpr_era5_oper_sfc_2008*')['mtpr'].loc[:,-10:-20,120:150]\n",
    "mtpr09 = xr.open_mfdataset('/g/data5/rt52/era5/single-levels/reanalysis/mtpr/2009/mtpr_era5_oper_sfc_2009*')['mtpr'].loc[:,-10:-20,120:150]\n",
    "mtpr10 = xr.open_mfdataset('/g/data5/rt52/era5/single-levels/reanalysis/mtpr/2010/mtpr_era5_oper_sfc_2010*')['mtpr'].loc[:,-10:-20,120:150]\n",
    "mtpr11 = xr.open_mfdataset('/g/data5/rt52/era5/single-levels/reanalysis/mtpr/2011/mtpr_era5_oper_sfc_2011*')['mtpr'].loc[:,-10:-20,120:150]\n",
    "mtpr12 = xr.open_mfdataset('/g/data5/rt52/era5/single-levels/reanalysis/mtpr/2012/mtpr_era5_oper_sfc_2012*')['mtpr'].loc[:,-10:-20,120:150]\n",
    "mtpr13 = xr.open_mfdataset('/g/data5/rt52/era5/single-levels/reanalysis/mtpr/2013/mtpr_era5_oper_sfc_2013*')['mtpr'].loc[:,-10:-20,120:150]\n",
    "mtpr14 = xr.open_mfdataset('/g/data5/rt52/era5/single-levels/reanalysis/mtpr/2014/mtpr_era5_oper_sfc_2014*')['mtpr'].loc[:,-10:-20,120:150]\n",
    "mtpr15 = xr.open_mfdataset('/g/data5/rt52/era5/single-levels/reanalysis/mtpr/2015/mtpr_era5_oper_sfc_2015*')['mtpr'].loc[:,-10:-20,120:150]\n",
    "mtpr16 = xr.open_mfdataset('/g/data5/rt52/era5/single-levels/reanalysis/mtpr/2016/mtpr_era5_oper_sfc_2016*')['mtpr'].loc[:,-10:-20,120:150]\n",
    "mtpr17 = xr.open_mfdataset('/g/data5/rt52/era5/single-levels/reanalysis/mtpr/2017/mtpr_era5_oper_sfc_2017*')['mtpr'].loc[:,-10:-20,120:150]\n",
    "mtpr18 = xr.open_mfdataset('/g/data5/rt52/era5/single-levels/reanalysis/mtpr/2018/mtpr_era5_oper_sfc_2018*')['mtpr'].loc[:,-10:-20,120:150]\n",
    "mtpr19 = xr.open_mfdataset('/g/data5/rt52/era5/single-levels/reanalysis/mtpr/2019/mtpr_era5_oper_sfc_2019*')['mtpr'].loc[:,-10:-20,120:150]\n",
    "mtpr20 = xr.open_mfdataset('/g/data5/rt52/era5/single-levels/reanalysis/mtpr/2020/mtpr_era5_oper_sfc_2020*')['mtpr'].loc[:,-10:-20,120:150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2928bbb5-e028-4d34-abe6-2c0697c89dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "t90 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/t/1990/t_era5_oper_pl_1990*')['t'].loc[:,925,-10:-30,110:155]\n",
    "t91 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/t/1991/t_era5_oper_pl_1991*')['t'].loc[:,925,-10:-30,110:155]\n",
    "t92 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/t/1992/t_era5_oper_pl_1992*')['t'].loc[:,925,-10:-30,110:155]\n",
    "t93 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/t/1993/t_era5_oper_pl_1993*')['t'].loc[:,925,-10:-30,110:155]\n",
    "t94 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/t/1994/t_era5_oper_pl_1994*')['t'].loc[:,925,-10:-30,110:155]\n",
    "t95 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/t/1995/t_era5_oper_pl_1995*')['t'].loc[:,925,-10:-30,110:155]\n",
    "t96 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/t/1996/t_era5_oper_pl_1996*')['t'].loc[:,925,-10:-30,110:155]\n",
    "t97 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/t/1997/t_era5_oper_pl_1997*')['t'].loc[:,925,-10:-30,110:155]\n",
    "t98 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/t/1998/t_era5_oper_pl_1998*')['t'].loc[:,925,-10:-30,110:155]\n",
    "t99 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/t/1999/t_era5_oper_pl_1999*')['t'].loc[:,925,-10:-30,110:155]\n",
    "t00 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/t/2000/t_era5_oper_pl_2000*')['t'].loc[:,925,-10:-30,110:155]\n",
    "t01 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/t/2001/t_era5_oper_pl_2001*')['t'].loc[:,925,-10:-30,110:155]\n",
    "t02 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/t/2002/t_era5_oper_pl_2002*')['t'].loc[:,925,-10:-30,110:155]\n",
    "t03 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/t/2003/t_era5_oper_pl_2003*')['t'].loc[:,925,-10:-30,110:155]\n",
    "t04 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/t/2004/t_era5_oper_pl_2004*')['t'].loc[:,925,-10:-30,110:155]\n",
    "t05 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/t/2005/t_era5_oper_pl_2005*')['t'].loc[:,925,-10:-30,110:155]\n",
    "t06 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/t/2006/t_era5_oper_pl_2006*')['t'].loc[:,925,-10:-30,110:155]\n",
    "t07 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/t/2007/t_era5_oper_pl_2007*')['t'].loc[:,925,-10:-30,110:155]\n",
    "t08 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/t/2008/t_era5_oper_pl_2008*')['t'].loc[:,925,-10:-30,110:155]\n",
    "t09 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/t/2009/t_era5_oper_pl_2009*')['t'].loc[:,925,-10:-30,110:155]\n",
    "t10 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/t/2010/t_era5_oper_pl_2010*')['t'].loc[:,925,-10:-30,110:155]\n",
    "t11 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/t/2011/t_era5_oper_pl_2011*')['t'].loc[:,925,-10:-30,110:155]\n",
    "t12 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/t/2012/t_era5_oper_pl_2012*')['t'].loc[:,925,-10:-30,110:155]\n",
    "t13 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/t/2013/t_era5_oper_pl_2013*')['t'].loc[:,925,-10:-30,110:155]\n",
    "t14 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/t/2014/t_era5_oper_pl_2014*')['t'].loc[:,925,-10:-30,110:155]\n",
    "t15 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/t/2015/t_era5_oper_pl_2015*')['t'].loc[:,925,-10:-30,110:155]\n",
    "t16 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/t/2016/t_era5_oper_pl_2016*')['t'].loc[:,925,-10:-30,110:155]\n",
    "t17 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/t/2017/t_era5_oper_pl_2017*')['t'].loc[:,925,-10:-30,110:155]\n",
    "t18 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/t/2018/t_era5_oper_pl_2018*')['t'].loc[:,925,-10:-30,110:155]\n",
    "t19 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/t/2019/t_era5_oper_pl_2019*')['t'].loc[:,925,-10:-30,110:155]\n",
    "t20 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/t/2020/t_era5_oper_pl_2020*')['t'].loc[:,925,-10:-30,110:155]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1ca139b-3bd4-45a5-ba19-ca226f843744",
   "metadata": {},
   "outputs": [],
   "source": [
    "#potential temperature conversion\n",
    "pot90=t90*(1000/t90.level)**0.286\n",
    "pot91=t91*(1000/t91.level)**0.286\n",
    "pot92=t92*(1000/t92.level)**0.286\n",
    "pot93=t93*(1000/t93.level)**0.286\n",
    "pot94=t94*(1000/t94.level)**0.286\n",
    "pot95=t95*(1000/t95.level)**0.286\n",
    "pot96=t96*(1000/t96.level)**0.286\n",
    "pot97=t97*(1000/t97.level)**0.286\n",
    "pot98=t98*(1000/t98.level)**0.286\n",
    "pot99=t99*(1000/t99.level)**0.286\n",
    "pot00=t00*(1000/t00.level)**0.286\n",
    "pot01=t01*(1000/t01.level)**0.286\n",
    "pot02=t02*(1000/t02.level)**0.286\n",
    "pot03=t03*(1000/t03.level)**0.286\n",
    "pot04=t04*(1000/t04.level)**0.286\n",
    "pot05=t05*(1000/t05.level)**0.286\n",
    "pot06=t06*(1000/t06.level)**0.286\n",
    "pot07=t07*(1000/t07.level)**0.286\n",
    "pot08=t08*(1000/t08.level)**0.286\n",
    "pot09=t09*(1000/t09.level)**0.286\n",
    "pot10=t10*(1000/t10.level)**0.286\n",
    "pot11=t11*(1000/t11.level)**0.286\n",
    "pot12=t12*(1000/t12.level)**0.286\n",
    "pot13=t13*(1000/t13.level)**0.286\n",
    "pot14=t14*(1000/t14.level)**0.286\n",
    "pot15=t15*(1000/t15.level)**0.286\n",
    "pot16=t16*(1000/t16.level)**0.286\n",
    "pot17=t17*(1000/t17.level)**0.286\n",
    "pot18=t18*(1000/t18.level)**0.286\n",
    "pot19=t19*(1000/t19.level)**0.286\n",
    "pot20=t20*(1000/t20.level)**0.286"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adb279a5-f4cb-44eb-b381-cb52f2ac6806",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in variables for vertical cross section\n",
    "temp90 = xr.open_mfdataset('/g/data/rt52/era5/pressure-levels/reanalysis/q/1990/q_era5_oper_pl_1990*')['q'].loc[:,500:1000,-16,110:130]\n",
    "temp91 = xr.open_mfdataset('/g/data/rt52/era5/pressure-levels/reanalysis/q/1991/q_era5_oper_pl_1991*')['q'].loc[:,500:1000,-16,110:130]\n",
    "temp92 = xr.open_mfdataset('/g/data/rt52/era5/pressure-levels/reanalysis/q/1992/q_era5_oper_pl_1992*')['q'].loc[:,500:1000,-16,110:130]\n",
    "temp93 = xr.open_mfdataset('/g/data/rt52/era5/pressure-levels/reanalysis/q/1993/q_era5_oper_pl_1993*')['q'].loc[:,500:1000,-16,110:130]\n",
    "temp94 = xr.open_mfdataset('/g/data/rt52/era5/pressure-levels/reanalysis/q/1994/q_era5_oper_pl_1994*')['q'].loc[:,500:1000,-16,110:130]\n",
    "temp95 = xr.open_mfdataset('/g/data/rt52/era5/pressure-levels/reanalysis/q/1995/q_era5_oper_pl_1995*')['q'].loc[:,500:1000,-16,110:130]\n",
    "temp96 = xr.open_mfdataset('/g/data/rt52/era5/pressure-levels/reanalysis/q/1996/q_era5_oper_pl_1996*')['q'].loc[:,500:1000,-16,110:130]\n",
    "temp97 = xr.open_mfdataset('/g/data/rt52/era5/pressure-levels/reanalysis/q/1997/q_era5_oper_pl_1997*')['q'].loc[:,500:1000,-16,110:130]\n",
    "temp98 = xr.open_mfdataset('/g/data/rt52/era5/pressure-levels/reanalysis/q/1998/q_era5_oper_pl_1998*')['q'].loc[:,500:1000,-16,110:130]\n",
    "temp99 = xr.open_mfdataset('/g/data/rt52/era5/pressure-levels/reanalysis/q/1999/q_era5_oper_pl_1999*')['q'].loc[:,500:1000,-16,110:130]\n",
    "temp00 = xr.open_mfdataset('/g/data/rt52/era5/pressure-levels/reanalysis/q/2000/q_era5_oper_pl_2000*')['q'].loc[:,500:1000,-16,110:130]\n",
    "temp01 = xr.open_mfdataset('/g/data/rt52/era5/pressure-levels/reanalysis/q/2001/q_era5_oper_pl_2001*')['q'].loc[:,500:1000,-16,110:130]\n",
    "temp02 = xr.open_mfdataset('/g/data/rt52/era5/pressure-levels/reanalysis/q/2002/q_era5_oper_pl_2002*')['q'].loc[:,500:1000,-16,110:130]\n",
    "temp03 = xr.open_mfdataset('/g/data/rt52/era5/pressure-levels/reanalysis/q/2003/q_era5_oper_pl_2003*')['q'].loc[:,500:1000,-16,110:130]\n",
    "temp04 = xr.open_mfdataset('/g/data/rt52/era5/pressure-levels/reanalysis/q/2004/q_era5_oper_pl_2004*')['q'].loc[:,500:1000,-16,110:130]\n",
    "temp05 = xr.open_mfdataset('/g/data/rt52/era5/pressure-levels/reanalysis/q/2005/q_era5_oper_pl_2005*')['q'].loc[:,500:1000,-16,110:130]\n",
    "temp06 = xr.open_mfdataset('/g/data/rt52/era5/pressure-levels/reanalysis/q/2006/q_era5_oper_pl_2006*')['q'].loc[:,500:1000,-16,110:130]\n",
    "temp07 = xr.open_mfdataset('/g/data/rt52/era5/pressure-levels/reanalysis/q/2007/q_era5_oper_pl_2007*')['q'].loc[:,500:1000,-16,110:130]\n",
    "temp08 = xr.open_mfdataset('/g/data/rt52/era5/pressure-levels/reanalysis/q/2008/q_era5_oper_pl_2008*')['q'].loc[:,500:1000,-16,110:130]\n",
    "temp09 = xr.open_mfdataset('/g/data/rt52/era5/pressure-levels/reanalysis/q/2009/q_era5_oper_pl_2009*')['q'].loc[:,500:1000,-16,110:130]\n",
    "temp10 = xr.open_mfdataset('/g/data/rt52/era5/pressure-levels/reanalysis/q/2010/q_era5_oper_pl_2010*')['q'].loc[:,500:1000,-16,110:130]\n",
    "temp11 = xr.open_mfdataset('/g/data/rt52/era5/pressure-levels/reanalysis/q/2011/q_era5_oper_pl_2011*')['q'].loc[:,500:1000,-16,110:130]\n",
    "temp12 = xr.open_mfdataset('/g/data/rt52/era5/pressure-levels/reanalysis/q/2012/q_era5_oper_pl_2012*')['q'].loc[:,500:1000,-16,110:130]\n",
    "temp13 = xr.open_mfdataset('/g/data/rt52/era5/pressure-levels/reanalysis/q/2013/q_era5_oper_pl_2013*')['q'].loc[:,500:1000,-16,110:130]\n",
    "temp14 = xr.open_mfdataset('/g/data/rt52/era5/pressure-levels/reanalysis/q/2014/q_era5_oper_pl_2014*')['q'].loc[:,500:1000,-16,110:130]\n",
    "temp15 = xr.open_mfdataset('/g/data/rt52/era5/pressure-levels/reanalysis/q/2015/q_era5_oper_pl_2015*')['q'].loc[:,500:1000,-16,110:130]\n",
    "temp16 = xr.open_mfdataset('/g/data/rt52/era5/pressure-levels/reanalysis/q/2016/q_era5_oper_pl_2016*')['q'].loc[:,500:1000,-16,110:130]\n",
    "temp17 = xr.open_mfdataset('/g/data/rt52/era5/pressure-levels/reanalysis/q/2017/q_era5_oper_pl_2017*')['q'].loc[:,500:1000,-16,110:130]\n",
    "temp18 = xr.open_mfdataset('/g/data/rt52/era5/pressure-levels/reanalysis/q/2018/q_era5_oper_pl_2018*')['q'].loc[:,500:1000,-16,110:130]\n",
    "temp19 = xr.open_mfdataset('/g/data/rt52/era5/pressure-levels/reanalysis/q/2019/q_era5_oper_pl_2019*')['q'].loc[:,500:1000,-16,110:130]\n",
    "temp20 = xr.open_mfdataset('/g/data/rt52/era5/pressure-levels/reanalysis/q/2020/q_era5_oper_pl_2020*')['q'].loc[:,500:1000,-16,110:130]\n",
    "                           \n",
    "#lat = temp20.latitude\n",
    "lvl = temp20.level\n",
    "lon = temp20.longitude"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc808cf0-a0c2-480a-a908-effca496e280",
   "metadata": {},
   "source": [
    "# Calculate Ageostrophic winds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45edcdd-830b-450c-82c1-f2c5601dea06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ageostrophic wind data\n",
    "g = 9.81\n",
    "f = 2*7.292*10**(-5)*np.sin(lat_r).data\n",
    "uawind = [[] for x in range(961)]\n",
    "vawind = [[] for x in range(961)]\n",
    "def ageowind(start,stop,lystart,lystop,month,monthlong):\n",
    "    for i in range(0,1): #hour loop\n",
    "        utime = [ut90,ut91,ut92,ut93,ut94,ut95,ut96,ut97,ut98,ut99,\n",
    "                ut00,ut01,ut02,ut03,ut04,ut05,ut06,ut07,ut08,ut09,\n",
    "                ut10,ut11,ut12,ut13,ut14,ut15,ut16,ut17,ut18,ut19,ut20] = [u90[i::24],u91[i::24],u92[i::24],u93[i::24],u94[i::24],\n",
    "                                                                           u95[i::24],u96[i::24],u97[i::24],u98[i::24],u99[i::24],\n",
    "                                                                           u00[i::24],u01[i::24],u02[i::24],u03[i::24],u04[i::24],\n",
    "                                                                           u05[i::24],u06[i::24],u07[i::24],u08[i::24],u09[i::24],\n",
    "                                                                           u10[i::24],u11[i::24],u12[i::24],u13[i::24],u14[i::24],\n",
    "                                                                           u15[i::24],u16[i::24],u17[i::24],u18[i::24],u19[i::24],u20[i::24]]\n",
    "\n",
    "\n",
    "        vtime = [vt90,vt91,vt92,vt93,vt94,vt95,vt96,vt97,vt98,vt99,\n",
    "            vt00,vt01,vt02,vt03,vt04,vt05,vt06,vt07,vt08,vt09,\n",
    "            vt10,vt11,vt12,vt13,vt14,vt15,vt16,vt17,vt18,vt19,vt20] = [v90[i::24],v91[i::24],v92[i::24],v93[i::24],v94[i::24],\n",
    "                                                                       v95[i::24],v96[i::24],v97[i::24],v98[i::24],v99[i::24],\n",
    "                                                                       v00[i::24],v01[i::24],v02[i::24],v03[i::24],v04[i::24],\n",
    "                                                                       v05[i::24],v06[i::24],v07[i::24],v08[i::24],v09[i::24],\n",
    "                                                                       v10[i::24],v11[i::24],v12[i::24],v13[i::24],v14[i::24],\n",
    "                                                                       v15[i::24],v16[i::24],v17[i::24],v18[i::24],v19[i::24],v20[i::24]]\n",
    "        ztime = [zt90,zt91,zt92,zt93,zt94,zt95,zt96,zt97,zt98,zt99,\n",
    "            zt00,zt01,zt02,zt03,zt04,zt05,zt06,zt07,zt08,zt09,\n",
    "            zt10,zt11,zt12,zt13,zt14,zt15,zt16,zt17,zt18,zt19,zt20] = [z90[i::24],z91[i::24],z92[i::24],z93[i::24],z94[i::24],\n",
    "                                                                       z95[i::24],z96[i::24],z97[i::24],z98[i::24],z99[i::24],\n",
    "                                                                       z00[i::24],z01[i::24],z02[i::24],z03[i::24],z04[i::24],\n",
    "                                                                       z05[i::24],z06[i::24],z07[i::24],z08[i::24],z09[i::24],\n",
    "                                                                       z10[i::24],z11[i::24],z12[i::24],z13[i::24],z14[i::24],\n",
    "                                                                       z15[i::24],z16[i::24],z17[i::24],z18[i::24],z19[i::24],z20[i::24]]\n",
    "        uhour = xr.concat([ut90[start:stop],ut91[start:stop],ut92[lystart:lystop],ut93[start:stop],ut94[start:stop],ut95[start:stop],\n",
    "                ut96[lystart:lystop],ut97[start:stop],ut98[start:stop],ut99[start:stop],ut00[lystart:lystop],ut01[start:stop],\n",
    "                ut02[start:stop],ut03[start:stop],ut04[lystart:lystop],ut05[start:stop],ut06[start:stop],ut07[start:stop],\n",
    "                ut08[lystart:lystop],ut09[start:stop],ut10[start:stop],ut11[start:stop],ut12[lystart:lystop],ut13[start:stop],\n",
    "                ut14[start:stop],ut15[start:stop],ut16[lystart:lystop],ut17[start:stop],ut18[start:stop],ut19[start:stop],ut20[lystart:lystop]],dim='time') \n",
    "        vhour = xr.concat([vt90[start:stop],vt91[start:stop],vt92[lystart:lystop],vt93[start:stop],vt94[start:stop],vt95[start:stop],\n",
    "                vt96[lystart:lystop],vt97[start:stop],vt98[start:stop],vt99[start:stop],vt00[lystart:lystop],vt01[start:stop],\n",
    "                vt02[start:stop],vt03[start:stop],vt04[lystart:lystop],vt05[start:stop],vt06[start:stop],vt07[start:stop],\n",
    "                vt08[lystart:lystop],vt09[start:stop],vt10[start:stop],vt11[start:stop],vt12[lystart:lystop],vt13[start:stop],\n",
    "                vt14[start:stop],vt15[start:stop],vt16[lystart:lystop],vt17[start:stop],vt18[start:stop],vt19[start:stop],vt20[lystart:lystop]],dim='time')\n",
    "        zhour = xr.concat([zt90[start:stop],zt91[start:stop],zt92[lystart:lystop],zt93[start:stop],zt94[start:stop],zt95[start:stop],\n",
    "                zt96[lystart:lystop],zt97[start:stop],zt98[start:stop],zt99[start:stop],zt00[lystart:lystop],zt01[start:stop],\n",
    "                zt02[start:stop],zt03[start:stop],zt04[lystart:lystop],zt05[start:stop],zt06[start:stop],zt07[start:stop],\n",
    "                zt08[lystart:lystop],zt09[start:stop],zt10[start:stop],zt11[start:stop],zt12[lystart:lystop],zt13[start:stop],\n",
    "                zt14[start:stop],zt15[start:stop],zt16[lystart:lystop],zt17[start:stop],zt18[start:stop],zt19[start:stop],zt20[lystart:lystop]],dim='time')\n",
    "        utime = vhour.time\n",
    "        for j in range(0,961): #yearxmonth\n",
    "                dzdx = np.gradient(zhour[j], lon_r, axis=1)/(r * np.cos(lat_r).data[:, np.newaxis])\n",
    "                dzdy = np.gradient(zhour[j], lat_r, axis=0)/r\n",
    "                u_geo = -(1/f[:, np.newaxis])*dzdy\n",
    "                v_geo = (1/f[:, np.newaxis])*dzdx\n",
    "                uawind[j] = uhour[j] - u_geo #u-ageostrophic wind\n",
    "                vawind[j] = vhour[j] - v_geo #v-ageostrophic wind\n",
    "                # (uawind)[j][np.where(uawind[j]>50)]=np.nan\n",
    "                # (vawind)[j][np.where(vawind[j]>50)]=np.nan\n",
    "                # if np.any(uawind[j] > 100):\n",
    "                #     print(uawind[j])\n",
    "                #     print(np.max(np.array(uawind[j])))\n",
    "                    # high_index = np.where(u_geo>100)\n",
    "                    # print(high_index)\n",
    "                    # print('f=')\n",
    "                    # print(f[18])\n",
    "                    # print('dzdy=')\n",
    "                    # print(dzdy[18][148])\n",
    "                    # print('ugeo=')\n",
    "                    # print(u_geo[18][148])\n",
    "                    # print(np.max(dzdy))\n",
    "                    # print(np.where(uhour[j]))\n",
    "                    # print(u_geo)\n",
    "                    # print(np.where(uawind[j]>50))\n",
    "                # if np.any(vawind[j] > 50):\n",
    "                    # print(np.max(vhour[j]))\n",
    "                    # print(v_geo)\n",
    "                    # print(np.where(vawind[j]))\n",
    "                # amag[j] = np.sqrt(u_ageo**2 + v_ageo**2)\n",
    "        uamean = np.nanmean(uawind, axis=0 )\n",
    "        vamean = np.nanmean(vawind, axis=0 )\n",
    "        zmean = zhour.mean(dim='time')\n",
    "        print(np.array(uamean))\n",
    "        print(np.array(vamean))\n",
    "        ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "        ax.set_extent([110, 155, -30, -10], ccrs.PlateCarree())\n",
    "        lon_grid = np.arange(110,155,5)\n",
    "        lat_grid = np.arange(-30,-10,5)\n",
    "        gl = ax.gridlines(draw_labels=True,xlocs=lon_grid,ylocs=lat_grid,\n",
    "                  x_inline=False,y_inline=False,color='k',linestyle='--',linewidth=0.4)\n",
    "        gl.top_labels = False\n",
    "        gl.right_labels = False\n",
    "        gl.left_labels = False\n",
    "        lons, lats = np.meshgrid(qlon, qlat)\n",
    "        quiver_slices = (slice(None, None, 9), slice(None, None, 7))\n",
    "        plt.quiver(lons[quiver_slices],lats[quiver_slices],uamean[quiver_slices],vamean[quiver_slices],width=0.0025)\n",
    "        # con = plt.contour(lons,lats,zmean)\n",
    "        plt.title('ageostrophic wind and geopotential height')\n",
    "        ax.coastlines()  \n",
    "        # plt.quiverkey(Q1, 0.81, 0.92, 10, r'$10 \\frac{m}{s}$', labelpos='E',\n",
    "        #                    coordinates='figure',angle = 180, labelsep=0.3) \n",
    "#         kw_clabels = {'fontsize': 11, 'inline': True, 'inline_spacing': 5, 'fmt': '%i',\n",
    "#                                   'rightside_up': True, 'use_clabeltext': True}\n",
    "\n",
    "#         plt.clabel(con, **kw_clabels)\n",
    "        plt.show()\n",
    "        # xr.DataArray(uamean,dims=[\"latitude\",\"longitude\"],coords=dict(latitude=lat,longitude=lon)).to_netcdf(path='/g/data/k10/lr0203/Winds/uageo-data/October/uageoOCT'+UTC[i]+'mean.nc')\n",
    "        # xr.DataArray(vamean,dims=[\"latitude\",\"longitude\"],coords=dict(latitude=lat,longitude=lon)).to_netcdf(path='/g/data/k10/lr0203/Winds/vageo-data/October/vageoOCT'+UTC[i]+'mean.nc')\n",
    "        # xr.DataArray(zmean).to_netcdf(path='/g/data/k10/lr0203/Winds/geopotential-data/October/zmeanOCT'+UTC[i]+'.nc')\n",
    "        # xr.DataArray(uawind,dims=[\"time\",\"latitude\",\"longitude\"],coords=dict(time=utime,latitude=qlat,longitude=qlon)).to_netcdf(path='/g/data/k10/lr0203/Winds/uageo/'+monthlong+'/uageo_full/uageofull'+month+UTC[i]+'.nc')\n",
    "        # xr.DataArray(vawind,dims=[\"time\",\"latitude\",\"longitude\"],coords=dict(time=utime,latitude=qlat,longitude=qlon)).to_netcdf(path='/g/data/k10/lr0203/Winds/vageo/'+monthlong+'/vageo_full/vageofull'+month+UTC[i]+'.nc')\n",
    "\n",
    "ageowind(decstart[0],decstop[0],decstart[1],decstop[1],month[11],monthlong[11])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1caa1b95-920b-4b9d-9541-48248b7dac85",
   "metadata": {},
   "source": [
    "# Frontogenesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec10bfea-4c7c-4160-8ee9-e12272dc1e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def frontogenesiscalc(start,stop,lystart,lystop,month,monthlong):\n",
    "    gradq=[[] for x in range(876)]\n",
    "    D=[[] for x in range(876)]\n",
    "    E=[[] for x in range(876)]\n",
    "    F=[[] for x in range(876)]\n",
    "    Eprime=[[] for x in range(876)]\n",
    "    alpha=[[] for x in range(876)]\n",
    "    delta=[[] for x in range(876)]\n",
    "    beta=[[] for x in range(876)]\n",
    "    frontogenesis=[[] for x in range(876)]\n",
    "    for i in range(17,24): #hour loop\n",
    "        qtime = [tq90,tq91,tq92,tq93,tq94,tq95,tq96,tq97,tq98,tq99,\n",
    "                tq00,tq01,tq02,tq03,tq04,tq05,tq06,tq07,tq08,tq09,\n",
    "                tq10,tq11,tq12,tq13,tq14,tq15,tq16,tq17,tq18,tq19,tq20] = [q90[i::24],q91[i::24],q92[i::24],q93[i::24],\n",
    "                                                                q94[i::24],q95[i::24],q96[i::24],q97[i::24],\n",
    "                                                                q98[i::24],q99[i::24],q00[i::24],q01[i::24],\n",
    "                                                                q02[i::24],q03[i::24],q04[i::24],q05[i::24],\n",
    "                                                                q06[i::24],q07[i::24],q08[i::24],q09[i::24],\n",
    "                                                                q10[i::24],q11[i::24],q12[i::24],q13[i::24],\n",
    "                                                                q14[i::24],q15[i::24],q16[i::24],q17[i::24],\n",
    "                                                                q18[i::24],q19[i::24],q20[i::24]]\n",
    "        qhour =  xr.concat([tq90[start:stop],tq91[start:stop],tq92[lystart:lystop],tq93[start:stop],tq94[start:stop],tq95[start:stop],tq96[lystart:lystop],tq97[start:stop],\n",
    "                tq98[start:stop],tq99[start:stop],tq00[lystart:lystop],tq01[start:stop],tq02[start:stop],tq03[start:stop],tq04[lystart:lystop],tq05[start:stop],\n",
    "                tq06[start:stop],tq07[start:stop],tq08[lystart:lystop],tq09[start:stop],tq10[start:stop],tq11[start:stop],tq12[lystart:lystop],tq13[start:stop],\n",
    "                tq14[start:stop],tq15[start:stop],tq16[lystart:lystop],tq17[start:stop],tq18[start:stop],tq19[start:stop],tq20[lystart:lystop]],dim='time')\n",
    "        ftime = qhour.time\n",
    "        \n",
    "        utime = [tu90,tu91,tu92,tu93,tu94,tu95,tu96,tu97,tu98,tu99,\n",
    "                tu00,tu01,tu02,tu03,tu04,tu05,tu06,tu07,tu08,tu09,\n",
    "                tu10,tu11,tu12,tu13,tu14,tu15,tu16,tu17,tu18,tu19,tu20] = [u90[i::24],u91[i::24],u92[i::24],u93[i::24],\n",
    "                                                                u94[i::24],u95[i::24],u96[i::24],u97[i::24],\n",
    "                                                                u98[i::24],u99[i::24],u00[i::24],u01[i::24],\n",
    "                                                                u02[i::24],u03[i::24],u04[i::24],u05[i::24],\n",
    "                                                                u06[i::24],u07[i::24],u08[i::24],u09[i::24],\n",
    "                                                                u10[i::24],u11[i::24],u12[i::24],u13[i::24],\n",
    "                                                                u14[i::24],u15[i::24],u16[i::24],u17[i::24],\n",
    "                                                                u18[i::24],u19[i::24],u20[i::24]]\n",
    "        uhour =  xr.concat([tu90[start:stop],tu91[start:stop],tu92[lystart:lystop],tu93[start:stop],tu94[start:stop],tu95[start:stop],tu96[lystart:lystop],tu97[start:stop],\n",
    "                tu98[start:stop],tu99[start:stop],tu00[lystart:lystop],tu01[start:stop],tu02[start:stop],tu03[start:stop],tu04[lystart:lystop],tu05[start:stop],\n",
    "                tu06[start:stop],tu07[start:stop],tu08[lystart:lystop],tu09[start:stop],tu10[start:stop],tu11[start:stop],tu12[lystart:lystop],tu13[start:stop],\n",
    "                tu14[start:stop],tu15[start:stop],tu16[lystart:lystop],tu17[start:stop],tu18[start:stop],tu19[start:stop],tu20[lystart:lystop]],dim='time')\n",
    "        \n",
    "        vtime = [tv90,tv91,tv92,tv93,tv94,tv95,tv96,tv97,tv98,tv99,\n",
    "               tv00,tv01,tv02,tv03,tv04,tv05,tv06,tv07,tv08,tv09,\n",
    "                tv10,tv11,tv12,tv13,tv14,tv15,tv16,tv17,tv18,tv19,tv20] = [v90[i::24],v91[i::24],v92[i::24],v93[i::24],\n",
    "                                                                v94[i::24],v95[i::24],v96[i::24],v97[i::24],\n",
    "                                                                v98[i::24],v99[i::24],v00[i::24],v01[i::24],\n",
    "                                                                v02[i::24],v03[i::24],v04[i::24],v05[i::24],\n",
    "                                                                v06[i::24],v07[i::24],v08[i::24],v09[i::24],\n",
    "                                                                v10[i::24],v11[i::24],v12[i::24],v13[i::24],\n",
    "                                                                v14[i::24],v15[i::24],v16[i::24],v17[i::24],\n",
    "                                                                v18[i::24],v19[i::24],v20[i::24]]\n",
    "        vhour =  xr.concat([tv90[start:stop],tv91[start:stop],tv92[lystart:lystop],tv93[start:stop],tv94[start:stop],tv95[start:stop],tv96[lystart:lystop],tv97[start:stop],\n",
    "                tv98[start:stop],tv99[start:stop],tv00[lystart:lystop],tv01[start:stop],tv02[start:stop],tv03[start:stop],tv04[lystart:lystop],tv05[start:stop],\n",
    "                tv06[start:stop],tv07[start:stop],tv08[lystart:lystop],tv09[start:stop],tv10[start:stop],tv11[start:stop],tv12[lystart:lystop],tv13[start:stop],\n",
    "                tv14[start:stop],tv15[start:stop],tv16[lystart:lystop],tv17[start:stop],tv18[start:stop],tv19[start:stop],tv20[lystart:lystop]],dim='time')\n",
    "        for j in range(0,876): #year(31) x month loop \n",
    "            #calculate gradq            \n",
    "            dqdy = np.gradient(qhour[j], lat_r, axis=0)/r\n",
    "            dqdx = np.gradient(qhour[j], lon_r, axis=1)/(r*np.cos(lat_r).data[:,np.newaxis])\n",
    "            gradq[j] = np.sqrt((dqdy) ** 2 + (dqdx) ** 2)*1000\n",
    "            # calculate D\n",
    "            vcos = vhour[j]*(np.cos(lat_r))\n",
    "            dudx = np.gradient(uhour[j], lon_r, axis=1) / (r * np.cos(lat_r).data[:, np.newaxis])\n",
    "            dDdy = (np.gradient(vcos, lat_r, axis=0) / r)/(np.cos(lat_r).data[:, np.newaxis])\n",
    "            D[j] = dudx + dDdy\n",
    "            #calculate E\n",
    "            v_cos = vhour[j]/(np.cos(lat_r))\n",
    "            dEdy = (np.gradient(v_cos, lat_r, axis=0) / r)*(np.cos(lat_r).data[:,np.newaxis])\n",
    "            E[j] = dudx - dEdy\n",
    "            #calculate F\n",
    "            dvdx = np.gradient(vhour[j], lon_r, axis=1) / (r * np.cos(lat_r).data[:, np.newaxis])\n",
    "            u_cos = uhour[j]/(np.cos(lat_r))\n",
    "            dFdy = (np.gradient(u_cos, lat_r, axis=0) / r)*(np.cos(lat_r).data[:, np.newaxis])\n",
    "            F[j] = dvdx + dFdy\n",
    "            #calculate E'\n",
    "            Eprime[j] = np.sqrt(E[j]**2 +F[j]**2)\n",
    "            #calculate alpha\n",
    "            angle=dqdx/dqdy\n",
    "            (angle)[np.isposinf(angle)]=(np.pi/2)\n",
    "            (angle)[np.isneginf(angle)]=-(np.pi/2)\n",
    "            alpha[j] = np.arctan(-(angle))\n",
    "            #calculate delta\n",
    "            delta[j] = (np.arctan(F[j]/E[j]))/2\n",
    "            #calculate beta\n",
    "            beta[j] = delta[j]-alpha[j]\n",
    "            #calculate frontogenesis\n",
    "            frontogenesis[j] = (np.absolute(gradq[j])*(D[j]-Eprime[j]*np.cos(2*beta[j])))/2\n",
    "        meanfronto = np.mean(frontogenesis,axis=0)\n",
    "        xr.DataArray(alpha,dims=[\"time\",\"latitude\",\"longitude\"],coords=dict(time=ftime,latitude=qlat,longitude=qlon)).to_netcdf(path='/g/data/k10/lr0203/Frontogenesis/Fn/'+monthlong+'/alpha/alpha'+month+UTC[i]+'.nc')\n",
    "        xr.DataArray(beta,dims=[\"time\",\"latitude\",\"longitude\"],coords=dict(time=ftime,latitude=qlat,longitude=qlon)).to_netcdf(path='/g/data/k10/lr0203/Frontogenesis/Fn/'+monthlong+'/beta/beta'+month+UTC[i]+'.nc')\n",
    "        xr.DataArray(D,dims=[\"time\",\"latitude\",\"longitude\"],coords=dict(time=ftime,latitude=qlat,longitude=qlon)).to_netcdf(path='/g/data/k10/lr0203/Frontogenesis/Fn/'+monthlong+'/D/D'+month+UTC[i]+'.nc')\n",
    "        xr.DataArray(delta,dims=[\"time\",\"latitude\",\"longitude\"],coords=dict(time=ftime,latitude=qlat,longitude=qlon)).to_netcdf(path='/g/data/k10/lr0203/Frontogenesis/Fn/'+monthlong+'/delta/delta'+month+UTC[i]+'.nc')\n",
    "        xr.DataArray(E,dims=[\"time\",\"latitude\",\"longitude\"],coords=dict(time=ftime,latitude=qlat,longitude=qlon)).to_netcdf(path='/g/data/k10/lr0203/Frontogenesis/Fn/'+monthlong+'/E/E'+month+UTC[i]+'.nc')\n",
    "        xr.DataArray(Eprime,dims=[\"time\",\"latitude\",\"longitude\"],coords=dict(time=ftime,latitude=qlat,longitude=qlon)).to_netcdf(path='/g/data/k10/lr0203/Frontogenesis/Fn/'+monthlong+'/Eprime/Eprime'+month+UTC[i]+'.nc')\n",
    "        xr.DataArray(F,dims=[\"time\",\"latitude\",\"longitude\"],coords=dict(time=ftime,latitude=qlat,longitude=qlon)).to_netcdf(path='/g/data/k10/lr0203/Frontogenesis/Fn/'+monthlong+'/F/F'+month+UTC[i]+'.nc')\n",
    "        xr.DataArray(frontogenesis,dims=[\"time\",\"latitude\",\"longitude\"],coords=dict(time=ftime,latitude=qlat,longitude=qlon)).to_netcdf(path='/g/data/k10/lr0203/Frontogenesis/Fn/'+monthlong+'/Fn_Fronto/Fn_Fronto'+month+UTC[i]+'.nc')\n",
    "        xr.DataArray(meanfronto,dims=[\"latitude\",\"longitude\"],coords=dict(latitude=qlat,longitude=qlon)).to_netcdf(path='/g/data/k10/lr0203/Frontogenesis/Fn/'+monthlong+'/Fn_MeanFronto/Fn_MeanFronto'+month+UTC[i]+'.nc')\n",
    "        xr.DataArray(gradq,dims=[\"time\",\"latitude\",\"longitude\"],coords=dict(time=ftime,latitude=qlat,longitude=qlon)).to_netcdf(path='/g/data/k10/lr0203/Frontogenesis/Fn/'+monthlong+'/gradq/gradq'+month+UTC[i]+'.nc')\n",
    "\n",
    "frontogenesiscalc(febstart[0],febstop[0],febstart[1],febstop[1],month[1],monthlong[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6a0b03-d795-4ce2-9d65-c7f9210d16f5",
   "metadata": {},
   "source": [
    "# Specific humidity gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8e15da63-f4ee-4c2f-9520-b5c70a5d90a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "gradq = [[] for x in range(961)]\n",
    "def dailygradq(start,stop,lystart,lystop,month,monthlong):\n",
    "    for i in range(3,4):#hour loop   \n",
    "        qtime = [tq90,tq91,tq92,tq93,tq94,tq95,tq96,tq97,tq98,tq99,\n",
    "                tq00,tq01,tq02,tq03,tq04,tq05,tq06,tq07,tq08,tq09,\n",
    "                tq10,tq11,tq12,tq13,tq14,tq15,tq16,tq17,tq18,tq19,tq20] = [q90[i::24],q91[i::24],q92[i::24],q93[i::24],\n",
    "                                                                q94[i::24],q95[i::24],q96[i::24],q97[i::24],\n",
    "                                                                q98[i::24],q99[i::24],q00[i::24],q01[i::24],\n",
    "                                                                q02[i::24],q03[i::24],q04[i::24],q05[i::24],\n",
    "                                                                q06[i::24],q07[i::24],q08[i::24],q09[i::24],\n",
    "                                                                q10[i::24],q11[i::24],q12[i::24],q13[i::24],\n",
    "                                                                q14[i::24],q15[i::24],q16[i::24],q17[i::24],\n",
    "                                                                q18[i::24],q19[i::24],q20[i::24]]\n",
    "        qhour =  xr.concat([tq90[start:stop],tq91[start:stop],tq92[lystart:lystop],tq93[start:stop],tq94[start:stop],tq95[start:stop],tq96[lystart:lystop],tq97[start:stop],\n",
    "                tq98[start:stop],tq99[start:stop],tq00[lystart:lystop],tq01[start:stop],tq02[start:stop],tq03[start:stop],tq04[lystart:lystop],tq05[start:stop],\n",
    "                tq06[start:stop],tq07[start:stop],tq08[lystart:lystop],tq09[start:stop],tq10[start:stop],tq11[start:stop],tq12[lystart:lystop],tq13[start:stop],\n",
    "                tq14[start:stop],tq15[start:stop],tq16[lystart:lystop],tq17[start:stop],tq18[start:stop],tq19[start:stop],tq20[lystart:lystop]],dim='time')\n",
    "        ftime = qhour.time\n",
    "        for j in range(0,961):\n",
    "            dfdy = np.gradient(qhour[j], lat_r, axis=0)/r\n",
    "            dfdx = np.gradient(qhour[j], lon_r, axis=1)/(r*np.cos(lat_r).data[:,np.newaxis])\n",
    "            gradq[j] = np.sqrt((dfdy) ** 2 + (dfdx) ** 2)*1000\n",
    "            (gradq)[j][gradq[j]<(0.00006)]=0\n",
    "        meanqkg = qhour.mean(dim=\"time\") #calculate hourly mean of q in g\n",
    "        meanqg = meanqkg*1000 #convert q mean to kg\n",
    "        meangradq = np.mean(gradq, axis=0 ) #calculate hourly mean of grad q\n",
    "        xr.DataArray(meangradq,dims=[\"latitude\",\"longitude\"],coords=dict(latitude=lat,longitude=lon)).to_netcdf(path='/g/data/k10/lr0203/gradq/'+monthlong+'/data'+month+UTC[i]+'.nc')\n",
    "        xr.DataArray(meanqg).to_netcdf(path='/g/data/k10/lr0203/SpecHum/'+monthlong+'/q'+month+UTC[i]+'.nc')\n",
    "        xr.DataArray(qhour).to_netcdf(path='/g/data/k10/lr0203/SpecHum/'+monthlong+'/qgfull/qg'+month+UTC[i]+'.nc')\n",
    "        xr.DataArray(gradq,dims=[\"time\",\"latitude\",\"longitude\"],coords=dict(time=ftime,latitude=qlat,longitude=qlon)).to_netcdf(path='/g/data/k10/lr0203/gradq/'+monthlong+'/gradqfull/new_gradqfull'+month+UTC[i]+'.nc')\n",
    "dailygradq(marstart[0],marstop[0],marstart[1],marstop[1],month[2],monthlong[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbcf6e1-3f1c-421f-a171-72da261fa8d6",
   "metadata": {},
   "source": [
    "# Divergence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f015b8dc-0051-4f9b-a10a-c2244437bc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for calculating monthly and hourly divergence\n",
    "div = [[] for x in range(961)]\n",
    "def divergence(stop,lystart,lystop,month,monthlong):\n",
    "    for i in range(0,24): #hour loop\n",
    "        dtime = [t90,t91,t92,t93,t94,t95,t96,t97,t98,t99,\n",
    "                t00,t01,t02,t03,t04,t05,t06,t07,t08,t09,\n",
    "                t10,t11,t12,t13,t14,t15,t16,t17,t18,t19,t20] = [d90[i::24],d91[i::24],d92[i::24],d93[i::24],\n",
    "                                                                d94[i::24],d95[i::24],d96[i::24],d97[i::24],\n",
    "                                                                d98[i::24],d99[i::24],d00[i::24],d01[i::24],\n",
    "                                                                d02[i::24],d03[i::24],d04[i::24],d05[i::24],\n",
    "                                                                d06[i::24],d07[i::24],d08[i::24],d09[i::24],\n",
    "                                                                d10[i::24],d11[i::24],d12[i::24],d13[i::24],\n",
    "                                                                d14[i::24],d15[i::24],d16[i::24],d17[i::24],\n",
    "                                                                d18[i::24],d19[i::24],d20[i::24]]\n",
    "        dhour =  xr.concat([t90[start:stop],t91[start:stop],t92[lystart:lystop],t93[start:stop],t94[start:stop],t95[start:stop],t96[lystart:lystop],t97[start:stop],\n",
    "                t98[start:stop],t99[start:stop],t00[lystart:lystop],t01[start:stop],t02[start:stop],t03[start:stop],t04[lystart:lystop],t05[start:stop],\n",
    "                t06[start:stop],t07[start:stop],t08[lystart:lystop],t09[start:stop],t10[start:stop],t11[start:stop],t12[lystart:lystop],t13[start:stop],\n",
    "                t14[start:stop],t15[start:stop],t16[lystart:lystop],t17[start:stop],t18[start:stop],t19[start:stop],t20[lystart:lystop]], dim='time')\n",
    "        meandiv = dhour.mean(dim='time')\n",
    "        xr.DataArray(meandiv).to_netcdf(path='/g/data/k10/lr0203/Convergence/'+monthlong+'/Data/conv'+month+UTC[i]+'.nc')\n",
    "divergence(novstart[0],novstop[0],novstart[1],novstop[1],month[10],monthlong[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9fefaaf-cbfc-409e-a646-76926bfcb252",
   "metadata": {},
   "source": [
    "# Mean winds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c90a1a3-4755-46b1-b28a-a5cb769c28f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot mean winds test \n",
    "def meanwinds(start,stop,lystart,lystop,month):\n",
    "    for i in range(0,24):\n",
    "        utime = [ut90,ut91,ut92,ut93,ut94,ut95,ut96,ut97,ut98,ut99,\n",
    "            ut00,ut01,ut02,ut03,ut04,ut05,ut06,ut07,ut08,ut09,\n",
    "            ut10,ut11,ut12,ut13,ut14,ut15,ut16,ut17,ut18,ut19,ut20] = [u90[i::24],u91[i::24],u92[i::24],u93[i::24],u94[i::24],\n",
    "                                                                       u95[i::24],u96[i::24],u97[i::24],u98[i::24],u99[i::24],\n",
    "                                                                       u00[i::24],u01[i::24],u02[i::24],u03[i::24],u04[i::24],\n",
    "                                                                       u05[i::24],u06[i::24],u07[i::24],u08[i::24],u09[i::24],\n",
    "                                                                       u10[i::24],u11[i::24],u12[i::24],u13[i::24],u14[i::24],\n",
    "                                                                       u15[i::24],u16[i::24],u17[i::24],u18[i::24],u19[i::24],u20[i::24]]\n",
    "\n",
    "        \n",
    "        vtime = [vt90,vt91,vt92,vt93,vt94,vt95,vt96,vt97,vt98,vt99,\n",
    "            vt00,vt01,vt02,vt03,vt04,vt05,vt06,vt07,vt08,vt09,\n",
    "            vt10,vt11,vt12,vt13,vt14,vt15,vt16,vt17,vt18,vt19,vt20] = [v90[i::24],v91[i::24],v92[i::24],v93[i::24],v94[i::24],\n",
    "                                                                       v95[i::24],v96[i::24],v97[i::24],v98[i::24],v99[i::24],\n",
    "                                                                       v00[i::24],v01[i::24],v02[i::24],v03[i::24],v04[i::24],\n",
    "                                                                       v05[i::24],v06[i::24],v07[i::24],v08[i::24],v09[i::24],\n",
    "                                                                       v10[i::24],v11[i::24],v12[i::24],v13[i::24],v14[i::24],\n",
    "                                                                       v15[i::24],v16[i::24],v17[i::24],v18[i::24],v19[i::24],v20[i::24]]\n",
    "        uhour = xr.concat([ut90[start:stop],ut91[start:stop],ut92[lystart:lystop],ut93[start:stop],ut94[start:stop],ut95[start:stop],\n",
    "                ut96[lystart:lystop],ut97[start:stop],ut98[start:stop],ut99[start:stop],ut00[lystart:lystop],ut01[start:stop],\n",
    "                ut02[start:stop],ut03[start:stop],ut04[lystart:lystop],ut05[start:stop],ut06[start:stop],ut07[start:stop],\n",
    "                ut08[lystart:lystop],ut09[start:stop],ut10[start:stop],ut11[start:stop],ut12[lystart:lystop],ut13[start:stop],\n",
    "                ut14[start:stop],ut15[start:stop],ut16[lystart:lystop],ut17[start:stop],ut18[start:stop],ut19[start:stop],ut20[lystart:lystop]],dim='time') \n",
    "        vhour = xr.concat([vt90[start:stop],vt91[start:stop],vt92[lystart:lystop],vt93[start:stop],vt94[start:stop],vt95[start:stop],\n",
    "                vt96[lystart:lystop],vt97[start:stop],vt98[start:stop],vt99[start:stop],vt00[lystart:lystop],vt01[start:stop],\n",
    "                vt02[start:stop],vt03[start:stop],vt04[lystart:lystop],vt05[start:stop],vt06[start:stop],vt07[start:stop],\n",
    "                vt08[lystart:lystop],vt09[start:stop],vt10[start:stop],vt11[start:stop],vt12[lystart:lystop],vt13[start:stop],\n",
    "                vt14[start:stop],vt15[start:stop],vt16[lystart:lystop],vt17[start:stop],vt18[start:stop],vt19[start:stop],vt20[lystart:lystop]],dim='time')\n",
    "        umean = uhour.mean(dim='time')\n",
    "        vmean = vhour.mean(dim='time')\n",
    "        xr.DataArray(umean).to_netcdf(path='/g/data/k10/lr0203/Winds/uwind-data/November/umeanNOV'+UTC[i]+'.nc')\n",
    "        xr.DataArray(vmean).to_netcdf(path='/g/data/k10/lr0203/Winds/vwind-data/November/vmeanNOV'+UTC[i]+'.nc')\n",
    "meanwinds(novstart[0],novstop[0],novstart[1],novstop[1],month[10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4179eefe-df01-4691-a6ef-18217dc34c39",
   "metadata": {},
   "source": [
    "# Sea Surface Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21c33a84-930e-4db1-900a-ec4303824b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sst for 30 and 31 day months data save\n",
    "def sst(start,stop,lystart,lystop,month,monthlong):\n",
    "    for i in range(18,19): #hour loop\n",
    "        ssttime = [t90,t91,t92,t93,t94,t95,t96,t97,t98,t99,\n",
    "                t00,t01,t02,t03,t04,t05,t06,t07,t08,t09,\n",
    "                t10,t11,t12,t13,t14,t15,t16,t17,t18,t19,t20] = [sst90[i::24],sst91[i::24],sst92[i::24],sst93[i::24],\n",
    "                                                                sst94[i::24],sst95[i::24],sst96[i::24],sst97[i::24],\n",
    "                                                                sst98[i::24],sst99[i::24],sst00[i::24],sst01[i::24],\n",
    "                                                                sst02[i::24],sst03[i::24],sst04[i::24],sst05[i::24],\n",
    "                                                                sst06[i::24],sst07[i::24],sst08[i::24],sst09[i::24],\n",
    "                                                                sst10[i::24],sst11[i::24],sst12[i::24],sst13[i::24],\n",
    "                                                                sst14[i::24],sst15[i::24],sst16[i::24],sst17[i::24],\n",
    "                                                                sst18[i::24],sst19[i::24],sst20[i::24]]\n",
    "        ssthour =  xr.concat([t90[start:stop],t91[start:stop],t92[lystart:lystop],t93[start:stop],t94[start:stop],t95[start:stop],t96[lystart:lystop],t97[start:stop],\n",
    "                t98[start:stop],t99[start:stop],t00[lystart:lystop],t01[start:stop],t02[start:stop],t03[start:stop],t04[lystart:lystop],t05[start:stop],\n",
    "                t06[start:stop],t07[start:stop],t08[lystart:lystop],t09[start:stop],t10[start:stop],t11[start:stop],t12[lystart:lystop],t13[start:stop],\n",
    "                t14[start:stop],t15[start:stop],t16[lystart:lystop],t17[start:stop],t18[start:stop],t19[start:stop],t20[lystart:lystop]],dim='time')\n",
    "        meansst = ssthour.mean(dim='time')\n",
    "        xr.DataArray(meansst).to_netcdf(path='/g/data/k10/lr0203/SST/'+monthlong+'/Data/sst'+month+UTC[i]+'.nc')\n",
    "sst(augstart[0],augstop[0],augstart[1],augstop[1],month[7],monthlong[7])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a79904e-65c5-40b6-9b2e-a6f93af0e79a",
   "metadata": {},
   "source": [
    "# Mean total precipitation rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63a03950-4438-4e4b-a02c-4f79c931c9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mtpr for 30 and 31 day months data save\n",
    "def mtpr(start,stop,lystart,lystop,month,monthlong):\n",
    "    for i in range(0,24): #hour loop\n",
    "        mtprtime = [t90,t91,t92,t93,t94,t95,t96,t97,t98,t99,\n",
    "                t00,t01,t02,t03,t04,t05,t06,t07,t08,t09,\n",
    "                t10,t11,t12,t13,t14,t15,t16,t17,t18,t19,t20] = [mtpr90[i::24],mtpr91[i::24],mtpr92[i::24],mtpr93[i::24],\n",
    "                                                                mtpr94[i::24],mtpr95[i::24],mtpr96[i::24],mtpr97[i::24],\n",
    "                                                                mtpr98[i::24],mtpr99[i::24],mtpr00[i::24],mtpr01[i::24],\n",
    "                                                                mtpr02[i::24],mtpr03[i::24],mtpr04[i::24],mtpr05[i::24],\n",
    "                                                                mtpr06[i::24],mtpr07[i::24],mtpr08[i::24],mtpr09[i::24],\n",
    "                                                                mtpr10[i::24],mtpr11[i::24],mtpr12[i::24],mtpr13[i::24],\n",
    "                                                                mtpr14[i::24],mtpr15[i::24],mtpr16[i::24],mtpr17[i::24],\n",
    "                                                                mtpr18[i::24],mtpr19[i::24],mtpr20[i::24]]\n",
    "        mtprhour =  xr.concat([t90[start:stop],t91[start:stop],t92[lystart:lystop],t93[start:stop],t94[start:stop],t95[start:stop],t96[lystart:lystop],t97[start:stop],\n",
    "                t98[start:stop],t99[start:stop],t00[lystart:lystop],t01[start:stop],t02[start:stop],t03[start:stop],t04[lystart:lystop],t05[start:stop],\n",
    "                t06[start:stop],t07[start:stop],t08[lystart:lystop],t09[start:stop],t10[start:stop],t11[start:stop],t12[lystart:lystop],t13[start:stop],\n",
    "                t14[start:stop],t15[start:stop],t16[lystart:lystop],t17[start:stop],t18[start:stop],t19[start:stop],t20[lystart:lystop]],dim='time')\n",
    "        meanmtpr = mtprhour.mean(dim='time')\n",
    "        xr.DataArray(meanmtpr).to_netcdf(path='/g/data/k10/lr0203/MTPR/'+monthlong+'/Data/mtpr'+month+UTC[i]+'.nc')\n",
    "        xr.DataArray(mtprhour).to_netcdf(path='/g/data/k10/lr0203/MTPR/'+monthlong+'/MTPRdaily/MTPRdaily'+month+UTC[i]+'.nc')\n",
    "mtpr(marstart[0],marstop[0],marstart[1],marstop[1],month[2],monthlong[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495c85c7-ea0e-4e14-892e-333e7892fbc4",
   "metadata": {},
   "source": [
    "# Potential temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c0a58d-1632-4f16-a3aa-82056d2b1163",
   "metadata": {},
   "outputs": [],
   "source": [
    "#potential temperature\n",
    "def theta(start,stop,lystart,lystop,month,monthlong):\n",
    "    for i in range(15,16): #hour loop\n",
    "        thetatime = [th90,th91,th92,th93,th94,th95,th96,th97,th98,th99,\n",
    "                th00,th01,th02,th03,th04,th05,th06,th07,th08,th09,\n",
    "                th10,th11,th12,th13,th14,th15,th16,th17,th18,th19,th20] = [pot90[i::24],pot91[i::24],pot92[i::24],pot93[i::24],\n",
    "                                                                pot94[i::24],pot95[i::24],pot96[i::24],pot97[i::24],\n",
    "                                                                pot98[i::24],pot99[i::24],pot00[i::24],pot01[i::24],\n",
    "                                                                pot02[i::24],pot03[i::24],pot04[i::24],pot05[i::24],\n",
    "                                                                pot06[i::24],pot07[i::24],pot08[i::24],pot09[i::24],\n",
    "                                                                pot10[i::24],pot11[i::24],pot12[i::24],pot13[i::24],\n",
    "                                                                pot14[i::24],pot15[i::24],pot16[i::24],pot17[i::24],\n",
    "                                                                pot18[i::24],pot19[i::24],pot20[i::24]]\n",
    "        thetahour =  xr.concat([th90[start:stop],th91[start:stop],th92[lystart:lystop],th93[start:stop],th94[start:stop],th95[start:stop],th96[lystart:lystop],th97[start:stop],\n",
    "                th98[start:stop],th99[start:stop],th00[lystart:lystop],th01[start:stop],th02[start:stop],th03[start:stop],th04[lystart:lystop],th05[start:stop],\n",
    "                th06[start:stop],th07[start:stop],th08[lystart:lystop],th09[start:stop],th10[start:stop],th11[start:stop],th12[lystart:lystop],th13[start:stop],\n",
    "                th14[start:stop],th15[start:stop],th16[lystart:lystop],th17[start:stop],th18[start:stop],th19[start:stop],th20[lystart:lystop]],dim='time')\n",
    "        # thetamean = thetahour.mean(dim='time')\n",
    "        xr.DataArray(thetahour).to_netcdf(path='/g/data/k10/lr0203/theta/'+monthlong+'/Full_data/thetafull'+month+UTC[i]+'.nc')\n",
    "        # xr.DataArray(thetamean).to_netcdf(path='/g/data/k10/lr0203/theta/'+monthlong+'/Data/theta'+month+UTC[i]+'.nc')\n",
    "theta(octstart[0],octstop[0],octstart[1],octstop[1],month[9],monthlong[9])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f1f302-77b9-4221-87bb-1be8c3f20a55",
   "metadata": {},
   "source": [
    "# Plotting and testing june case study data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837eb33d-0bbd-4e37-b18f-2dec2f5b1f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "q02 = xr.open_dataset('/g/data5/rt52/era5/pressure-levels/reanalysis/q/2010/q_era5_oper_pl_20150101-20150131.nc')['q'].loc[:,925,-10:-30,110:155]\n",
    "z98 = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/z/2015/z_era5_oper_pl_20150101-20150131.nc')['z'].loc[:,925,-10:-30,110:155]\n",
    "u = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/u/2015/u_era5_oper_pl_20150101-20150131.nc')['u'].loc[:,925,-10:-30,110:155]\n",
    "v = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/v/2015/v_era5_oper_pl_20150101-20150131.nc')['v'].loc[:,925,-10:-30,110:155]\n",
    "pcp = xr.open_mfdataset('/g/data5/rt52/era5/single-levels/reanalysis/mtpr/2015/mtpr_era5_oper_sfc_20150101-20150131.nc')['mtpr'].loc[:,-10:-30,110:155]\n",
    "d = xr.open_mfdataset('/g/data/rt52/era5/pressure-levels/reanalysis/d/2015/d_era5_oper_pl_20150101-20150131.nc')['d'].loc[:,925,-10:-30,110:155]\n",
    "# q02[264]\n",
    "# q02[287]\n",
    "qgrad1=[[] for x in range(24)]\n",
    "z = [[] for x in range(24)]\n",
    "ui = [[] for x in range(24)]\n",
    "vi=[[] for x in range(24)]\n",
    "pcpi=[[] for x in range(24)]\n",
    "di=[[] for x in range(24)]\n",
    "for k in range(30,31): #day\n",
    "    for j in range(0,24):\n",
    "    #calculate gradq            \n",
    "        dqdy = np.gradient(q02[j+(k*24)], lat_r, axis=0)/r\n",
    "        dqdx = np.gradient(q02[j+(k*24)], lon_r, axis=1)/(r*np.cos(lat_r).data[:,np.newaxis])\n",
    "        qgrad1[j] = np.sqrt((dqdy) ** 2 + (dqdx) ** 2)*1000\n",
    "        # (qgrad1)[j][qgrad1[j]<(0.00006)]=0\n",
    "        z[j]=z98[j+(k*24)]\n",
    "        ui[j]=u[j+(k*24)]\n",
    "        vi[j]=v[j+(k*24)]\n",
    "        pcpi[j]=pcp[j+(k*24)]\n",
    "        di[j]=d[j+(k*24)]\n",
    "        \n",
    "        ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "        lon_grid = np.arange(110,155,5)\n",
    "        lat_grid = np.arange(-30,-10,5)\n",
    "        gl = ax.gridlines(draw_labels=True,xlocs=lon_grid,ylocs=lat_grid,\n",
    "                  x_inline=False,y_inline=False,color='k',linestyle='--',linewidth=0.4)\n",
    "        gl.top_labels = False\n",
    "        gl.right_labels = False\n",
    "        plt.title(UTC[j])\n",
    "        # conv = plt.contourf(qlon, qlat, di[j],levels=[-10e-5,-8e-5,-6e-5,-4e-5,-2e-5,-1e-5], colors=['darkred','firebrick','crimson','red','darkorange','khaki','white'],extend='both')\n",
    "\n",
    "        grad = plt.contourf(qlon, qlat, qgrad1[j],levels=[3e-5,4e-5,5e-5,6e-5,7e-5,8e-5],cmap='Blues',extend='max')\n",
    "        kw_clabels = {'fontsize': 11, 'inline': True, 'inline_spacing': 5, 'fmt': '%i',\n",
    "                     'rightside_up': True, 'use_clabeltext': True}\n",
    "        mslp = plt.contour(qlon,qlat,z[j], colors='black')\n",
    "        plt.clabel(mslp, **kw_clabels)\n",
    "        plt.colorbar(grad, orientation='horizontal', label='Specific Humidity (g/Kg m)')\n",
    "        ax.coastlines()\n",
    "        plt.show()\n",
    "        # xr.DataArray(z[j],dims=[\"latitude\",\"longitude\"],coords=dict(latitude=qlat,longitude=qlon)).to_netcdf(path='/g/data/k10/lr0203/JUNcasestudy/z/z21062010'+UTC[j]+'.nc')\n",
    "        # xr.DataArray(ui[j],dims=[\"latitude\",\"longitude\"],coords=dict(latitude=qlat,longitude=qlon)).to_netcdf(path='/g/data/k10/lr0203/JUNcasestudy/u/u21062010'+UTC[j]+'.nc')\n",
    "        # xr.DataArray(vi[j],dims=[\"latitude\",\"longitude\"],coords=dict(latitude=qlat,longitude=qlon)).to_netcdf(path='/g/data/k10/lr0203/JUNcasestudy/v/v21062010'+UTC[j]+'.nc')\n",
    "        # xr.DataArray(qgrad1[j],dims=[\"latitude\",\"longitude\"],coords=dict(latitude=qlat,longitude=qlon)).to_netcdf(path='/g/data/k10/lr0203/JUNcasestudy/qgrad/qgrad21062010'+UTC[j]+'.nc')\n",
    "        # xr.DataArray(pcpi[j],dims=[\"latitude\",\"longitude\"],coords=dict(latitude=qlat,longitude=qlon)).to_netcdf(path='/g/data/k10/lr0203/JUNcasestudy/pcp/pcp21062010'+UTC[j]+'.nc')\n",
    "        # xr.DataArray(di[j],dims=[\"latitude\",\"longitude\"],coords=dict(latitude=qlat,longitude=qlon)).to_netcdf(path='/g/data/k10/lr0203/JUNcasestudy/d/d21062010'+UTC[j]+'.nc')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1f80f2-cd3e-4643-a39e-965fa53b6a08",
   "metadata": {},
   "source": [
    "# Frontogenesis for June case study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f71d1a-0f33-4388-9c58-1c0a814eea5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = xr.open_dataset('/g/data5/rt52/era5/pressure-levels/reanalysis/q/2010/q_era5_oper_pl_20100601-20100630.nc')['q'].loc[:,925,-10:-30,110:155]\n",
    "z = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/z/2010/z_era5_oper_pl_20100601-20100630.nc')['z'].loc[:,925,-10:-30,110:155]\n",
    "u = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/u/2010/u_era5_oper_pl_20100601-20100630.nc')['u'].loc[:,925,-10:-30,110:155]\n",
    "v = xr.open_mfdataset('/g/data5/rt52/era5/pressure-levels/reanalysis/v/2010/v_era5_oper_pl_20100601-20100630.nc')['v'].loc[:,925,-10:-30,110:155]\n",
    "gradq=[[] for x in range(24)]\n",
    "D = [[] for x in range(24)]\n",
    "E = [[] for x in range(24)]\n",
    "F=[[] for x in range(24)]\n",
    "Eprime=[[] for x in range(24)]\n",
    "alpha=[[] for x in range(24)]\n",
    "delta=[[] for x in range(24)]\n",
    "beta=[[] for x in range(24)]\n",
    "frontogenesis=[[] for x in range(24)]\n",
    "for k in range(22,23): #day\n",
    "    for j in range(0,24):\n",
    "        dqdy = np.gradient(q[j+(k*24)], lat_r, axis=0)/r\n",
    "        dqdx = np.gradient(q[j+(k*24)], lon_r, axis=1)/(r*np.cos(lat_r).data[:,np.newaxis])\n",
    "        gradq[j] = np.sqrt((dqdy) ** 2 + (dqdx) ** 2)*1000\n",
    "        # calculate D\n",
    "        vcos = v[j+(k*24)]*(np.cos(lat_r))\n",
    "        dudx = np.gradient(u[j+(k*24)], lon_r, axis=1) / (r * np.cos(lat_r).data[:, np.newaxis])\n",
    "        dDdy = (np.gradient(vcos, lat_r, axis=0) / r)/(np.cos(lat_r).data[:, np.newaxis])\n",
    "        D[j] = dudx + dDdy\n",
    "        #calculate E\n",
    "        v_cos = v[j+(k*24)]/(np.cos(lat_r))\n",
    "        dEdy = (np.gradient(v_cos, lat_r, axis=0) / r)*(np.cos(lat_r).data[:,np.newaxis])\n",
    "        E[j] = dudx - dEdy\n",
    "        #calculate F\n",
    "        dvdx = np.gradient(v[j+(k*24)], lon_r, axis=1) / (r * np.cos(lat_r).data[:, np.newaxis])\n",
    "        u_cos = u[j+(k*24)]/(np.cos(lat_r))\n",
    "        dFdy = (np.gradient(u_cos, lat_r, axis=0) / r)*(np.cos(lat_r).data[:, np.newaxis])\n",
    "        F[j] = dvdx + dFdy\n",
    "        #calculate E'\n",
    "        Eprime[j] = np.sqrt(E[j]**2 +F[j]**2)\n",
    "        #calculate alpha\n",
    "        angle=dqdx/dqdy\n",
    "        (angle)[np.isposinf(angle)]=(np.pi/2)\n",
    "        (angle)[np.isneginf(angle)]=-(np.pi/2)\n",
    "        alpha[j] = np.arctan(-(angle))\n",
    "        #calculate delta\n",
    "        delta[j] = (np.arctan(F[j]/E[j]))/2\n",
    "        #calculate beta\n",
    "        beta[j] = delta[j]-alpha[j]\n",
    "        #calculate frontogenesis\n",
    "        frontogenesis[j] = (np.absolute(gradq[j])*(D[j]-Eprime[j]*np.cos(2*beta[j])))/2\n",
    "        xr.DataArray(D[j],dims=[\"latitude\",\"longitude\"],coords=dict(latitude=qlat,longitude=qlon)).to_netcdf(path='/g/data/k10/lr0203/JUNcasestudy/frontogenesis/D/D22062010'+UTC[j]+'.nc')\n",
    "        xr.DataArray(E[j],dims=[\"latitude\",\"longitude\"],coords=dict(latitude=qlat,longitude=qlon)).to_netcdf(path='/g/data/k10/lr0203/JUNcasestudy/frontogenesis/E/E22062010'+UTC[j]+'.nc')\n",
    "        xr.DataArray(F[j],dims=[\"latitude\",\"longitude\"],coords=dict(latitude=qlat,longitude=qlon)).to_netcdf(path='/g/data/k10/lr0203/JUNcasestudy/frontogenesis/F/F22062010'+UTC[j]+'.nc')\n",
    "        xr.DataArray(Eprime[j],dims=[\"latitude\",\"longitude\"],coords=dict(latitude=qlat,longitude=qlon)).to_netcdf(path='/g/data/k10/lr0203/JUNcasestudy/frontogenesis/Eprime/Eprime22062010'+UTC[j]+'.nc')\n",
    "        xr.DataArray(alpha[j],dims=[\"latitude\",\"longitude\"],coords=dict(latitude=qlat,longitude=qlon)).to_netcdf(path='/g/data/k10/lr0203/JUNcasestudy/frontogenesis/alpha/alpha22062010'+UTC[j]+'.nc')\n",
    "        xr.DataArray(delta[j],dims=[\"latitude\",\"longitude\"],coords=dict(latitude=qlat,longitude=qlon)).to_netcdf(path='/g/data/k10/lr0203/JUNcasestudy/frontogenesis/delta/delta22062010'+UTC[j]+'.nc')\n",
    "        xr.DataArray(beta[j],dims=[\"latitude\",\"longitude\"],coords=dict(latitude=qlat,longitude=qlon)).to_netcdf(path='/g/data/k10/lr0203/JUNcasestudy/frontogenesis/beta/beta22062010'+UTC[j]+'.nc')\n",
    "        xr.DataArray(frontogenesis[j],dims=[\"latitude\",\"longitude\"],coords=dict(latitude=qlat,longitude=qlon)).to_netcdf(path='/g/data/k10/lr0203/JUNcasestudy/frontogenesis/Fn/Fn22062010'+UTC[j]+'.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fee0513-4d9c-46b6-8771-27afadaf5599",
   "metadata": {},
   "source": [
    "# Calculate vertical cross section variables (variables often changed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fc2359-3f1b-4369-8fed-563631aad0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#potential temperature monthly average\n",
    "def vertcross(start,stop,lystart,lystop,month,monthlong):\n",
    "    for i in range(8,9): #hour loop\n",
    "        time = [t90,t91,t92,t93,t94,t95,t96,t97,t98,t99,\n",
    "                t00,t01,t02,t03,t04,t05,t06,t07,t08,t09,\n",
    "                t10,t11,t12,t13,t14,t15,t16,t17,t18,t19,t20] = [temp90[i::24],temp91[i::24],temp92[i::24],temp93[i::24],\n",
    "                                                                temp94[i::24],temp95[i::24],temp96[i::24],temp97[i::24],\n",
    "                                                                temp98[i::24],temp99[i::24],temp00[i::24],temp01[i::24],\n",
    "                                                                temp02[i::24],temp03[i::24],temp04[i::24],temp05[i::24],\n",
    "                                                                temp06[i::24],temp07[i::24],temp08[i::24],temp09[i::24],\n",
    "                                                                temp10[i::24],temp11[i::24],temp12[i::24],temp13[i::24],\n",
    "                                                                temp14[i::24],temp15[i::24],temp16[i::24],temp17[i::24],\n",
    "                                                                temp18[i::24],temp19[i::24],temp20[i::24]]\n",
    "        thour =  xr.concat([t90[start:stop],t91[start:stop],t92[lystart:lystop],t93[start:stop],t94[start:stop],t95[start:stop],t96[lystart:lystop],t97[start:stop],\n",
    "                t98[start:stop],t99[start:stop],t00[lystart:lystop],t01[start:stop],t02[start:stop],t03[start:stop],t04[lystart:lystop],t05[start:stop],\n",
    "                t06[start:stop],t07[start:stop],t08[lystart:lystop],t09[start:stop],t10[start:stop],t11[start:stop],t12[lystart:lystop],t13[start:stop],\n",
    "                t14[start:stop],t15[start:stop],t16[lystart:lystop],t17[start:stop],t18[start:stop],t19[start:stop],t20[lystart:lystop]],dim='time')\n",
    "          \n",
    "        mean = thour.mean(dim='time')\n",
    "        # pot=mean*(1000/temp19.level)**0.286\n",
    "        #pot_temp=xr.DataArray(pot)\n",
    "        xr.DataArray(thour).to_netcdf(path='/g/data/k10/lr0203/16S-110-130E/q/'+monthlong+'/V16-110-130q'+month+UTC[i]+'.nc')\n",
    "        # xr.DataArray(pot).to_netcdf(path='/g/data/k10/lr0203/16S-110-130E/theta/'+monthlong+'/V16-110-130theta'+month+UTC[i]+'.nc')\n",
    "        #xr.DataArray(pot_temp,dims=[\"level\",\"latitude\"],coords=dict(level=lvl,latitude=lat)).to_netcdf(path='/g/data/k10/lr0203/117E-10-30S/theta/'+monthlong+'/Data/V117-10-30theta'+month+UTC[i]+'.nc')\n",
    "vertcross(junstart[0],junstop[0],junstart[1],junstop[1],month[5],monthlong[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246e0c81-253d-46b8-8de0-4d9c38a9e5c6",
   "metadata": {},
   "source": [
    "# Dryline associated precipitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cde16a40-b570-4fda-b0a1-ab6163b00425",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pcp and dryline \n",
    "# feb is 876??\n",
    "#31x31=961\n",
    "#31x30=930\n",
    "#adjust condition to 0.00004\n",
    "def pcpdryline(start,stop,lystart,lystop,month,monthlong):\n",
    "    dryline=[[] for x in range(930)]\n",
    "    buffer=[[] for x in range(930)]\n",
    "    for i in range(0,24): #hour loop\n",
    "        mtpr_mean = xr.open_dataarray('/g/data/k10/lr0203/MTPR/'+monthlong+'/Data/mtpr'+month+UTC[i]+'.nc')\n",
    "        qtime = [tq90,tq91,tq92,tq93,tq94,tq95,tq96,tq97,tq98,tq99,\n",
    "                tq00,tq01,tq02,tq03,tq04,tq05,tq06,tq07,tq08,tq09,\n",
    "                tq10,tq11,tq12,tq13,tq14,tq15,tq16,tq17,tq18,tq19,tq20] = [q90[i::24],q91[i::24],q92[i::24],q93[i::24],\n",
    "                                                                q94[i::24],q95[i::24],q96[i::24],q97[i::24],\n",
    "                                                                q98[i::24],q99[i::24],q00[i::24],q01[i::24],\n",
    "                                                                q02[i::24],q03[i::24],q04[i::24],q05[i::24],\n",
    "                                                                q06[i::24],q07[i::24],q08[i::24],q09[i::24],\n",
    "                                                                q10[i::24],q11[i::24],q12[i::24],q13[i::24],\n",
    "                                                                q14[i::24],q15[i::24],q16[i::24],q17[i::24],\n",
    "                                                                q18[i::24],q19[i::24],q20[i::24]]\n",
    "        qhour =  xr.concat([tq90[start:stop],tq91[start:stop],tq92[lystart:lystop],tq93[start:stop],tq94[start:stop],tq95[start:stop],tq96[lystart:lystop],tq97[start:stop],\n",
    "                tq98[start:stop],tq99[start:stop],tq00[lystart:lystop],tq01[start:stop],tq02[start:stop],tq03[start:stop],tq04[lystart:lystop],tq05[start:stop],\n",
    "                tq06[start:stop],tq07[start:stop],tq08[lystart:lystop],tq09[start:stop],tq10[start:stop],tq11[start:stop],tq12[lystart:lystop],tq13[start:stop],\n",
    "                tq14[start:stop],tq15[start:stop],tq16[lystart:lystop],tq17[start:stop],tq18[start:stop],tq19[start:stop],tq20[lystart:lystop]],dim='time')\n",
    "        \n",
    "        pcptime = [t90,t91,t92,t93,t94,t95,t96,t97,t98,t99,\n",
    "                t00,t01,t02,t03,t04,t05,t06,t07,t08,t09,\n",
    "                t10,t11,t12,t13,t14,t15,t16,t17,t18,t19,t20] = [mtpr90[i::24],mtpr91[i::24],mtpr92[i::24],mtpr93[i::24],\n",
    "                                                                mtpr94[i::24],mtpr95[i::24],mtpr96[i::24],mtpr97[i::24],\n",
    "                                                                mtpr98[i::24],mtpr99[i::24],mtpr00[i::24],mtpr01[i::24],\n",
    "                                                                mtpr02[i::24],mtpr03[i::24],mtpr04[i::24],mtpr05[i::24],\n",
    "                                                                mtpr06[i::24],mtpr07[i::24],mtpr08[i::24],mtpr09[i::24],\n",
    "                                                                mtpr10[i::24],mtpr11[i::24],mtpr12[i::24],mtpr13[i::24],\n",
    "                                                                mtpr14[i::24],mtpr15[i::24],mtpr16[i::24],mtpr17[i::24],\n",
    "                                                                mtpr18[i::24],mtpr19[i::24],mtpr20[i::24]]\n",
    "        pcp =  xr.concat([t90[start:stop],t91[start:stop],t92[lystart:lystop],t93[start:stop],t94[start:stop],t95[start:stop],t96[lystart:lystop],t97[start:stop],\n",
    "                t98[start:stop],t99[start:stop],t00[lystart:lystop],t01[start:stop],t02[start:stop],t03[start:stop],t04[lystart:lystop],t05[start:stop],\n",
    "                t06[start:stop],t07[start:stop],t08[lystart:lystop],t09[start:stop],t10[start:stop],t11[start:stop],t12[lystart:lystop],t13[start:stop],\n",
    "                t14[start:stop],t15[start:stop],t16[lystart:lystop],t17[start:stop],t18[start:stop],t19[start:stop],t20[lystart:lystop]],dim='time')\n",
    "        for j in range(0,930): #year(31) x month loop \n",
    "            dfdy = np.gradient(qhour[j], lat_r, axis=0)/r\n",
    "            dfdx = np.gradient(qhour[j], lon_r, axis=1)/(r*np.cos(lat_r).data[:,np.newaxis])\n",
    "            dryline[j] = np.sqrt((dfdy) ** 2 + (dfdx) ** 2)*1000\n",
    "            (dryline)[j][dryline[j]<(0.00006)]=0\n",
    "            (dryline)[j][dryline[j]>=(0.00006)]=1\n",
    "            buffer[j]=scind.binary_dilation(dryline[j], structure=None, iterations=4) #increase dryline by 1degree (4x0.25)\n",
    "            pcp_dryline=(pcp[j]*buffer[j]).compute()\n",
    "            if j==0:\n",
    "                tot_pcp_dryline=pcp_dryline\n",
    "            if j>0:\n",
    "                tot_pcp_dryline=tot_pcp_dryline+pcp_dryline\n",
    "\n",
    "        av_pcp_dryline = tot_pcp_dryline/(mtpr_mean*930)\n",
    "        xr.DataArray(tot_pcp_dryline,dims=[\"latitude\",\"longitude\"],coords=dict(latitude=qlat,longitude=qlon)).to_netcdf(path='/g/data/k10/lr0203/pcpbuffer/'+monthlong+'/tot_pcp_dryline/tot_pcp_dry'+month+UTC[i]+'.nc')\n",
    "        xr.DataArray(av_pcp_dryline,dims=[\"latitude\",\"longitude\"],coords=dict(latitude=qlat,longitude=qlon)).to_netcdf(path='/g/data/k10/lr0203/pcpbuffer/'+monthlong+'/av_pcp_dryline/av_pcp_dry'+month+UTC[i]+'.nc')\n",
    "pcpdryline(novstart[0],novstop[0],novstart[1],novstop[1],month[10],monthlong[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97486ed-f429-4676-8e8b-7995f7ed3884",
   "metadata": {},
   "source": [
    "# Start plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1171845-41fc-4ac7-b7f4-6a6734a90d95",
   "metadata": {},
   "source": [
    "**Early plotting practice of single panels and unused variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "afd294a1-761d-486e-a0fd-4bb5f34b92ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting function for convergence/divergence higher interval\n",
    "for j in range(11,12):\n",
    "    monthlong = [\"January\",\"February\",\"March\",\"April\",\"May\",\"June\",\"July\",\"August\",\"September\",\"October\",\"November\",\"December\"]\n",
    "    def plotting(monthshort,monthlong):\n",
    "        for i in range(0,24): #hour loop\n",
    "            meangrad = xr.open_dataarray('/g/data/k10/lr0203/Convergence/'+monthlong+'/Data/conv'+monthshort+UTC[i]+'.nc')\n",
    "            meangrad1 = np.clip(meangrad,-0.000031,0.000031)\n",
    "            ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "            plt.title('mean Divergence '+UTC[i]+'UTC '+monthshort+' 1990-2020')\n",
    "            ax.set_extent([110, 155, -30, -10], ccrs.PlateCarree())\n",
    "            ax.coastlines()\n",
    "            lon_grid = np.arange(110,155,5)\n",
    "            lat_grid = np.arange(-30,-10,5)\n",
    "            gl = ax.gridlines(draw_labels=True,xlocs=lon_grid,ylocs=lat_grid,\n",
    "                      x_inline=False,y_inline=False,color='k',linestyle='--',linewidth=0.4)\n",
    "            gl.top_labels = False\n",
    "            gl.right_labels = False\n",
    "            grad = plt.contourf(lon, lat, meangrad1,14, transform=ccrs.PlateCarree(), colors=['darkred','firebrick','crimson','red','darkorange','khaki','white','white','powderblue','skyblue','cornflowerblue','royalblue','mediumblue','darkblue'],vmin=-0.00003,vmax=0.00003,extend='both')\n",
    "            plt.colorbar(grad, spacing='proportional',orientation='horizontal', label='Divergence ($s^{-1}$)',ticks=[-0.00003,-0.000025,-0.00002,-0.000015,-0.00001,-0.000005,0,0.000005,0.00001,0.000015,0.00002,0.000025,0.00003])\n",
    "            save_results_to = '/g/data/k10/lr0203/Convergence/'+monthlong+'/conv-div/'\n",
    "            plt.savefig(save_results_to+monthshort+'convdiv-'+UTC[i]+'-90-20.jpg')\n",
    "            #plt.show()\n",
    "            plt.close()\n",
    "    plotting(month[j],monthlong[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64357e57-b853-4365-ab02-61096fc15fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting function for convergence\n",
    "monthlong = [\"January\",\"February\",\"March\",\"April\",\"May\",\"June\",\"July\",\"August\",\"September\",\"October\",\"November\",\"December\"]\n",
    "def plotting(monthshort,monthlong):\n",
    "    for i in range(0,24): #hour loop\n",
    "        meangrad = xr.open_dataarray('/g/data/k10/lr0203/Convergence/'+monthlong+'/Data/conv'+monthshort+UTC[i]+'.nc')\n",
    "        meangrad1 = np.clip(meangrad,-0.00005,0)\n",
    "        ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "        plt.title('mean Convergence '+UTC[i]+'UTC '+monthshort+' 1990-2020')\n",
    "        ax.set_extent([110, 155, -30, -10], ccrs.PlateCarree())\n",
    "        ax.coastlines()\n",
    "        lon_grid = np.arange(110,155,5)\n",
    "        lat_grid = np.arange(-30,-10,5)\n",
    "        gl = ax.gridlines(draw_labels=True,xlocs=lon_grid,ylocs=lat_grid,\n",
    "                  x_inline=False,y_inline=False,color='k',linestyle='--',linewidth=0.4)\n",
    "        gl.top_labels = False\n",
    "        gl.right_labels = False\n",
    "        grad = plt.contourf(lon, lat, meangrad1,4, transform=ccrs.PlateCarree(), colors=['black','crimson','darkorange','khaki','white'],vmax=-0.00002,vmin=-0.00003,extend='min')\n",
    "        plt.colorbar(grad, orientation='horizontal', label='Convergence ($s^{-1}$)',ticks=[-0.00004,-0.00003,-0.00002,-0.00001,0])\n",
    "        save_results_to = '/g/data/k10/lr0203/Convergence/'+monthlong+'/conv-plt/'\n",
    "        plt.savefig(save_results_to+monthshort+'conv-'+UTC[i]+'-90-20.jpg')\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "plotting(month[11],monthlong[11])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d4832e-ccb4-4a3a-90e1-100025229dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting function for convergence/divergence\n",
    "for j in range(0,12):\n",
    "    monthlong = [\"January\",\"February\",\"March\",\"April\",\"May\",\"June\",\"July\",\"August\",\"September\",\"October\",\"November\",\"December\"]\n",
    "    def plotting(monthshort,monthlong):\n",
    "        for i in range(0,24): #hour loop\n",
    "            meangrad = xr.open_dataarray('/g/data/k10/lr0203/Convergence/'+monthlong+'/Data/conv'+monthshort+UTC[i]+'.nc')\n",
    "            meangrad1 = np.clip(meangrad,-0.00003,0)\n",
    "            ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "            plt.title('mean Convergence '+UTC[i]+'UTC '+monthshort+' 1990-2020')\n",
    "            ax.set_extent([110, 155, -30, -10], ccrs.PlateCarree())\n",
    "            ax.coastlines()\n",
    "            lon_grid = np.arange(110,155,5)\n",
    "            lat_grid = np.arange(-30,-10,5)\n",
    "            gl = ax.gridlines(draw_labels=True,xlocs=lon_grid,ylocs=lat_grid,\n",
    "                      x_inline=False,y_inline=False,color='k',linestyle='--',linewidth=0.4)\n",
    "            gl.top_labels = False\n",
    "            gl.right_labels = False\n",
    "            grad = plt.contourf(lon, lat, meangrad1,5, transform=ccrs.PlateCarree(), colors=['black','darkred','crimson','darkorange','khaki','white'],extend='min')\n",
    "            plt.colorbar(grad, spacing='proportional',orientation='horizontal', label='Convergence ($s^{-1}$)',ticks=[-0.000025,-0.00002,-0.000015,-0.00001,-0.000005,0])\n",
    "            save_results_to = '/g/data/k10/lr0203/Convergence/'+monthlong+'/conv-plt-lower-int/'\n",
    "            #plt.savefig(save_results_to+monthshort+'conv-'+UTC[i]+'-90-20.jpg')\n",
    "            #plt.show()\n",
    "            #plt.close()\n",
    "    plotting(month[j],monthlong[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "625ddcc3-9ead-4e63-abac-02476c2407e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "monthlong = [\"January\",\"February\",\"March\",\"April\",\"May\",\"June\",\"July\",\"August\",\"September\",\"October\",\"November\",\"December\"]\n",
    "for j in range(2,12): #month loop\n",
    "    def plotting(monthshort,monthlong):\n",
    "        for i in range(0,24): #hour loop\n",
    "            uageo = xr.open_dataarray('/g/data/k10/lr0203/Winds/uageo-data/'+monthlong+'/uageo'+monthshort+UTC[i]+'mean.nc')\n",
    "            vageo = xr.open_dataarray('/g/data/k10/lr0203/Winds/vageo-data/'+monthlong+'/vageo'+monthshort+UTC[i]+'mean.nc')\n",
    "            zmean = xr.open_dataarray('/g/data/k10/lr0203/Winds/geopotential-data/'+monthlong+'/zmean'+monthshort+UTC[i]+'.nc')\n",
    "            ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "            plt.title('mean Ageostrophic Winds and Geopotenital Height \\n'+UTC[i]+'UTC '+monthshort+' 1990-2020')\n",
    "            ax.set_extent([110, 155, -30, -10], ccrs.PlateCarree())\n",
    "            ax.coastlines()\n",
    "            lons, lats = np.meshgrid(lon, lat)\n",
    "            lon_grid = np.arange(110,155,5)\n",
    "            lat_grid = np.arange(-30,-10,5)\n",
    "            gl = ax.gridlines(draw_labels=True,xlocs=lon_grid,ylocs=lat_grid,\n",
    "                      x_inline=False,y_inline=False,color='k',linestyle='--',linewidth=0.4)\n",
    "            gl.top_labels = False\n",
    "            gl.right_labels = False\n",
    "            quiver_slices = (slice(None, None, 6), slice(None, None, 6))\n",
    "            kw_clabels = {'fontsize': 11, 'inline': True, 'inline_spacing': 5, 'fmt': '%i',\n",
    "                      'rightside_up': True, 'use_clabeltext': True}\n",
    "            mslp = plt.contour(lons,lats,zmean, colors='darkblue') #mslp contours\n",
    "            plt.clabel(mslp, **kw_clabels)\n",
    "            Q = ax.quiver(lons[quiver_slices],lats[quiver_slices],uageo[quiver_slices],vageo[quiver_slices])\n",
    "            #ax.quiverkey(Q, 1.07, 0.8, 5, r'$1 \\frac{m}{s}$',labelpos='N')\n",
    "            save_results_to = '/g/data/k10/lr0203/Winds/ageo-plt/'+monthlong+'/'\n",
    "            plt.savefig(save_results_to+monthshort+'ageo-'+UTC[i]+'-90-20.jpg')\n",
    "            #plt.show()\n",
    "            plt.close()\n",
    "    plotting(month[j],monthlong[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c7ee7664-0c14-4751-9c7a-dd94b696c88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for j in range(0,12):\n",
    "    def sstplotting(monthshort,monthlong):\n",
    "\n",
    "        sst00 = xr.open_dataarray('/g/data/k10/lr0203/SST/'+monthlong+'/Data/sst'+monthshort+'0000.nc')\n",
    "        sst01 = xr.open_dataarray('/g/data/k10/lr0203/SST/'+monthlong+'/Data/sst'+monthshort+'0100.nc')\n",
    "        sst02 = xr.open_dataarray('/g/data/k10/lr0203/SST/'+monthlong+'/Data/sst'+monthshort+'0200.nc')\n",
    "        sst03 = xr.open_dataarray('/g/data/k10/lr0203/SST/'+monthlong+'/Data/sst'+monthshort+'0300.nc')\n",
    "        sst04 = xr.open_dataarray('/g/data/k10/lr0203/SST/'+monthlong+'/Data/sst'+monthshort+'0400.nc')\n",
    "        sst05 = xr.open_dataarray('/g/data/k10/lr0203/SST/'+monthlong+'/Data/sst'+monthshort+'0500.nc')\n",
    "        sst06 = xr.open_dataarray('/g/data/k10/lr0203/SST/'+monthlong+'/Data/sst'+monthshort+'0600.nc')\n",
    "        sst07 = xr.open_dataarray('/g/data/k10/lr0203/SST/'+monthlong+'/Data/sst'+monthshort+'0700.nc')\n",
    "        sst08 = xr.open_dataarray('/g/data/k10/lr0203/SST/'+monthlong+'/Data/sst'+monthshort+'0800.nc')\n",
    "        sst09 = xr.open_dataarray('/g/data/k10/lr0203/SST/'+monthlong+'/Data/sst'+monthshort+'0900.nc')\n",
    "        sst10 = xr.open_dataarray('/g/data/k10/lr0203/SST/'+monthlong+'/Data/sst'+monthshort+'1000.nc')\n",
    "        sst11 = xr.open_dataarray('/g/data/k10/lr0203/SST/'+monthlong+'/Data/sst'+monthshort+'1100.nc')\n",
    "        sst12 = xr.open_dataarray('/g/data/k10/lr0203/SST/'+monthlong+'/Data/sst'+monthshort+'1200.nc')\n",
    "        sst13 = xr.open_dataarray('/g/data/k10/lr0203/SST/'+monthlong+'/Data/sst'+monthshort+'1300.nc')\n",
    "        sst14 = xr.open_dataarray('/g/data/k10/lr0203/SST/'+monthlong+'/Data/sst'+monthshort+'1400.nc')\n",
    "        sst15 = xr.open_dataarray('/g/data/k10/lr0203/SST/'+monthlong+'/Data/sst'+monthshort+'1500.nc')\n",
    "        sst16 = xr.open_dataarray('/g/data/k10/lr0203/SST/'+monthlong+'/Data/sst'+monthshort+'1600.nc')\n",
    "        sst17 = xr.open_dataarray('/g/data/k10/lr0203/SST/'+monthlong+'/Data/sst'+monthshort+'1700.nc')\n",
    "        sst18 = xr.open_dataarray('/g/data/k10/lr0203/SST/'+monthlong+'/Data/sst'+monthshort+'1800.nc')\n",
    "        sst19 = xr.open_dataarray('/g/data/k10/lr0203/SST/'+monthlong+'/Data/sst'+monthshort+'1900.nc')\n",
    "        sst20 = xr.open_dataarray('/g/data/k10/lr0203/SST/'+monthlong+'/Data/sst'+monthshort+'2000.nc')\n",
    "        sst21 = xr.open_dataarray('/g/data/k10/lr0203/SST/'+monthlong+'/Data/sst'+monthshort+'2100.nc')\n",
    "        sst22 = xr.open_dataarray('/g/data/k10/lr0203/SST/'+monthlong+'/Data/sst'+monthshort+'2200.nc')\n",
    "        sst23 = xr.open_dataarray('/g/data/k10/lr0203/SST/'+monthlong+'/Data/sst'+monthshort+'2300.nc')\n",
    "        sst = [sst00,sst01,sst02,sst03,sst04,sst05,sst06,sst07,sst08,sst09,sst10,sst11,sst12,sst13,sst14,sst15,sst16,sst17,sst18,sst19,sst20,sst21,sst22,sst23]\n",
    "        totmeansst = np.mean(sst,axis=0)\n",
    "        celciussst = totmeansst-273.15\n",
    "        ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "        plt.title('Mean monthly SST '+month[j]+' 1990-2020')\n",
    "        ax.set_extent([110, 155, -30, -10], ccrs.PlateCarree())\n",
    "        \n",
    "        lon_grid = np.arange(110,155,5)\n",
    "        lat_grid = np.arange(-30,-10,5)\n",
    "        gl = ax.gridlines(draw_labels=True,xlocs=lon_grid,ylocs=lat_grid,\n",
    "                  x_inline=False,y_inline=False,color='k',linestyle='--',linewidth=0.4)\n",
    "        gl.top_labels = False\n",
    "        gl.right_labels = False\n",
    "        grad = plt.contourf(lon, lat, celciussst,6, transform=ccrs.PlateCarree(),cmap='coolwarm',extend='both')\n",
    "        plt.colorbar(grad, orientation='horizontal', label='Temperature ($^\\circ$C)')\n",
    "        ax.coastlines()\n",
    "        save_results_to = '/g/data/k10/lr0203/SST/'+monthlong+'/'\n",
    "        plt.savefig(save_results_to+'sst'+monthshort+'-90-20.jpg')\n",
    "        plt.close()\n",
    "\n",
    "    sstplotting(month[j],monthlong[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "25e0c14c-388a-4f16-85d4-ff94e5b66ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting function modified for 3 intervals\n",
    "monthlong = [\"January\",\"February\",\"March\",\"April\",\"May\",\"June\",\"July\",\"August\",\"September\",\"October\",\"November\",\"December\"]\n",
    "def plotting(monthshort,monthlong):\n",
    "    for i in range(0,24): #hour loop\n",
    "        meangrad = xr.open_dataarray('/g/data/k10/lr0203/gradq/'+monthlong+'/data'+monthshort+UTC[i]+'.nc')\n",
    "        meangrad1 = np.clip(meangrad,0,0.000008)\n",
    "        ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "        plt.title('mean q '+UTC[i]+'UTC '+monthshort+' 1990-2020')\n",
    "        ax.set_extent([110, 155, -30, -10], ccrs.PlateCarree())\n",
    "        ax.coastlines()\n",
    "        lon_grid = np.arange(110,155,5)\n",
    "        lat_grid = np.arange(-30,-10,5)\n",
    "        gl = ax.gridlines(draw_labels=True,xlocs=lon_grid,ylocs=lat_grid,\n",
    "                  x_inline=False,y_inline=False,color='k',linestyle='--',linewidth=0.4)\n",
    "        gl.top_labels = False\n",
    "        gl.right_labels = False\n",
    "        grad = plt.contourf(lon, lat, meangrad1,3, transform=ccrs.PlateCarree(), cmap='Blues',vmin=0.000002,vmax=0.000006,extend='max')\n",
    "        plt.colorbar(grad, orientation='horizontal', label='Specific Humidity (g/Kg m)')\n",
    "        save_results_to = '/g/data/k10/lr0203/gradq/'+monthlong+'/3tier/'\n",
    "        plt.savefig(save_results_to+monthshort+'-'+UTC[i]+'-90-20-3tier.jpg')\n",
    "       # plt.show()\n",
    "        plt.close()\n",
    "plotting(month[9],monthlong[9])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f8bcc00-0ebf-45de-ae1b-5faa886111af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lowest 5km is about 840hPa which is lvl 30\n",
    "#500hpa starts at lvl 21\n",
    "lontemp = xr.open_mfdataset('/g/data/rt52/era5/pressure-levels/reanalysis/t/2020/t_era5_oper_pl_2020*')['t'].loc[:,500:1000,-13,120:150]\n",
    "lattemp = xr.open_mfdataset('/g/data/rt52/era5/pressure-levels/reanalysis/t/2020/t_era5_oper_pl_2020*')['t'].loc[:,500:1000,-10:-30,117]\n",
    "lat = lattemp.latitude\n",
    "lvl = lattemp.level\n",
    "lon = lontemp.longitude\n",
    "for i in range(9,10): #month\n",
    "    for j in range(0,24): #hour\n",
    "        data = xr.open_dataarray('/g/data/k10/lr0203/13S-120-150E/q/'+monthlong[i]+'/Data/V13-120-150q'+month[i]+UTC[j]+'.nc')\n",
    "        umean = xr.open_dataarray('/g/data/k10/lr0203/13S-120-150E/u/'+monthlong[i]+'/Data/V13-120-150u'+month[i]+UTC[j]+'.nc')\n",
    "        wmean = xr.open_dataarray('/g/data/k10/lr0203/13S-120-150E/w/'+monthlong[i]+'/Data/V13-120-150w'+month[i]+UTC[j]+'.nc')\n",
    "        u=umean\n",
    "        w=(wmean)/-11.76 #converts into m/s\n",
    "        # cel = data-273.15\n",
    "        spec_hum = data*1000\n",
    "        x, y = np.meshgrid(lon, lvl)\n",
    "        clip = np.clip(spec_hum,0,16)\n",
    "        horo = plt.contourf(lon, lvl,clip, 6,cmap='BrBG', extend='both')\n",
    "        quiver_slices = (slice(None, None, 2), slice(None, None, 6))\n",
    "        Q = plt.quiver(x[quiver_slices], y[quiver_slices], u[quiver_slices],100*w[quiver_slices])\n",
    "        plt.quiverkey(Q, 0.81, 0.92, 5, r'$5 \\frac{m}{s}$', labelpos='E',\n",
    "                   coordinates='figure',angle = 180, labelsep=0.2)\n",
    "\n",
    "        plt.gca().invert_yaxis()\n",
    "        plt.xlabel('Longitude ($^\\circ$)')\n",
    "        plt.ylabel('Pressure (hPa)')\n",
    "        plt.title('Vertical circulation along 13$^\\circ$S \\n'+month[i]+' '+UTC[j]+'UTC 1990-2020')\n",
    "        #plt.title('Vertical Cross Section '+month[i]+' '+UTC[j]+'UTC 1990-2020')\n",
    "        plt.colorbar(horo,orientation='horizontal', label='Specific Humidity (g/Kg)',pad=0.2)\n",
    "        save_results_to = '/g/data/k10/lr0203/13S-120-150E/q/'+monthlong[i]+'/Plot/'\n",
    "        plt.savefig(save_results_to+'13S-120-150Equw'+month[i]+UTC[j]+'.jpg')\n",
    "        plt.close()\n",
    "        # plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca753bee-704d-4dd1-91c7-8a8f4e926971",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(2,3):\n",
    "    monthlong = [\"January\",\"February\",\"March\",\"April\",\"May\",\"June\",\"July\",\"August\",\"September\",\"October\",\"November\",\"December\"]\n",
    "    def plotting(monthshort,monthlong):\n",
    "        for i in range(0,24): #hour loop\n",
    "            data = xr.open_dataarray('/g/data/k10/lr0203/MTPR/'+monthlong+'/Data/mtpr'+monthshort+UTC[i]+'.nc')\n",
    "            mmday=data*86400 \n",
    "            clip = np.clip(mmday,0,15)\n",
    "            ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "            plt.title('Mean Total Precipitation Rate '+UTC[i]+'UTC '+monthshort+' 1990-2020')\n",
    "            ax.set_extent([110, 155, -30, -10], ccrs.PlateCarree())\n",
    "            \n",
    "            lon_grid = np.arange(110,155,5)\n",
    "            lat_grid = np.arange(-30,-10,5)\n",
    "            gl = ax.gridlines(draw_labels=True,xlocs=lon_grid,ylocs=lat_grid,\n",
    "                      x_inline=False,y_inline=False,color='k',linestyle='--',linewidth=0.4)\n",
    "            gl.top_labels = False\n",
    "            gl.right_labels = False\n",
    "            grad = plt.contourf(qlon, qlat, clip,5, transform=ccrs.PlateCarree(), colors=['white','paleturquoise','mediumturquoise','lightseagreen','teal','darkslategrey'],vmax=12.5,extend='max')\n",
    "            plt.colorbar(grad, spacing='proportional',orientation='horizontal', label='rainfall (mm/day)')\n",
    "            ax.coastlines()\n",
    "            save_results_to = '/g/data/k10/lr0203/MTPR/'+monthlong+'/Plot/'\n",
    "            # plt.savefig(save_results_to+'mtpr'+monthshort+UTC[i]+'90-20.jpg')\n",
    "            plt.close()\n",
    "            # plt.show()\n",
    "    plotting(month[j],monthlong[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bdc29938-7f37-4c76-99d7-6ed2ca30c736",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lowest 5km is about 840hPa which is lvl 30\n",
    "#500hpa starts at lvl 21\n",
    "lontemp = xr.open_mfdataset('/g/data/rt52/era5/pressure-levels/reanalysis/t/2020/t_era5_oper_pl_2020*')['t'].loc[:,500:1000,-15,120:150]\n",
    "lattemp = xr.open_mfdataset('/g/data/rt52/era5/pressure-levels/reanalysis/t/2020/t_era5_oper_pl_2020*')['t'].loc[:,500:1000,-10:-30,117]\n",
    "lat = lattemp.latitude\n",
    "lvl = lattemp.level\n",
    "lon = lontemp.longitude\n",
    "for i in range(9,10): #month\n",
    "    for j in range(0,24): #hour\n",
    "        data = xr.open_dataarray('/g/data/k10/lr0203/15S-120-150E/theta/'+monthlong[i]+'/Data/V15-120-150theta'+month[i]+UTC[j]+'.nc')\n",
    "        umean = xr.open_dataarray('/g/data/k10/lr0203/15S-120-150E/u/'+monthlong[i]+'/Data/V15-120-150u'+month[i]+UTC[j]+'.nc')\n",
    "        wmean = xr.open_dataarray('/g/data/k10/lr0203/15S-120-150E/w/'+monthlong[i]+'/Data/V15-120-150w'+month[i]+UTC[j]+'.nc')\n",
    "        u=umean\n",
    "        w=(wmean)/-11.76 #converts into m/s\n",
    "        cel = data-273.15\n",
    "        #spec_hum = data*1000\n",
    "        x, y = np.meshgrid(lon, lvl)\n",
    "        #clip = np.clip(cel,26,51)\n",
    "        horo = plt.contourf(lon, lvl,cel, 6,cmap='coolwarm', extend='both')\n",
    "        quiver_slices = (slice(None, None, 2), slice(None, None, 6))\n",
    "        Q = plt.quiver(x[quiver_slices], y[quiver_slices], u[quiver_slices],100*w[quiver_slices])\n",
    "        plt.quiverkey(Q, 0.81, 0.92, 5, r'$5 \\frac{m}{s}$', labelpos='E',\n",
    "                   coordinates='figure',angle = 180, labelsep=0.3)\n",
    "\n",
    "        plt.gca().invert_yaxis()\n",
    "        plt.xlabel('Longitude ($^\\circ$)')\n",
    "        plt.ylabel('Pressure (hPa)')\n",
    "        plt.title('Vertical circulation along 117$^\\circ$E \\n'+month[i]+' '+UTC[j]+'UTC 1990-2020')\n",
    "        #plt.title('Vertical Cross Section '+month[i]+' '+UTC[j]+'UTC 1990-2020')\n",
    "        plt.colorbar(horo,orientation='horizontal', label='Potential Temperature ($^\\circ$C)',pad=0.2)\n",
    "        save_results_to = '/g/data/k10/lr0203/15S-120-150E/theta/'+monthlong[i]+'/thetauwplt/'\n",
    "        plt.savefig(save_results_to+'V15-120-150thetauw'+month[i]+UTC[j]+'plt.jpg')\n",
    "        plt.close()\n",
    "        # plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772161b8-f10a-4af8-83b5-605b6dc0cad3",
   "metadata": {},
   "source": [
    "**October case study**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0e577d-7753-4323-ba8e-9650028c59ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = xr.open_dataarray('/g/data/k10/lr0203/Frontogenesis/Fn/October/gradq/gradqOCT1500.nc')\n",
    "\n",
    "q_cs = q[383]\n",
    "plt.figure(figsize=(10,5))\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "ax.set_extent([110, 155, -30, -10], ccrs.PlateCarree())\n",
    "lon_grid = np.arange(110,155,5)\n",
    "lat_grid = np.arange(-30,-10,5)\n",
    "gl = ax.gridlines(draw_labels=True,xlocs=lon_grid,ylocs=lat_grid,\n",
    "          x_inline=False,y_inline=False,color='k',linestyle='--',linewidth=0.4)\n",
    "gl.top_labels = False\n",
    "gl.right_labels = False\n",
    "lons, lats = np.meshgrid(qlon, qlat)\n",
    "qg = plt.contourf(lons,lats,q_cs,levels=[2.5e-5,5e-5,7.5e-5,10e-5,12.5e-5,15e-5],cmap='Blues',extend='max')\n",
    "kw_clabels = {'fontsize': 11, 'inline': True, 'inline_spacing': 5, 'fmt': '%i',\n",
    "                          'rightside_up': True, 'use_clabeltext': True}\n",
    "mslp = ax.contour(lons,lats,pot02, colors='black',linewidths=1) #mslp contours\n",
    "ax.clabel(mslp, **kw_clabels)\n",
    "plt.colorbar(qg, orientation='horizontal',label='Specific Humidity Gradient (g $Kg^{-1} m^{-1}$)',fraction=0.06)\n",
    "ax.coastlines()   \n",
    "plt.title('|q| and  \\n1500UTC 12th OCTOBER 2002')\n",
    "save_results_to = '/g/data/k10/lr0203/final-plt/'\n",
    "plt.savefig(save_results_to+'12OCT02.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36da528f-86fd-4576-8fb0-17f5702407d9",
   "metadata": {},
   "source": [
    "**June Case Study 4-panel showing frontogenesis, deformation, specific humidity gradient, mean winds and convergence**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eeb04f2-8414-49ef-80f2-bf8dd46d6628",
   "metadata": {},
   "outputs": [],
   "source": [
    "qgrad = [[] for x in range(4)]\n",
    "fronto = [[] for x in range(4)]\n",
    "Eprime = [[] for x in range(4)]\n",
    "d = [[] for x in range(4)]\n",
    "u = [[] for x in range(4)]\n",
    "v = [[] for x in range(4)]\n",
    "abc = [\"a)\",\"b)\",\"c)\",\"d)\"]\n",
    "time4h = [\"0000UTC 21/06/2010\",\"1200UTC 21/06/2010\",\"0000UTC 22/06/2010\",\"1200UTC 22/06/2010\"]\n",
    "fig, ax = plt.subplots(2,2,subplot_kw={'projection': ccrs.PlateCarree()},figsize=(15,10))\n",
    "for i in range(0,2):\n",
    "    qgrad[i] = xr.open_dataarray('/g/data/k10/lr0203/JUNcasestudy/qgrad/qgrad21062010'+UTC[(i*12)]+'.nc')\n",
    "    fronto[i] = xr.open_dataarray('/g/data/k10/lr0203/JUNcasestudy/frontogenesis/Fn/Fn21062010'+UTC[(i*12)]+'.nc')\n",
    "    Eprime[i] = xr.open_dataarray('/g/data/k10/lr0203/JUNcasestudy/frontogenesis/Eprime/Eprime21062010'+UTC[(i*12)]+'.nc')\n",
    "    d[i] = xr.open_dataarray('/g/data/k10/lr0203/JUNcasestudy/d/d21062010'+UTC[(i*12)]+'.nc')\n",
    "    u[i] = xr.open_dataarray('/g/data/k10/lr0203/JUNcasestudy/u/u21062010'+UTC[(i*12)]+'.nc')\n",
    "    v[i] = xr.open_dataarray('/g/data/k10/lr0203/JUNcasestudy/v/v21062010'+UTC[(i*12)]+'.nc')\n",
    "\n",
    "    qgrad[i+2] = xr.open_dataarray('/g/data/k10/lr0203/JUNcasestudy/qgrad/qgrad22062010'+UTC[(i*12)]+'.nc')\n",
    "    fronto[i+2] = xr.open_dataarray('/g/data/k10/lr0203/JUNcasestudy/frontogenesis/Fn/Fn22062010'+UTC[(i*12)]+'.nc')\n",
    "    Eprime[i+2] = xr.open_dataarray('/g/data/k10/lr0203/JUNcasestudy/frontogenesis/Eprime/Eprime22062010'+UTC[(i*12)]+'.nc')\n",
    "    d[i+2] = xr.open_dataarray('/g/data/k10/lr0203/JUNcasestudy/d/d22062010'+UTC[(i*12)]+'.nc')\n",
    "    u[i+2] = xr.open_dataarray('/g/data/k10/lr0203/JUNcasestudy/u/u22062010'+UTC[(i*12)]+'.nc')\n",
    "    v[i+2] = xr.open_dataarray('/g/data/k10/lr0203/JUNcasestudy/v/v22062010'+UTC[(i*12)]+'.nc')\n",
    "for j in range(0,4):\n",
    "    if j == 0 or j == 2:\n",
    "        ax=ax.flatten()\n",
    "        ax[j].set_extent([110, 155, -30, -10], ccrs.PlateCarree())\n",
    "        lon_grid = np.arange(110,155,5)\n",
    "        lat_grid = np.arange(-30,-10,5)\n",
    "        gl = ax[j].gridlines(draw_labels=True,xlocs=lon_grid,ylocs=lat_grid,\n",
    "                  x_inline=False,y_inline=False,color='k',linestyle='--',linewidth=0.4)\n",
    "        gl.top_labels = False\n",
    "        gl.right_labels = False\n",
    "        lons, lats = np.meshgrid(qlon, qlat)\n",
    "        u1=u[j]\n",
    "        v1=v[j]\n",
    "        quiver_slices = (slice(None, None, 9), slice(None, None, 7))\n",
    "        conv = ax[j].contourf(lons, lats, d[j],levels=[-1,-1.5e-5], colors=['khaki'],linestyles='solid',extend='min')\n",
    "        Q1=ax[j].quiver(lons[quiver_slices],lats[quiver_slices],u1[quiver_slices],v1[quiver_slices],width=0.0025)\n",
    "        q = ax[j].contourf(lons, lats, qgrad[j],levels=[3e-5,4e-5,5e-5,6e-5,7e-5,8e-5], cmap='Blues',extend='max')\n",
    "        Ep = ax[j].contour(lons,lats,Eprime[j], levels=[0.00005],colors='limegreen',linestyles='solid',extend='max')\n",
    "        f = ax[j].contour(lons,lats,fronto[j], levels=[-0.25e-9],colors='magenta',linestyles='solid',extend='min')\n",
    "        ax[j].set_title(abc[j], loc='left')\n",
    "        ax[j].set_title(time4h[j])\n",
    "        ax[j].coastlines()  \n",
    "    else:\n",
    "        ax=ax.flatten()\n",
    "        ax[j].set_extent([110, 155, -30, -10], ccrs.PlateCarree())\n",
    "        lon_grid = np.arange(110,155,5)\n",
    "        lat_grid = np.arange(-30,-10,5)\n",
    "        gl = ax[j].gridlines(draw_labels=True,xlocs=lon_grid,ylocs=lat_grid,\n",
    "                  x_inline=False,y_inline=False,color='k',linestyle='--',linewidth=0.4)\n",
    "        gl.top_labels = False\n",
    "        gl.right_labels = False\n",
    "        gl.left_labels = False\n",
    "        lons, lats = np.meshgrid(qlon, qlat)\n",
    "        u1=u[j]\n",
    "        v1=v[j]\n",
    "        quiver_slices = (slice(None, None, 9), slice(None, None, 7))\n",
    "        conv = ax[j].contourf(lons, lats, d[j],levels=[-1,-1.5e-5], colors=['khaki'],linestyles='solid',extend='min')\n",
    "\n",
    "        Q1=ax[j].quiver(lons[quiver_slices],lats[quiver_slices],u1[quiver_slices],v1[quiver_slices],width=0.0025)\n",
    "        q = ax[j].contourf(lons, lats, qgrad[j],levels=[3e-5,4e-5,5e-5,6e-5,7e-5,8e-5], cmap='Blues',extend='max')\n",
    "        Ep = ax[j].contour(lons,lats,Eprime[j], levels=[0.00005],colors='limegreen',linestyles='solid',extend='max')\n",
    "        f = ax[j].contour(lons,lats,fronto[j], levels=[-0.25e-9],colors='magenta',linestyles='solid',extend='min')\n",
    "        ax[j].set_title(abc[j], loc='left')\n",
    "        ax[j].set_title(time4h[j])\n",
    "        ax[j].coastlines()  \n",
    "ax[1].quiverkey(Q1, 0.81, 0.92, 10, r'$10 \\frac{m}{s}$', labelpos='E',\n",
    "                   coordinates='figure',angle = 180, labelsep=0.3)    \n",
    "\n",
    "\n",
    "    \n",
    " # Adjust the location of the subplots on the page to make room for the colorbar\n",
    "fig.subplots_adjust(bottom=0.3, top=0.9, left=0.1, right=0.9,\n",
    "                    wspace=0.02, hspace=0.3)\n",
    "# # Add a colorbar axis at the bottom of the graph\n",
    "cbar_ax = fig.add_axes([0.2, 0.2, 0.6, 0.02])\n",
    "# cbar_ax1 = fig.add_axes([0.2, 0.18, 0.6, 0.02])\n",
    "# cbar_ax2 = fig.add_axes([0.2, 0.11, 0.6, 0.02])\n",
    "\n",
    "# # Draw the colorbar\n",
    "cbar=fig.colorbar(q,cax=cbar_ax,orientation='horizontal',label='Specific Humidity Gradient (g $Kg^{-1}m^{-1}$)')\n",
    "# cbar1=fig.colorbar(conv,cax=cbar_ax1,orientation='horizontal',label='Convergence ($s^{-1}$)')\n",
    "# cbar2=fig.colorbar(Ep,cax=cbar_ax2,orientation='horizontal',label='Frontogenesis ($g Kg^{-1} m^{-1} s^{-1}$)')\n",
    "\n",
    "\n",
    "# # Add a big title at the top\n",
    "plt.suptitle('|q|, Convergence, Deformation, Fn and Total Winds\\n 21-22nd JUNE 2010',fontsize='xx-large')\n",
    "save_results_to = '/g/data/k10/lr0203/final-plt/'\n",
    "plt.savefig(save_results_to+'junecasestudy.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf1fa4f-61e7-4036-972f-e32d4860f112",
   "metadata": {},
   "source": [
    "**Specific humidity gradient, potential temperature, ageostrophic winds 9-panel**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4777c83e-5143-4969-b93f-e4f3f0f1e855",
   "metadata": {},
   "outputs": [],
   "source": [
    "#seasonal gradq combine with 3 hours\n",
    "qgrad = [[] for x in range(9)]\n",
    "p = [[] for x in range(9)]\n",
    "u = [[] for x in range(9)]\n",
    "v = [[] for x in range(9)]\n",
    "time4h = [\"1PM AEST AMJJ\",\"7PM AEST AMJJ\",\"1AM AEST AMJJ\",\"1PM AEST ASON\",\"7PM AEST ASON\",\"1AM AEST ASON\",\n",
    "          \"1PM AEST DJFM\",\"7PM AEST DJFM\",\"1AM AEST DJFM\"]\n",
    "abc = [\"a)\",\"b)\",\"c)\",\"d)\",\"e)\",\"f)\",\"g)\",\"h)\",\"i)\"]\n",
    "fig, ax = plt.subplots(3,3,subplot_kw={'projection': ccrs.PlateCarree()},figsize=(20,15))\n",
    "for j in range(0,3):\n",
    "    qg1 = xr.open_dataarray('/g/data/k10/lr0203/gradq/April/dataAPR'+UTC[(j*6)+3]+'.nc')\n",
    "    qg2 = xr.open_dataarray('/g/data/k10/lr0203/gradq/May/dataMAY'+UTC[(j*6)+3]+'.nc')\n",
    "    qg3 = xr.open_dataarray('/g/data/k10/lr0203/gradq/June/dataJUN'+UTC[(j*6)+3]+'.nc')\n",
    "    qg4 = xr.open_dataarray('/g/data/k10/lr0203/gradq/July/dataJUL'+UTC[(j*6)+3]+'.nc')\n",
    "    qg5 = xr.open_dataarray('/g/data/k10/lr0203/gradq/August/dataAUG'+UTC[(j*6)+3]+'.nc')\n",
    "    qg6 = xr.open_dataarray('/g/data/k10/lr0203/gradq/September/dataSEP'+UTC[(j*6)+3]+'.nc')\n",
    "    qg7 = xr.open_dataarray('/g/data/k10/lr0203/gradq/October/dataOCT'+UTC[(j*6)+3]+'.nc')\n",
    "    qg8 = xr.open_dataarray('/g/data/k10/lr0203/gradq/November/dataNOV'+UTC[(j*6)+3]+'.nc')\n",
    "    qg9 = xr.open_dataarray('/g/data/k10/lr0203/gradq/December/dataDEC'+UTC[(j*6)+3]+'.nc')\n",
    "    qg10 = xr.open_dataarray('/g/data/k10/lr0203/gradq/January/dataJAN'+UTC[(j*6)+3]+'.nc')\n",
    "    qg11 = xr.open_dataarray('/g/data/k10/lr0203/gradq/February/dataFEB'+UTC[(j*6)+3]+'.nc')\n",
    "    qg12 = xr.open_dataarray('/g/data/k10/lr0203/gradq/March/dataMAR'+UTC[(j*6)+3]+'.nc')\n",
    "    qgrad[j] =(qg1+qg2+qg3+qg4)/4\n",
    "    qgrad[j+3] = (qg5+qg6+qg7+qg8)/4\n",
    "    qgrad[j+6] = (qg9+qg10+qg11+qg12)/4\n",
    "    \n",
    "    p1 = xr.open_dataarray('/g/data/k10/lr0203/theta/April/Data/thetaAPR'+UTC[(j*6)+3]+'.nc')\n",
    "    p2 = xr.open_dataarray('/g/data/k10/lr0203/theta/May/Data/thetaMAY'+UTC[(j*6)+3]+'.nc')\n",
    "    p3 = xr.open_dataarray('/g/data/k10/lr0203/theta/June/Data/thetaJUN'+UTC[(j*6)+3]+'.nc')\n",
    "    p4 = xr.open_dataarray('/g/data/k10/lr0203/theta/July/Data/thetaJUL'+UTC[(j*6)+3]+'.nc')\n",
    "    p5 = xr.open_dataarray('/g/data/k10/lr0203/theta/August/Data/thetaAUG'+UTC[(j*6)+3]+'.nc')\n",
    "    p6 = xr.open_dataarray('/g/data/k10/lr0203/theta/September/Data/thetaSEP'+UTC[(j*6)+3]+'.nc')\n",
    "    p7 = xr.open_dataarray('/g/data/k10/lr0203/theta/October/Data/thetaOCT'+UTC[(j*6)+3]+'.nc')\n",
    "    p8 = xr.open_dataarray('/g/data/k10/lr0203/theta/November/Data/thetaNOV'+UTC[(j*6)+3]+'.nc')\n",
    "    p9 = xr.open_dataarray('/g/data/k10/lr0203/theta/December/Data/thetaDEC'+UTC[(j*6)+3]+'.nc')\n",
    "    p10 = xr.open_dataarray('/g/data/k10/lr0203/theta/January/Data/thetaJAN'+UTC[(j*6)+3]+'.nc')\n",
    "    p11 = xr.open_dataarray('/g/data/k10/lr0203/theta/February/Data/thetaFEB'+UTC[(j*6)+3]+'.nc')\n",
    "    p12 = xr.open_dataarray('/g/data/k10/lr0203/theta/March/Data/thetaMAR'+UTC[(j*6)+3]+'.nc')\n",
    "    p[j] =(p1+p2+p3+p4)/4\n",
    "    p[j+3] = (p5+p6+p7+p8)/4\n",
    "    p[j+6] = (p9+p10+p11+p12)/4\n",
    "    \n",
    "    u1 = xr.open_dataarray('/g/data/k10/lr0203/Winds/uageo/April/uageoAPR'+UTC[(j*6)+3]+'mean.nc')\n",
    "    u2 = xr.open_dataarray('/g/data/k10/lr0203/Winds/uageo/May/uageoMAY'+UTC[(j*6)+3]+'mean.nc')\n",
    "    u3 = xr.open_dataarray('/g/data/k10/lr0203/Winds/uageo/June/uageoJUN'+UTC[(j*6)+3]+'mean.nc')\n",
    "    u4 = xr.open_dataarray('/g/data/k10/lr0203/Winds/uageo/July/uageoJUL'+UTC[(j*6)+3]+'mean.nc')\n",
    "    u5 = xr.open_dataarray('/g/data/k10/lr0203/Winds/uageo/August/uageoAUG'+UTC[(j*6)+3]+'mean.nc')\n",
    "    u6 = xr.open_dataarray('/g/data/k10/lr0203/Winds/uageo/September/uageoSEP'+UTC[(j*6)+3]+'mean.nc')\n",
    "    u7 = xr.open_dataarray('/g/data/k10/lr0203/Winds/uageo/October/uageoOCT'+UTC[(j*6)+3]+'mean.nc')\n",
    "    u8 = xr.open_dataarray('/g/data/k10/lr0203/Winds/uageo/November/uageoNOV'+UTC[(j*6)+3]+'mean.nc')\n",
    "    u9 = xr.open_dataarray('/g/data/k10/lr0203/Winds/uageo/December/uageoDEC'+UTC[(j*6)+3]+'mean.nc')\n",
    "    u10 = xr.open_dataarray('/g/data/k10/lr0203/Winds/uageo/January/uageoJAN'+UTC[(j*6)+3]+'mean.nc')\n",
    "    u11 = xr.open_dataarray('/g/data/k10/lr0203/Winds/uageo/February/uageoFEB'+UTC[(j*6)+3]+'mean.nc')\n",
    "    u12 = xr.open_dataarray('/g/data/k10/lr0203/Winds/uageo/March/uageoMAR'+UTC[(j*6)+3]+'mean.nc')\n",
    "    u[j] = (u1+u2+u3+u4)/4\n",
    "    u[j+3] = (u5+u6+u7+u8)/4\n",
    "    u[j+6] = (u9+u10+u11+u12)/4\n",
    "    \n",
    "    v1 = xr.open_dataarray('/g/data/k10/lr0203/Winds/vageo/April/vageoAPR'+UTC[(j*6)+3]+'mean.nc')\n",
    "    v2 = xr.open_dataarray('/g/data/k10/lr0203/Winds/vageo/May/vageoMAY'+UTC[(j*6)+3]+'mean.nc')\n",
    "    v3 = xr.open_dataarray('/g/data/k10/lr0203/Winds/vageo/June/vageoJUN'+UTC[(j*6)+3]+'mean.nc')\n",
    "    v4 = xr.open_dataarray('/g/data/k10/lr0203/Winds/vageo/July/vageoJUL'+UTC[(j*6)+3]+'mean.nc')\n",
    "    v5 = xr.open_dataarray('/g/data/k10/lr0203/Winds/vageo/August/vageoAUG'+UTC[(j*6)+3]+'mean.nc')\n",
    "    v6 = xr.open_dataarray('/g/data/k10/lr0203/Winds/vageo/September/vageoSEP'+UTC[(j*6)+3]+'mean.nc')\n",
    "    v7 = xr.open_dataarray('/g/data/k10/lr0203/Winds/vageo/October/vageoOCT'+UTC[(j*6)+3]+'mean.nc')\n",
    "    v8 = xr.open_dataarray('/g/data/k10/lr0203/Winds/vageo/November/vageoNOV'+UTC[(j*6)+3]+'mean.nc')\n",
    "    v9 = xr.open_dataarray('/g/data/k10/lr0203/Winds/vageo/December/vageoDEC'+UTC[(j*6)+3]+'mean.nc')\n",
    "    v10 = xr.open_dataarray('/g/data/k10/lr0203/Winds/vageo/January/vageoJAN'+UTC[(j*6)+3]+'mean.nc')\n",
    "    v11 = xr.open_dataarray('/g/data/k10/lr0203/Winds/vageo/February/vageoFEB'+UTC[(j*6)+3]+'mean.nc')\n",
    "    v12 = xr.open_dataarray('/g/data/k10/lr0203/Winds/vageo/March/vageoMAR'+UTC[(j*6)+3]+'mean.nc')\n",
    "    v[j] = (v1+v2+v3+v4)/4\n",
    "    v[j+3] = (v5+v6+v7+v8)/4\n",
    "    v[j+6] = (v9+v10+v11+v12)/4\n",
    "for k in range(0,9):\n",
    "    if k == 0 or k == 3 or k == 6:\n",
    "        ax=ax.flatten()\n",
    "        ax[k].set_extent([110, 155, -30, -10], ccrs.PlateCarree())\n",
    "        lon_grid = np.arange(110,155,5)\n",
    "        lat_grid = np.arange(-30,-10,5)\n",
    "        gl = ax[k].gridlines(draw_labels=True,xlocs=lon_grid,ylocs=lat_grid,\n",
    "                  x_inline=False,y_inline=False,color='k',linestyle='--',linewidth=0.4)\n",
    "        gl.top_labels = False\n",
    "        gl.right_labels = False\n",
    "        lons, lats = np.meshgrid(qlon, qlat)\n",
    "        umean1=u[k]\n",
    "        vmean1=v[k]\n",
    "        quiver_slices = (slice(None, None, 9), slice(None, None, 7))\n",
    "        grad = ax[k].contourf(lons, lats, qgrad[k],levels=[1e-6,2e-6,3e-6,4e-6,5e-6,6e-6,7e-6], cmap='Blues',extend='max')\n",
    "        Q1=ax[k].quiver(lons[quiver_slices],lats[quiver_slices],umean1[quiver_slices],vmean1[quiver_slices],width=0.0025)\n",
    "        kw_clabels = {'fontsize': 11, 'inline': True, 'inline_spacing': 5, 'fmt': '%i',\n",
    "                          'rightside_up': True, 'use_clabeltext': True}\n",
    "        mslp = ax[k].contour(qlon,qlat,p[k], colors='black') #mslp contours\n",
    "        ax[k].clabel(mslp, **kw_clabels)\n",
    "        ax[k].set_title(time4h[k])\n",
    "        ax[k].set_title(abc[k], loc='left')\n",
    "        ax[k].coastlines()  \n",
    "    else:\n",
    "        ax=ax.flatten()\n",
    "        ax[k].set_extent([110, 155, -30, -10], ccrs.PlateCarree())\n",
    "        lon_grid = np.arange(110,155,5)\n",
    "        lat_grid = np.arange(-30,-10,5)\n",
    "        gl = ax[k].gridlines(draw_labels=True,xlocs=lon_grid,ylocs=lat_grid,\n",
    "                  x_inline=False,y_inline=False,color='k',linestyle='--',linewidth=0.4)\n",
    "        gl.top_labels = False\n",
    "        gl.right_labels = False\n",
    "        gl.left_labels = False\n",
    "        lons, lats = np.meshgrid(qlon, qlat)\n",
    "        umean1=u[k]\n",
    "        vmean1=v[k]\n",
    "        quiver_slices = (slice(None, None, 9), slice(None, None, 7))\n",
    "        grad = ax[k].contourf(lons, lats, qgrad[k],levels=[1e-6,2e-6,3e-6,4e-6,5e-6,6e-6,7e-6], cmap='Blues',extend='max')\n",
    "        Q1=ax[k].quiver(lons[quiver_slices],lats[quiver_slices],umean1[quiver_slices],vmean1[quiver_slices],width=0.0025)\n",
    "        kw_clabels = {'fontsize': 11, 'inline': True, 'inline_spacing': 5, 'fmt': '%i',\n",
    "                          'rightside_up': True, 'use_clabeltext': True}\n",
    "        mslp = ax[k].contour(qlon,qlat,p[k], colors='black') #mslp contours\n",
    "        ax[k].clabel(mslp, **kw_clabels)\n",
    "        ax[k].set_title(time4h[k])\n",
    "        ax[k].set_title(abc[k], loc='left')\n",
    "        ax[k].coastlines()\n",
    "ax[5].quiverkey(Q1, 0.81, 0.92, 3, r'$3 \\frac{m}{s}$', labelpos='E',\n",
    "                   coordinates='figure',angle = 180, labelsep=0.3)\n",
    "\n",
    "# Adjust the location of the subplots on the page to make room for the colorbar\n",
    "fig.subplots_adjust(bottom=0.3, top=0.9, left=0.1, right=0.9,\n",
    "                    wspace=0.02, hspace=0.3)\n",
    "# # Add a colorbar axis at the bottom of the graph\n",
    "cbar_ax = fig.add_axes([0.2, 0.2, 0.6, 0.02])\n",
    "\n",
    "# # Draw the colorbar\n",
    "cbar=fig.colorbar(grad,cax=cbar_ax,orientation='horizontal',label='Specific Humidity Gradient (g $Kg^{-1} m^{-1}$)')\n",
    "\n",
    "# # Add a big title at the top\n",
    "plt.suptitle('Mean |q|,  and Ageostrophic Winds \\n 1990-2020 at 925hPa',fontsize='xx-large')\n",
    "save_results_to = '/g/data/k10/lr0203/final-plt/'\n",
    "plt.savefig(save_results_to+'3int-annualgradq.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56fae029-e422-4639-8a02-cc4a90b53548",
   "metadata": {},
   "source": [
    "**Mean total dryline associated precipitation rate over 5h 9-panel**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902bd245-2271-4812-b2d6-d90f7d0620f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean total dryline associated precipitation\n",
    "pcp = [[] for x in range(9)]\n",
    "h1 = [[] for x in range(5)]\n",
    "h2 = [[] for x in range(5)]\n",
    "h3 = [[] for x in range(5)]\n",
    "h4 = [[] for x in range(5)]\n",
    "h5 = [[] for x in range(5)]\n",
    "h6 = [[] for x in range(5)]\n",
    "h7 = [[] for x in range(5)]\n",
    "h8 = [[] for x in range(5)]\n",
    "h9 = [[] for x in range(5)]\n",
    "h10 = [[] for x in range(5)]\n",
    "h11 = [[] for x in range(5)]\n",
    "h12 = [[] for x in range(5)]\n",
    "time4h = [\"1PM AEST AMJJ\",\"7PM AEST AMJJ\",\"1AM AEST AMJJ\",\"1PM AEST ASON\",\"7PM AEST ASON\",\"1AM AEST ASON\",\n",
    "          \"1PM AEST DJFM\",\"7PM AEST DJFM\",\"1AM AEST DJFM\"]\n",
    "abc = [\"a)\",\"b)\",\"c)\",\"d)\",\"e)\",\"f)\",\"g)\",\"h)\",\"i)\"]\n",
    "fig, ax = plt.subplots(3,3,subplot_kw={'projection': ccrs.PlateCarree()},figsize=(20,15))\n",
    "\n",
    "for j in range(0,3):\n",
    "    for k in range(0,5):\n",
    "        n = 3\n",
    "        pcp1 = xr.open_dataarray('/g/data/k10/lr0203/pcpbuffer/April/tot_pcp_dryline/tot_pcp_dryAPR'+UTC[(j*6)+(n-2)+k]+'.nc')\n",
    "        pcp2 = xr.open_dataarray('/g/data/k10/lr0203/pcpbuffer/May/tot_pcp_dryline/tot_pcp_dryMAY'+UTC[(j*6)+(n-2)+k]+'.nc')\n",
    "        pcp3 = xr.open_dataarray('/g/data/k10/lr0203/pcpbuffer/June/tot_pcp_dryline/tot_pcp_dryJUN'+UTC[(j*6)+(n-2)+k]+'.nc')\n",
    "        pcp4 = xr.open_dataarray('/g/data/k10/lr0203/pcpbuffer/July/tot_pcp_dryline/tot_pcp_dryJUL'+UTC[(j*6)+(n-2)+k]+'.nc')\n",
    "        pcp5 = xr.open_dataarray('/g/data/k10/lr0203/pcpbuffer/August/tot_pcp_dryline/tot_pcp_dryAUG'+UTC[(j*6)+(n-2)+k]+'.nc')\n",
    "        pcp6 = xr.open_dataarray('/g/data/k10/lr0203/pcpbuffer/September/tot_pcp_dryline/tot_pcp_drySEP'+UTC[(j*6)+(n-2)+k]+'.nc')\n",
    "        pcp7 = xr.open_dataarray('/g/data/k10/lr0203/pcpbuffer/October/tot_pcp_dryline/tot_pcp_dryOCT'+UTC[(j*6)+(n-2)+k]+'.nc')\n",
    "        pcp8 = xr.open_dataarray('/g/data/k10/lr0203/pcpbuffer/November/tot_pcp_dryline/tot_pcp_dryNOV'+UTC[(j*6)+(n-2)+k]+'.nc')\n",
    "        pcp9 = xr.open_dataarray('/g/data/k10/lr0203/pcpbuffer/December/tot_pcp_dryline/tot_pcp_dryDEC'+UTC[(j*6)+(n-2)+k]+'.nc')\n",
    "        pcp10 = xr.open_dataarray('/g/data/k10/lr0203/pcpbuffer/January/tot_pcp_dryline/tot_pcp_dryJAN'+UTC[(j*6)+(n-2)+k]+'.nc')\n",
    "        pcp11 = xr.open_dataarray('/g/data/k10/lr0203/pcpbuffer/February/tot_pcp_dryline/tot_pcp_dryFEB'+UTC[(j*6)+(n-2)+k]+'.nc')\n",
    "        pcp12 = xr.open_dataarray('/g/data/k10/lr0203/pcpbuffer/March/tot_pcp_dryline/tot_pcp_dryMAR'+UTC[(j*6)+(n-2)+k]+'.nc')\n",
    "        h1[k] = pcp1\n",
    "        h2[k] = pcp2\n",
    "        h3[k] = pcp3\n",
    "        h4[k] = pcp4\n",
    "        h5[k] = pcp5\n",
    "        h6[k] = pcp6\n",
    "        h7[k] = pcp7\n",
    "        h8[k] = pcp8\n",
    "        h9[k] = pcp9\n",
    "        h10[k] = pcp10\n",
    "        h11[k] = pcp11\n",
    "        h12[k] = pcp12\n",
    "    hm1 = np.mean(h1,axis=0)\n",
    "    hm2 = np.mean(h2,axis=0)\n",
    "    hm3 = np.mean(h3,axis=0)\n",
    "    hm4 = np.mean(h4,axis=0)\n",
    "    hm5 = np.mean(h5,axis=0)\n",
    "    hm6 = np.mean(h6,axis=0)\n",
    "    hm7 = np.mean(h7,axis=0)\n",
    "    hm8 = np.mean(h8,axis=0)\n",
    "    hm9 = np.mean(h9,axis=0)\n",
    "    hm10 = np.mean(h10,axis=0)\n",
    "    hm11 = np.mean(h11,axis=0)\n",
    "    hm12 = np.mean(h12,axis=0)                                                                                                 \n",
    "                                                                                                     \n",
    "    pcp[j] = (hm1+hm2+hm3+hm4)/4\n",
    "    pcp[j+3] = (hm5+hm6+hm7+hm8)/4\n",
    "    pcp[j+6] = (hm9+hm10+hm11+hm12)/4\n",
    "for i in range(0,9):\n",
    "    if i == 0 or i == 3 or i == 6:\n",
    "        ax=ax.flatten()\n",
    "        ax[i].set_extent([110, 155, -30, -10], ccrs.PlateCarree())\n",
    "        lon_grid = np.arange(110,155,5)\n",
    "        lat_grid = np.arange(-30,-10,5)\n",
    "        gl = ax[i].gridlines(draw_labels=True,xlocs=lon_grid,ylocs=lat_grid,\n",
    "                  x_inline=False,y_inline=False,color='k',linestyle='--',linewidth=0.4)\n",
    "        gl.top_labels = False\n",
    "        gl.right_labels = False\n",
    "        grad = ax[i].contourf(qlon, qlat, pcp[i]*3600,levels=[0,2,4,8,16,32,48,64],\n",
    "                              colors=['white','lightgreen','mediumaquamarine','lightseagreen','steelblue','slateblue','rebeccapurple','indigo'],transform=ccrs.PlateCarree(),extend='max')\n",
    "\n",
    "        ax[i].set_title(time4h[i])\n",
    "        ax[i].set_title(abc[i], loc='left')\n",
    "        ax[i].coastlines()\n",
    "    else:\n",
    "        ax=ax.flatten()\n",
    "        ax[i].set_extent([110, 155, -30, -10], ccrs.PlateCarree())\n",
    "        lon_grid = np.arange(110,155,5)\n",
    "        lat_grid = np.arange(-30,-10,5)\n",
    "        gl = ax[i].gridlines(draw_labels=True,xlocs=lon_grid,ylocs=lat_grid,\n",
    "                  x_inline=False,y_inline=False,color='k',linestyle='--',linewidth=0.4)\n",
    "        gl.top_labels = False\n",
    "        gl.right_labels = False\n",
    "        gl.left_labels = False\n",
    "        grad = ax[i].contourf(qlon, qlat, pcp[i]*3600,levels=[0,2,4,8,16,32,48,64],\n",
    "                              colors=['white','lightgreen','mediumaquamarine','lightseagreen','steelblue','slateblue','rebeccapurple','indigo'],transform=ccrs.PlateCarree(),extend='max')\n",
    "\n",
    "        ax[i].set_title(time4h[i])\n",
    "        ax[i].set_title(abc[i], loc='left')\n",
    "        ax[i].coastlines()\n",
    "\n",
    "\n",
    "# Adjust the location of the subplots on the page to make room for the colorbar\n",
    "fig.subplots_adjust(bottom=0.3, top=0.9, left=0.1, right=0.9,\n",
    "                    wspace=0.02, hspace=0.3)\n",
    "# # Add a colorbar axis at the bottom of the graph\n",
    "cbar_ax = fig.add_axes([0.2, 0.2, 0.6, 0.02])\n",
    "\n",
    "# # Draw the colorbar\n",
    "cbar=fig.colorbar(grad,cax=cbar_ax,orientation='horizontal',label='Precipitation Rate (mm/hour)')\n",
    "\n",
    "# # Add a big title at the top\n",
    "plt.suptitle('Mean Total Dryline-Associated Precipitation Rate averaged over 5h\\n 1990-2020',fontsize='xx-large')\n",
    "save_results_to = '/g/data/k10/lr0203/final-plt/'\n",
    "plt.savefig(save_results_to+'3int-annual-buftotpcpdryjpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7ca391-77dd-4ac2-9de7-e0b80b4a97b6",
   "metadata": {},
   "source": [
    "**Mean percent of dryline associated rainfall over 5h 9-panel**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3334547-ff46-4e81-9324-4d5f70b66259",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mean percent of dryline associated rainfall over 5h\n",
    "percent = [[] for x in range(9)]\n",
    "h1 = [[] for x in range(5)]\n",
    "h2 = [[] for x in range(5)]\n",
    "h3 = [[] for x in range(5)]\n",
    "h4 = [[] for x in range(5)]\n",
    "h5 = [[] for x in range(5)]\n",
    "h6 = [[] for x in range(5)]\n",
    "h7 = [[] for x in range(5)]\n",
    "h8 = [[] for x in range(5)]\n",
    "h9 = [[] for x in range(5)]\n",
    "h10 = [[] for x in range(5)]\n",
    "h11 = [[] for x in range(5)]\n",
    "h12 = [[] for x in range(5)]\n",
    "time4h = [\"1PM AEST AMJJ\",\"7PM AEST AMJJ\",\"1AM AEST AMJJ\",\"1PM AEST ASON\",\"7PM AEST ASON\",\"1AM AEST ASON\",\n",
    "          \"1PM AEST DJFM\",\"7PM AEST DJFM\",\"1AM AEST DJFM\"]\n",
    "abc = [\"a)\",\"b)\",\"c)\",\"d)\",\"e)\",\"f)\",\"g)\",\"h)\",\"i)\"]\n",
    "fig, ax = plt.subplots(3,3,subplot_kw={'projection': ccrs.PlateCarree()},figsize=(20,15))\n",
    "\n",
    "for j in range(0,3):\n",
    "    for k in range(0,5):\n",
    "        n=3\n",
    "        per1 = xr.open_dataarray('/g/data/k10/lr0203/pcpbuffer/April/av_pcp_dryline/av_pcp_dryAPR'+UTC[(j*6)+(n-2)+k]+'.nc')\n",
    "        per2 = xr.open_dataarray('/g/data/k10/lr0203/pcpbuffer/May/av_pcp_dryline/av_pcp_dryMAY'+UTC[(j*6)+(n-2)+k]+'.nc')\n",
    "        per3 = xr.open_dataarray('/g/data/k10/lr0203/pcpbuffer/June/av_pcp_dryline/av_pcp_dryJUN'+UTC[(j*6)+(n-2)+k]+'.nc')\n",
    "        per4 = xr.open_dataarray('/g/data/k10/lr0203/pcpbuffer/July/av_pcp_dryline/av_pcp_dryJUL'+UTC[(j*6)+(n-2)+k]+'.nc')\n",
    "        per5 = xr.open_dataarray('/g/data/k10/lr0203/pcpbuffer/August/av_pcp_dryline/av_pcp_dryAUG'+UTC[(j*6)+(n-2)+k]+'.nc')\n",
    "        per6 = xr.open_dataarray('/g/data/k10/lr0203/pcpbuffer/September/av_pcp_dryline/av_pcp_drySEP'+UTC[(j*6)+(n-2)+k]+'.nc')\n",
    "        per7 = xr.open_dataarray('/g/data/k10/lr0203/pcpbuffer/October/av_pcp_dryline/av_pcp_dryOCT'+UTC[(j*6)+(n-2)+k]+'.nc')\n",
    "        per8 = xr.open_dataarray('/g/data/k10/lr0203/pcpbuffer/November/av_pcp_dryline/av_pcp_dryNOV'+UTC[(j*6)+(n-2)+k]+'.nc')\n",
    "        per9 = xr.open_dataarray('/g/data/k10/lr0203/pcpbuffer/December/av_pcp_dryline/av_pcp_dryDEC'+UTC[(j*6)+(n-2)+k]+'.nc')\n",
    "        per10 = xr.open_dataarray('/g/data/k10/lr0203/pcpbuffer/January/av_pcp_dryline/av_pcp_dryJAN'+UTC[(j*6)+(n-2)+k]+'.nc')\n",
    "        per11 = xr.open_dataarray('/g/data/k10/lr0203/pcpbuffer/February/av_pcp_dryline/av_pcp_dryFEB'+UTC[(j*6)+(n-2)+k]+'.nc')\n",
    "        per12 = xr.open_dataarray('/g/data/k10/lr0203/pcpbuffer/March/av_pcp_dryline/av_pcp_dryMAR'+UTC[(j*6)+(n-2)+k]+'.nc')\n",
    "        h1[k] = per1\n",
    "        h2[k] = per2\n",
    "        h3[k] = per3\n",
    "        h4[k] = per4\n",
    "        h5[k] = per5\n",
    "        h6[k] = per6\n",
    "        h7[k] = per7\n",
    "        h8[k] = per8\n",
    "        h9[k] = per9\n",
    "        h10[k] = per10\n",
    "        h11[k] = per11\n",
    "        h12[k] = per12\n",
    "    hm1 = np.mean(h1,axis=0)\n",
    "    hm2 = np.mean(h2,axis=0)\n",
    "    hm3 = np.mean(h3,axis=0)\n",
    "    hm4 = np.mean(h4,axis=0)\n",
    "    hm5 = np.mean(h5,axis=0)\n",
    "    hm6 = np.mean(h6,axis=0)\n",
    "    hm7 = np.mean(h7,axis=0)\n",
    "    hm8 = np.mean(h8,axis=0)\n",
    "    hm9 = np.mean(h9,axis=0)\n",
    "    hm10 = np.mean(h10,axis=0)\n",
    "    hm11 = np.mean(h11,axis=0)\n",
    "    hm12 = np.mean(h12,axis=0)                                                                                                 \n",
    "                                                                                                     \n",
    "    percent[j] = (hm1+hm2+hm3+hm4)/4\n",
    "    percent[j+3] = (hm5+hm6+hm7+hm8)/4\n",
    "    percent[j+6] = (hm9+hm10+hm11+hm12)/4\n",
    "\n",
    "for i in range(0,9):\n",
    "    if i ==0 or i == 3 or i == 6:\n",
    "        ax=ax.flatten()\n",
    "        ax[i].set_extent([110, 155, -30, -10], ccrs.PlateCarree())\n",
    "        lon_grid = np.arange(110,155,5)\n",
    "        lat_grid = np.arange(-30,-10,5)\n",
    "        gl = ax[i].gridlines(draw_labels=True,xlocs=lon_grid,ylocs=lat_grid,\n",
    "                  x_inline=False,y_inline=False,color='k',linestyle='--',linewidth=0.4)\n",
    "        gl.top_labels = False\n",
    "        gl.right_labels = False\n",
    "        percentage = ax[i].contourf(qlon, qlat, percent[i]*100,levels=[5,10,15,20,25,30,35,40,45,50,55,60], transform=ccrs.PlateCarree(),cmap='turbo',extend='max')\n",
    "        ax[i].set_title(time4h[i])\n",
    "        ax[i].set_title(abc[i], loc='left')\n",
    "        ax[i].coastlines()\n",
    "    else:\n",
    "        ax=ax.flatten()\n",
    "        ax[i].set_extent([110, 155, -30, -10], ccrs.PlateCarree())\n",
    "        lon_grid = np.arange(110,155,5)\n",
    "        lat_grid = np.arange(-30,-10,5)\n",
    "        gl = ax[i].gridlines(draw_labels=True,xlocs=lon_grid,ylocs=lat_grid,\n",
    "                  x_inline=False,y_inline=False,color='k',linestyle='--',linewidth=0.4)\n",
    "        gl.top_labels = False\n",
    "        gl.right_labels = False\n",
    "        gl.left_labels = False\n",
    "        percentage = ax[i].contourf(qlon, qlat, percent[i]*100,levels=[5,10,15,20,25,30,35,40,45,50,55,60], transform=ccrs.PlateCarree(),cmap='turbo',extend='max')\n",
    "        ax[i].set_title(time4h[i])\n",
    "        ax[i].set_title(abc[i], loc='left')\n",
    "        ax[i].coastlines()\n",
    "\n",
    "# # Adjust the location of the subplots on the page to make room for the colorbar\n",
    "fig.subplots_adjust(bottom=0.3, top=0.9, left=0.1, right=0.9,\n",
    "                    wspace=0.02, hspace=0.3)\n",
    "# # Add a colorbar axis at the bottom of the graph\n",
    "cbar_ax = fig.add_axes([0.2, 0.2, 0.6, 0.02])\n",
    "\n",
    "# # Draw the colorbar\n",
    "cbar=fig.colorbar(percentage,cax=cbar_ax,orientation='horizontal',label='(%)')\n",
    "\n",
    "# # Add a big title at the top\n",
    "plt.suptitle('Mean Percentage of Total Rainfall Associated with Drylines\\n 1990-2020',fontsize='xx-large')\n",
    "save_results_to = '/g/data/k10/lr0203/final-plt/'\n",
    "plt.savefig(save_results_to+'3int-annual-bufavpcpdry.jpg')\n",
    "plt.show()\n",
    "\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a83675-f3a0-43fa-aa06-e37ff0d524e5",
   "metadata": {},
   "source": [
    "**Mean divergence, geopotential height and ageostrophic winds 9-panel**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96817db8-dff8-43b8-98ba-e8ab18cc99d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mean divergence, geopotential height and ageostrophic winds\n",
    "d = [[] for x in range(9)]\n",
    "v = [[] for x in range(9)]\n",
    "u = [[] for x in range(9)]\n",
    "z = [[] for x in range(9)]\n",
    "time4h = [\"1PM AEST AMJJ\",\"7PM AEST AMJJ\",\"1AM AEST AMJJ\",\"1PM AEST ASON\",\"7PM AEST ASON\",\"1AM AEST ASON\",\n",
    "          \"1PM AEST DJFM\",\"7PM AEST DJFM\",\"1AM AEST DJFM\"]\n",
    "abc = [\"a)\",\"b)\",\"c)\",\"d)\",\"e)\",\"f)\",\"g)\",\"h)\",\"i)\"]\n",
    "fig, ax = plt.subplots(3,3,subplot_kw={'projection': ccrs.PlateCarree()},figsize=(20,15))\n",
    "\n",
    "for j in range(0,3):\n",
    "    d1 = xr.open_dataarray('/g/data/k10/lr0203/Convergence/April/Data/convAPR'+UTC[(j*6)+3]+'.nc')\n",
    "    d2 = xr.open_dataarray('/g/data/k10/lr0203/Convergence/May/Data/convMAY'+UTC[(j*6)+3]+'.nc')\n",
    "    d3 = xr.open_dataarray('/g/data/k10/lr0203/Convergence/June/Data/convJUN'+UTC[(j*6)+3]+'.nc')\n",
    "    d4 = xr.open_dataarray('/g/data/k10/lr0203/Convergence/July/Data/convJUL'+UTC[(j*6)+3]+'.nc')\n",
    "    d5 = xr.open_dataarray('/g/data/k10/lr0203/Convergence/August/Data/convAUG'+UTC[(j*6)+3]+'.nc')\n",
    "    d6 = xr.open_dataarray('/g/data/k10/lr0203/Convergence/September/Data/convSEP'+UTC[(j*6)+3]+'.nc')\n",
    "    d7 = xr.open_dataarray('/g/data/k10/lr0203/Convergence/October/Data/convOCT'+UTC[(j*6)+3]+'.nc')\n",
    "    d8 = xr.open_dataarray('/g/data/k10/lr0203/Convergence/November/Data/convNOV'+UTC[(j*6)+3]+'.nc')\n",
    "    d9 = xr.open_dataarray('/g/data/k10/lr0203/Convergence/December/Data/convDEC'+UTC[(j*6)+3]+'.nc')\n",
    "    d10 = xr.open_dataarray('/g/data/k10/lr0203/Convergence/January/Data/convJAN'+UTC[(j*6)+3]+'.nc')\n",
    "    d11 = xr.open_dataarray('/g/data/k10/lr0203/Convergence/February/Data/convFEB'+UTC[(j*6)+3]+'.nc')\n",
    "    d12 = xr.open_dataarray('/g/data/k10/lr0203/Convergence/March/Data/convMAR'+UTC[(j*6)+3]+'.nc')\n",
    "    d[j] = (d1+d2+d3+d4)/4\n",
    "    d[j+3] = (d5+d6+d7+d8)/4\n",
    "    d[j+6] = (d9+d10+d11+d12)/4\n",
    "    \n",
    "    u1 = xr.open_dataarray('/g/data/k10/lr0203/Winds/uageo/April/uageoAPR'+UTC[(j*6)+3]+'mean.nc')\n",
    "    u2 = xr.open_dataarray('/g/data/k10/lr0203/Winds/uageo/May/uageoMAY'+UTC[(j*6)+3]+'mean.nc')\n",
    "    u3 = xr.open_dataarray('/g/data/k10/lr0203/Winds/uageo/June/uageoJUN'+UTC[(j*6)+3]+'mean.nc')\n",
    "    u4 = xr.open_dataarray('/g/data/k10/lr0203/Winds/uageo/July/uageoJUL'+UTC[(j*6)+3]+'mean.nc')\n",
    "    u5 = xr.open_dataarray('/g/data/k10/lr0203/Winds/uageo/August/uageoAUG'+UTC[(j*6)+3]+'mean.nc')\n",
    "    u6 = xr.open_dataarray('/g/data/k10/lr0203/Winds/uageo/September/uageoSEP'+UTC[(j*6)+3]+'mean.nc')\n",
    "    u7 = xr.open_dataarray('/g/data/k10/lr0203/Winds/uageo/October/uageoOCT'+UTC[(j*6)+3]+'mean.nc')\n",
    "    u8 = xr.open_dataarray('/g/data/k10/lr0203/Winds/uageo/November/uageoNOV'+UTC[(j*6)+3]+'mean.nc')\n",
    "    u9 = xr.open_dataarray('/g/data/k10/lr0203/Winds/uageo/December/uageoDEC'+UTC[(j*6)+3]+'mean.nc')\n",
    "    u10 = xr.open_dataarray('/g/data/k10/lr0203/Winds/uageo/January/uageoJAN'+UTC[(j*6)+3]+'mean.nc')\n",
    "    u11 = xr.open_dataarray('/g/data/k10/lr0203/Winds/uageo/February/uageoFEB'+UTC[(j*6)+3]+'mean.nc')\n",
    "    u12 = xr.open_dataarray('/g/data/k10/lr0203/Winds/uageo/March/uageoMAR'+UTC[(j*6)+3]+'mean.nc')\n",
    "    u[j] = (u1+u2+u3+u4)/4\n",
    "    u[j+3] = (u5+u6+u7+u8)/4\n",
    "    u[j+6] = (u9+u10+u11+u12)/4\n",
    "    \n",
    "    v1 = xr.open_dataarray('/g/data/k10/lr0203/Winds/vageo/April/vageoAPR'+UTC[(j*6)+3]+'mean.nc')\n",
    "    v2 = xr.open_dataarray('/g/data/k10/lr0203/Winds/vageo/May/vageoMAY'+UTC[(j*6)+3]+'mean.nc')\n",
    "    v3 = xr.open_dataarray('/g/data/k10/lr0203/Winds/vageo/June/vageoJUN'+UTC[(j*6)+3]+'mean.nc')\n",
    "    v4 = xr.open_dataarray('/g/data/k10/lr0203/Winds/vageo/July/vageoJUL'+UTC[(j*6)+3]+'mean.nc')\n",
    "    v5 = xr.open_dataarray('/g/data/k10/lr0203/Winds/vageo/August/vageoAUG'+UTC[(j*6)+3]+'mean.nc')\n",
    "    v6 = xr.open_dataarray('/g/data/k10/lr0203/Winds/vageo/September/vageoSEP'+UTC[(j*6)+3]+'mean.nc')\n",
    "    v7 = xr.open_dataarray('/g/data/k10/lr0203/Winds/vageo/October/vageoOCT'+UTC[(j*6)+3]+'mean.nc')\n",
    "    v8 = xr.open_dataarray('/g/data/k10/lr0203/Winds/vageo/November/vageoNOV'+UTC[(j*6)+3]+'mean.nc')\n",
    "    v9 = xr.open_dataarray('/g/data/k10/lr0203/Winds/vageo/December/vageoDEC'+UTC[(j*6)+3]+'mean.nc')\n",
    "    v10 = xr.open_dataarray('/g/data/k10/lr0203/Winds/vageo/January/vageoJAN'+UTC[(j*6)+3]+'mean.nc')\n",
    "    v11 = xr.open_dataarray('/g/data/k10/lr0203/Winds/vageo/February/vageoFEB'+UTC[(j*6)+3]+'mean.nc')\n",
    "    v12 = xr.open_dataarray('/g/data/k10/lr0203/Winds/vageo/March/vageoMAR'+UTC[(j*6)+3]+'mean.nc')\n",
    "    v[j] = (v1+v2+v3+v4)/4\n",
    "    v[j+3] = (v5+v6+v7+v8)/4\n",
    "    v[j+6] = (v9+v10+v11+v12)/4\n",
    "    \n",
    "    z1 = xr.open_dataarray('/g/data/k10/lr0203/Winds/geo/April/zmeanAPR'+UTC[(j*6)+3]+'.nc')\n",
    "    z2 = xr.open_dataarray('/g/data/k10/lr0203/Winds/geo/May/zmeanMAY'+UTC[(j*6)+3]+'.nc')\n",
    "    z3 = xr.open_dataarray('/g/data/k10/lr0203/Winds/geo/June/zmeanJUN'+UTC[(j*6)+3]+'.nc')\n",
    "    z4 = xr.open_dataarray('/g/data/k10/lr0203/Winds/geo/July/zmeanJUL'+UTC[(j*6)+3]+'.nc')\n",
    "    z5 = xr.open_dataarray('/g/data/k10/lr0203/Winds/geo/August/zmeanAUG'+UTC[(j*6)+3]+'.nc')\n",
    "    z6 = xr.open_dataarray('/g/data/k10/lr0203/Winds/geo/September/zmeanSEP'+UTC[(j*6)+3]+'.nc')\n",
    "    z7 = xr.open_dataarray('/g/data/k10/lr0203/Winds/geo/October/zmeanOCT'+UTC[(j*6)+3]+'.nc')\n",
    "    z8 = xr.open_dataarray('/g/data/k10/lr0203/Winds/geo/November/zmeanNOV'+UTC[(j*6)+3]+'.nc')\n",
    "    z9 = xr.open_dataarray('/g/data/k10/lr0203/Winds/geo/December/zmeanDEC'+UTC[(j*6)+3]+'.nc')\n",
    "    z10 = xr.open_dataarray('/g/data/k10/lr0203/Winds/geo/January/zmeanJAN'+UTC[(j*6)+3]+'.nc')\n",
    "    z11 = xr.open_dataarray('/g/data/k10/lr0203/Winds/geo/February/zmeanFEB'+UTC[(j*6)+3]+'.nc')\n",
    "    z12 = xr.open_dataarray('/g/data/k10/lr0203/Winds/geo/March/zmeanMAR'+UTC[(j*6)+3]+'.nc')\n",
    "    z[j] = (z1+z2+z3+z4)/4\n",
    "    z[j+3] = (z5+z6+z7+z8)/4\n",
    "    z[j+6] = (z9+z10+z11+z12)/4\n",
    "for k in range(0,9):\n",
    "    if k == 0 or k == 3 or k == 6:\n",
    "        ax=ax.flatten()\n",
    "        ax[k].set_extent([110, 155, -30, -10], ccrs.PlateCarree())\n",
    "        lons, lats = np.meshgrid(qlon, qlat)\n",
    "        lon_grid = np.arange(110,155,5)\n",
    "        lat_grid = np.arange(-30,-10,5)\n",
    "        gl = ax[k].gridlines(draw_labels=True,xlocs=lon_grid,ylocs=lat_grid,\n",
    "                  x_inline=False,y_inline=False,color='k',linestyle='--',linewidth=0.4)\n",
    "        gl.top_labels = False\n",
    "        gl.right_labels = False\n",
    "        umean1=u[k]\n",
    "        vmean1=v[k]\n",
    "        grad = ax[k].contourf(lons, lats, d[k],levels=[-3e-5,-2.5e-5,-2e-5,-1.5e-5,-1e-5,-0.5e-5,0,0.5e-5,1e-5,1.5e-5,2e-5,2.5e-5,3e-5], transform=ccrs.PlateCarree(), \n",
    "                              colors=['darkred','firebrick','crimson','red','darkorange','khaki','white','white','powderblue','skyblue','cornflowerblue','royalblue','mediumblue','darkblue'],\n",
    "                              extend='both')\n",
    "\n",
    "        mslp = ax[k].contour(lons,lats,z[k], colors='black') #mslp contours\n",
    "        quiver_slices = (slice(None, None, 9), slice(None, None, 7))\n",
    "        Q1=ax[k].quiver(lons[quiver_slices],lats[quiver_slices],umean1[quiver_slices],vmean1[quiver_slices],width=0.0025)\n",
    "        kw_clabels = {'fontsize': 11, 'inline': True, 'inline_spacing': 5, 'fmt': '%i',\n",
    "                          'rightside_up': True, 'use_clabeltext': True}\n",
    "        ax[k].clabel(mslp, **kw_clabels)\n",
    "        ax[k].set_title(time4h[k])\n",
    "        ax[k].set_title(abc[k], loc='left')\n",
    "        ax[k].coastlines()\n",
    "    else:\n",
    "        ax=ax.flatten()\n",
    "        ax[k].set_extent([110, 155, -30, -10], ccrs.PlateCarree())\n",
    "        lons, lats = np.meshgrid(qlon, qlat)\n",
    "        lon_grid = np.arange(110,155,5)\n",
    "        lat_grid = np.arange(-30,-10,5)\n",
    "        gl = ax[k].gridlines(draw_labels=True,xlocs=lon_grid,ylocs=lat_grid,\n",
    "                  x_inline=False,y_inline=False,color='k',linestyle='--',linewidth=0.4)\n",
    "        gl.top_labels = False\n",
    "        gl.right_labels = False\n",
    "        gl.left_labels = False\n",
    "        umean1=u[k]\n",
    "        vmean1=v[k]\n",
    "        grad = ax[k].contourf(lons, lats, d[k],levels=[-3e-5,-2.5e-5,-2e-5,-1.5e-5,-1e-5,-0.5e-5,0,0.5e-5,1e-5,1.5e-5,2e-5,2.5e-5,3e-5], transform=ccrs.PlateCarree(), \n",
    "                              colors=['darkred','firebrick','crimson','red','darkorange','khaki','white','white','powderblue','skyblue','cornflowerblue','royalblue','mediumblue','darkblue'],\n",
    "                              extend='both')\n",
    "\n",
    "        mslp = ax[k].contour(lons,lats,z[k], colors='black') #mslp contours\n",
    "        quiver_slices = (slice(None, None, 9), slice(None, None, 7))\n",
    "        Q1=ax[k].quiver(lons[quiver_slices],lats[quiver_slices],umean1[quiver_slices],vmean1[quiver_slices],width=0.0025)\n",
    "        kw_clabels = {'fontsize': 11, 'inline': True, 'inline_spacing': 5, 'fmt': '%i',\n",
    "                          'rightside_up': True, 'use_clabeltext': True}\n",
    "        ax[k].clabel(mslp, **kw_clabels)\n",
    "        ax[k].set_title(time4h[k])\n",
    "        ax[k].set_title(abc[k], loc='left')\n",
    "        ax[k].coastlines()\n",
    "ax[5].quiverkey(Q1, 0.81, 0.92, 3, r'$3 \\frac{m}{s}$', labelpos='E',\n",
    "                   coordinates='figure',angle = 180, labelsep=0.3)\n",
    "# Adjust the location of the subplots on the page to make room for the colorbar\n",
    "fig.subplots_adjust(bottom=0.3, top=0.9, left=0.1, right=0.9,\n",
    "                    wspace=0.02, hspace=0.3)\n",
    "# # Add a colorbar axis at the bottom of the graph\n",
    "cbar_ax = fig.add_axes([0.2, 0.2, 0.6, 0.02])\n",
    "\n",
    "# # Draw the colorbar\n",
    "cbar=fig.colorbar(grad,cax=cbar_ax,spacing='proportional',orientation='horizontal',label='Divergence ($s^{-1}$)')\n",
    "\n",
    "# # Add a big title at the top\n",
    "plt.suptitle('Mean Divergence, Geopotential Height and Ageostrophic Winds\\n 1990-2020 at 925hPa',fontsize='xx-large')\n",
    "save_results_to = '/g/data/k10/lr0203/final-plt/'\n",
    "plt.savefig(save_results_to+'3int-annualdivergence.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1bfb2d-f7f0-4750-b90a-8e2d4d3e6927",
   "metadata": {},
   "source": [
    "**Mean Frontogenesis and specific humidity 9-panel**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bdb331-c274-4d67-b08c-725265a5ba3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#frontogenesis\n",
    "#seasonal combine example\n",
    "f = [[] for x in range(9)]\n",
    "q = [[] for x in range(9)]\n",
    "e = [[] for x in range(9)]\n",
    "d = [[] for x in range(9)]\n",
    "time4h = [\"1PM AEST AMJJ\",\"7PM AEST AMJJ\",\"1AM AEST AMJJ\",\"1PM AEST ASON\",\"7PM AEST ASON\",\"1AM AEST ASON\",\n",
    "          \"1PM AEST DJFM\",\"7PM AEST DJFM\",\"1AM AEST DJFM\"]\n",
    "abc = [\"a)\",\"b)\",\"c)\",\"d)\",\"e)\",\"f)\",\"g)\",\"h)\",\"i)\"]\n",
    "fig, ax = plt.subplots(3,3,subplot_kw={'projection': ccrs.PlateCarree()},figsize=(20,15))\n",
    "\n",
    "for j in range(0,3):\n",
    "    f1 = xr.open_dataarray('/g/data/k10/lr0203/Frontogenesis/Fn/April/Fn_MeanFronto/Fn_MeanFrontoAPR'+UTC[(j*6)+3]+'.nc')\n",
    "    f2 = xr.open_dataarray('/g/data/k10/lr0203/Frontogenesis/Fn/May/Fn_MeanFronto/Fn_MeanFrontoMAY'+UTC[(j*6)+3]+'.nc')\n",
    "    f3 = xr.open_dataarray('/g/data/k10/lr0203/Frontogenesis/Fn/June/Fn_MeanFronto/Fn_MeanFrontoJUN'+UTC[(j*6)+3]+'.nc')\n",
    "    f4 = xr.open_dataarray('/g/data/k10/lr0203/Frontogenesis/Fn/July/Fn_MeanFronto/Fn_MeanFrontoJUL'+UTC[(j*6)+3]+'.nc')\n",
    "    f5 = xr.open_dataarray('/g/data/k10/lr0203/Frontogenesis/Fn/August/Fn_MeanFronto/Fn_MeanFrontoAUG'+UTC[(j*6)+3]+'.nc')\n",
    "    f6 = xr.open_dataarray('/g/data/k10/lr0203/Frontogenesis/Fn/September/Fn_MeanFronto/Fn_MeanFrontoSEP'+UTC[(j*6)+3]+'.nc')\n",
    "    f7 = xr.open_dataarray('/g/data/k10/lr0203/Frontogenesis/Fn/October/Fn_MeanFronto/Fn_MeanFrontoOCT'+UTC[(j*6)+3]+'.nc')\n",
    "    f8 = xr.open_dataarray('/g/data/k10/lr0203/Frontogenesis/Fn/November/Fn_MeanFronto/Fn_MeanFrontoNOV'+UTC[(j*6)+3]+'.nc')\n",
    "    f9 = xr.open_dataarray('/g/data/k10/lr0203/Frontogenesis/Fn/December/Fn_MeanFronto/Fn_MeanFrontoDEC'+UTC[(j*6)+3]+'.nc')\n",
    "    f10 = xr.open_dataarray('/g/data/k10/lr0203/Frontogenesis/Fn/January/Fn_MeanFronto/Fn_MeanFrontoJAN'+UTC[(j*6)+3]+'.nc')\n",
    "    f11 = xr.open_dataarray('/g/data/k10/lr0203/Frontogenesis/Fn/February/Fn_MeanFronto/Fn_MeanFrontoFEB'+UTC[(j*6)+3]+'.nc')\n",
    "    f12 = xr.open_dataarray('/g/data/k10/lr0203/Frontogenesis/Fn/March/Fn_MeanFronto/Fn_MeanFrontoMAR'+UTC[(j*6)+3]+'.nc')\n",
    "    f[j] = (f1+f2+f3+f4)/4\n",
    "    f[j+3] = (f5+f6+f7+f8)/4\n",
    "    f[j+6] = (f9+f10+f11+f12)/4\n",
    "    d1 = xr.open_dataarray('/g/data/k10/lr0203/Convergence/April/Data/convAPR'+UTC[(j*6)+3]+'.nc')\n",
    "    d2 = xr.open_dataarray('/g/data/k10/lr0203/Convergence/May/Data/convMAY'+UTC[(j*6)+3]+'.nc')\n",
    "    d3 = xr.open_dataarray('/g/data/k10/lr0203/Convergence/June/Data/convJUN'+UTC[(j*6)+3]+'.nc')\n",
    "    d4 = xr.open_dataarray('/g/data/k10/lr0203/Convergence/July/Data/convJUL'+UTC[(j*6)+3]+'.nc')\n",
    "    d5 = xr.open_dataarray('/g/data/k10/lr0203/Convergence/August/Data/convAUG'+UTC[(j*6)+3]+'.nc')\n",
    "    d6 = xr.open_dataarray('/g/data/k10/lr0203/Convergence/September/Data/convSEP'+UTC[(j*6)+3]+'.nc')\n",
    "    d7 = xr.open_dataarray('/g/data/k10/lr0203/Convergence/October/Data/convOCT'+UTC[(j*6)+3]+'.nc')\n",
    "    d8 = xr.open_dataarray('/g/data/k10/lr0203/Convergence/November/Data/convNOV'+UTC[(j*6)+3]+'.nc')\n",
    "    d9 = xr.open_dataarray('/g/data/k10/lr0203/Convergence/December/Data/convDEC'+UTC[(j*6)+3]+'.nc')\n",
    "    d10 = xr.open_dataarray('/g/data/k10/lr0203/Convergence/January/Data/convJAN'+UTC[(j*6)+3]+'.nc')\n",
    "    d11 = xr.open_dataarray('/g/data/k10/lr0203/Convergence/February/Data/convFEB'+UTC[(j*6)+3]+'.nc')\n",
    "    d12 = xr.open_dataarray('/g/data/k10/lr0203/Convergence/March/Data/convMAR'+UTC[(j*6)+3]+'.nc')\n",
    "    d[j] = (d1+d2+d3+d4)/4\n",
    "    d[j+3] = (d5+d6+d7+d8)/4\n",
    "    d[j+6] = (d9+d10+d11+d12)/4\n",
    "    e1 = xr.open_dataarray('/g/data/k10/lr0203/Frontogenesis/Fn/April/Eprime_mean/Eprime_meanAPR'+UTC[(j*6)+3]+'.nc')\n",
    "    e2 = xr.open_dataarray('/g/data/k10/lr0203/Frontogenesis/Fn/May/Eprime_mean/Eprime_meanMAY'+UTC[(j*6)+3]+'.nc')\n",
    "    e3 = xr.open_dataarray('/g/data/k10/lr0203/Frontogenesis/Fn/June/Eprime_mean/Eprime_meanJUN'+UTC[(j*6)+3]+'.nc')\n",
    "    e4 = xr.open_dataarray('/g/data/k10/lr0203/Frontogenesis/Fn/July/Eprime_mean/Eprime_meanJUL'+UTC[(j*6)+3]+'.nc')\n",
    "    e5 = xr.open_dataarray('/g/data/k10/lr0203/Frontogenesis/Fn/August/Eprime_mean/Eprime_meanAUG'+UTC[(j*6)+3]+'.nc')\n",
    "    e6 = xr.open_dataarray('/g/data/k10/lr0203/Frontogenesis/Fn/September/Eprime_mean/Eprime_meanSEP'+UTC[(j*6)+3]+'.nc')\n",
    "    e7 = xr.open_dataarray('/g/data/k10/lr0203/Frontogenesis/Fn/October/Eprime_mean/Eprime_meanOCT'+UTC[(j*6)+3]+'.nc')\n",
    "    e8 = xr.open_dataarray('/g/data/k10/lr0203/Frontogenesis/Fn/November/Eprime_mean/Eprime_meanNOV'+UTC[(j*6)+3]+'.nc')\n",
    "    e9 = xr.open_dataarray('/g/data/k10/lr0203/Frontogenesis/Fn/December/Eprime_mean/Eprime_meanDEC'+UTC[(j*6)+3]+'.nc')\n",
    "    e10 = xr.open_dataarray('/g/data/k10/lr0203/Frontogenesis/Fn/January/Eprime_mean/Eprime_meanJAN'+UTC[(j*6)+3]+'.nc')\n",
    "    e11 = xr.open_dataarray('/g/data/k10/lr0203/Frontogenesis/Fn/February/Eprime_mean/Eprime_meanFEB'+UTC[(j*6)+3]+'.nc')\n",
    "    e12 = xr.open_dataarray('/g/data/k10/lr0203/Frontogenesis/Fn/March/Eprime_mean/Eprime_meanMAR'+UTC[(j*6)+3]+'.nc')\n",
    "    e[j] = (e1+e2+e3+e4)/4\n",
    "    e[j+3] = (e5+e6+e7+e8)/4\n",
    "    e[j+6] = (e9+e10+e11+e12)/4\n",
    "    q1 = xr.open_dataarray('/g/data/k10/lr0203/SpecHum/April/qAPR'+UTC[(j*6)+3]+'.nc')\n",
    "    q2 = xr.open_dataarray('/g/data/k10/lr0203/SpecHum/May/qMAY'+UTC[(j*6)+3]+'.nc')\n",
    "    q3 = xr.open_dataarray('/g/data/k10/lr0203/SpecHum/June/qJUN'+UTC[(j*6)+3]+'.nc')\n",
    "    q4 = xr.open_dataarray('/g/data/k10/lr0203/SpecHum/July/qJUL'+UTC[(j*6)+3]+'.nc')\n",
    "    q5 = xr.open_dataarray('/g/data/k10/lr0203/SpecHum/August/qAUG'+UTC[(j*6)+3]+'.nc')\n",
    "    q6 = xr.open_dataarray('/g/data/k10/lr0203/SpecHum/September/qSEP'+UTC[(j*6)+3]+'.nc')\n",
    "    q7 = xr.open_dataarray('/g/data/k10/lr0203/SpecHum/October/qOCT'+UTC[(j*6)+3]+'.nc')\n",
    "    q8 = xr.open_dataarray('/g/data/k10/lr0203/SpecHum/November/qNOV'+UTC[(j*6)+3]+'.nc')\n",
    "    q9 = xr.open_dataarray('/g/data/k10/lr0203/SpecHum/December/qDEC'+UTC[(j*6)+3]+'.nc')\n",
    "    q10 = xr.open_dataarray('/g/data/k10/lr0203/SpecHum/January/qJAN'+UTC[(j*6)+3]+'.nc')\n",
    "    q11 = xr.open_dataarray('/g/data/k10/lr0203/SpecHum/February/qFEB'+UTC[(j*6)+3]+'.nc')\n",
    "    q12 = xr.open_dataarray('/g/data/k10/lr0203/SpecHum/March/qMAR'+UTC[(j*6)+3]+'.nc')\n",
    "    q[j] = (q1+q2+q3+q4)/4\n",
    "    q[j+3] = (q5+q6+q7+q8)/4\n",
    "    q[j+6] = (q9+q10+q11+q12)/4\n",
    "for k in range(0,9):\n",
    "    if k == 0 or k == 3 or k == 6:\n",
    "        ax=ax.flatten()\n",
    "        ax[k].set_extent([110, 155, -30, -10], ccrs.PlateCarree())\n",
    "        lons, lats = np.meshgrid(qlon, qlat)\n",
    "        lon_grid = np.arange(110,155,5)\n",
    "        lat_grid = np.arange(-30,-10,5)\n",
    "        gl = ax[k].gridlines(draw_labels=True,xlocs=lon_grid,ylocs=lat_grid,\n",
    "                  x_inline=False,y_inline=False,color='k',linestyle='--',linewidth=0.4)\n",
    "        gl.top_labels = False\n",
    "        gl.right_labels = False\n",
    "        ax[k].set_title(time4h[k])\n",
    "        ax[k].set_title(abc[k], loc='left')\n",
    "        kw_clabels = {'fontsize': 11, 'inline': True, 'inline_spacing': 5, 'fmt': '%i',\n",
    "                          'rightside_up': True, 'use_clabeltext': True}\n",
    "        qcon = ax[k].contour(lons,lats,q[k],colors='black') #mslp contours\n",
    "        epcon = ax[k].contour(lons,lats,e[k],levels=[0.00006],colors='blue',extend='max')\n",
    "        dcon = ax[k].contour(lons,lats,d[k],levels=[-0.000015],linestyles='solid',colors='magenta',extend='min')\n",
    "        ax[k].clabel(qcon, **kw_clabels)\n",
    "        fronto = ax[k].contourf(qlon, qlat, f[k],levels=[-9e-10,-7.5e-10,-6e-10,-4.5e-10,-3e-10,-1.5e-10,0],transform=ccrs.PlateCarree(), \n",
    "                                colors=['saddlebrown','sienna','chocolate','darkorange','orange','navajowhite','white'],extend='min')\n",
    "        ax[k].coastlines()\n",
    "    else:\n",
    "        ax=ax.flatten()\n",
    "        ax[k].set_extent([110, 155, -30, -10], ccrs.PlateCarree())\n",
    "        lons, lats = np.meshgrid(qlon, qlat)\n",
    "        lon_grid = np.arange(110,155,5)\n",
    "        lat_grid = np.arange(-30,-10,5)\n",
    "        gl = ax[k].gridlines(draw_labels=True,xlocs=lon_grid,ylocs=lat_grid,\n",
    "                  x_inline=False,y_inline=False,color='k',linestyle='--',linewidth=0.4)\n",
    "        gl.top_labels = False\n",
    "        gl.right_labels = False\n",
    "        gl.left_labels = False\n",
    "        ax[k].set_title(time4h[k])\n",
    "        ax[k].set_title(abc[k], loc='left')\n",
    "        kw_clabels = {'fontsize': 11, 'inline': True, 'inline_spacing': 5, 'fmt': '%i',\n",
    "                          'rightside_up': True, 'use_clabeltext': True}\n",
    "        qcon = ax[k].contour(lons,lats,q[k],colors='black') #mslp contours\n",
    "        epcon = ax[k].contour(lons,lats,e[k],levels=[0.00006],colors='blue',extend='max')\n",
    "        dcon = ax[k].contour(lons,lats,d[k],levels=[-0.000015],linestyles='solid',colors='magenta',extend='min')\n",
    "\n",
    "        ax[k].clabel(qcon, **kw_clabels)\n",
    "        fronto = ax[k].contourf(qlon, qlat, f[k],levels=[-9e-10,-7.5e-10,-6e-10,-4.5e-10,-3e-10,-1.5e-10,0],transform=ccrs.PlateCarree(), \n",
    "                                colors=['saddlebrown','sienna','chocolate','darkorange','orange','navajowhite','white'],extend='min')\n",
    "        ax[k].coastlines()\n",
    "\n",
    "fig.subplots_adjust(bottom=0.3, top=0.9, left=0.1, right=0.9,\n",
    "                    wspace=0.02, hspace=0.3)\n",
    "# # Add a colorbar axis at the bottom of the graph\n",
    "cbar_ax = fig.add_axes([0.2, 0.2, 0.6, 0.02])\n",
    "\n",
    "# # Draw the colorbar\n",
    "cbar=fig.colorbar(fronto,cax=cbar_ax,spacing='proportional',orientation='horizontal',label='Frontogenesis ($g Kg^{-1} m^{-1} s^{-1}$)')\n",
    "# # Add a big title at the top\n",
    "plt.suptitle('Mean Fn and q\\n 1990-2020 at 925hPa',fontsize='xx-large')\n",
    "# save_results_to = '/g/data/k10/lr0203/final-plt/'\n",
    "# plt.savefig(save_results_to+'3int-annual-Fn.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147bbf36-bcbc-445d-ba43-c5b8321b069d",
   "metadata": {},
   "source": [
    "**Mean deformation and specific humidity 9-panel**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a304649-dc93-488e-bf59-515bc2c66cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#deformation\n",
    "#seasonal combine example\n",
    "ones = np.ones((81,181))\n",
    "q = [[] for x in range(9)]\n",
    "e = [[] for x in range(9)]\n",
    "b = [[] for x in range(9)]\n",
    "time4h = [\"1PM AEST AMJJ\",\"7PM AEST AMJJ\",\"1AM AEST AMJJ\",\"1PM AEST ASON\",\"7PM AEST ASON\",\"1AM AEST ASON\",\n",
    "          \"1PM AEST DJFM\",\"7PM AEST DJFM\",\"1AM AEST DJFM\"]\n",
    "abc = [\"a)\",\"b)\",\"c)\",\"d)\",\"e)\",\"f)\",\"g)\",\"h)\",\"i)\"]\n",
    "fig, ax = plt.subplots(3,3,subplot_kw={'projection': ccrs.PlateCarree()},figsize=(20,15))\n",
    "\n",
    "for j in range(0,3):\n",
    "    e1 = xr.open_dataarray('/g/data/k10/lr0203/Frontogenesis/Fn/April/Eprime_mean/Eprime_meanAPR'+UTC[(j*6)+3]+'.nc')\n",
    "    e2 = xr.open_dataarray('/g/data/k10/lr0203/Frontogenesis/Fn/May/Eprime_mean/Eprime_meanMAY'+UTC[(j*6)+3]+'.nc')\n",
    "    e3 = xr.open_dataarray('/g/data/k10/lr0203/Frontogenesis/Fn/June/Eprime_mean/Eprime_meanJUN'+UTC[(j*6)+3]+'.nc')\n",
    "    e4 = xr.open_dataarray('/g/data/k10/lr0203/Frontogenesis/Fn/July/Eprime_mean/Eprime_meanJUL'+UTC[(j*6)+3]+'.nc')\n",
    "    e5 = xr.open_dataarray('/g/data/k10/lr0203/Frontogenesis/Fn/August/Eprime_mean/Eprime_meanAUG'+UTC[(j*6)+3]+'.nc')\n",
    "    e6 = xr.open_dataarray('/g/data/k10/lr0203/Frontogenesis/Fn/September/Eprime_mean/Eprime_meanSEP'+UTC[(j*6)+3]+'.nc')\n",
    "    e7 = xr.open_dataarray('/g/data/k10/lr0203/Frontogenesis/Fn/October/Eprime_mean/Eprime_meanOCT'+UTC[(j*6)+3]+'.nc')\n",
    "    e8 = xr.open_dataarray('/g/data/k10/lr0203/Frontogenesis/Fn/November/Eprime_mean/Eprime_meanNOV'+UTC[(j*6)+3]+'.nc')\n",
    "    e9 = xr.open_dataarray('/g/data/k10/lr0203/Frontogenesis/Fn/December/Eprime_mean/Eprime_meanDEC'+UTC[(j*6)+3]+'.nc')\n",
    "    e10 = xr.open_dataarray('/g/data/k10/lr0203/Frontogenesis/Fn/January/Eprime_mean/Eprime_meanJAN'+UTC[(j*6)+3]+'.nc')\n",
    "    e11 = xr.open_dataarray('/g/data/k10/lr0203/Frontogenesis/Fn/February/Eprime_mean/Eprime_meanFEB'+UTC[(j*6)+3]+'.nc')\n",
    "    e12 = xr.open_dataarray('/g/data/k10/lr0203/Frontogenesis/Fn/March/Eprime_mean/Eprime_meanMAR'+UTC[(j*6)+3]+'.nc')\n",
    "    e[j] = (e1+e2+e3+e4)/4\n",
    "    e[j+3] = (e5+e6+e7+e8)/4\n",
    "    e[j+6] = (e9+e10+e11+e12)/4\n",
    "    \n",
    "    b1 = xr.open_dataarray('/g/data/k10/lr0203/Frontogenesis/Fn/April/delta_test/delta_testAPR'+UTC[(j*6)+3]+'.nc')\n",
    "    b2 = xr.open_dataarray('/g/data/k10/lr0203/Frontogenesis/Fn/May/delta_test/delta_testMAY'+UTC[(j*6)+3]+'.nc')\n",
    "    b3 = xr.open_dataarray('/g/data/k10/lr0203/Frontogenesis/Fn/June/delta_test/delta_testJUN'+UTC[(j*6)+3]+'.nc')\n",
    "    b4 = xr.open_dataarray('/g/data/k10/lr0203/Frontogenesis/Fn/July/delta_test/delta_testJUL'+UTC[(j*6)+3]+'.nc')\n",
    "    b5 = xr.open_dataarray('/g/data/k10/lr0203/Frontogenesis/Fn/August/delta_test/delta_testAUG'+UTC[(j*6)+3]+'.nc')\n",
    "    b6 = xr.open_dataarray('/g/data/k10/lr0203/Frontogenesis/Fn/September/delta_test/delta_testSEP'+UTC[(j*6)+3]+'.nc')\n",
    "    b7 = xr.open_dataarray('/g/data/k10/lr0203/Frontogenesis/Fn/October/delta_test/delta_testOCT'+UTC[(j*6)+3]+'.nc')\n",
    "    b8 = xr.open_dataarray('/g/data/k10/lr0203/Frontogenesis/Fn/November/delta_test/delta_testNOV'+UTC[(j*6)+3]+'.nc')\n",
    "    b9 = xr.open_dataarray('/g/data/k10/lr0203/Frontogenesis/Fn/December/delta_test/delta_testDEC'+UTC[(j*6)+3]+'.nc')\n",
    "    b10 = xr.open_dataarray('/g/data/k10/lr0203/Frontogenesis/Fn/January/delta_test/delta_testJAN'+UTC[(j*6)+3]+'.nc')\n",
    "    b11 = xr.open_dataarray('/g/data/k10/lr0203/Frontogenesis/Fn/February/delta_test/delta_testFEB'+UTC[(j*6)+3]+'.nc')\n",
    "    b12 = xr.open_dataarray('/g/data/k10/lr0203/Frontogenesis/Fn/March/delta_test/delta_testMAR'+UTC[(j*6)+3]+'.nc')\n",
    "    b[j] = (b1+b2+b3+b4)/4\n",
    "    b[j+3] = (b5+b6+b7+b8)/4\n",
    "    b[j+6] = (b9+b10+b11+b12)/4\n",
    "    \n",
    "    q1 = xr.open_dataarray('/g/data/k10/lr0203/SpecHum/April/qAPR'+UTC[(j*6)+3]+'.nc')\n",
    "    q2 = xr.open_dataarray('/g/data/k10/lr0203/SpecHum/May/qMAY'+UTC[(j*6)+3]+'.nc')\n",
    "    q3 = xr.open_dataarray('/g/data/k10/lr0203/SpecHum/June/qJUN'+UTC[(j*6)+3]+'.nc')\n",
    "    q4 = xr.open_dataarray('/g/data/k10/lr0203/SpecHum/July/qJUL'+UTC[(j*6)+3]+'.nc')\n",
    "    q5 = xr.open_dataarray('/g/data/k10/lr0203/SpecHum/August/qAUG'+UTC[(j*6)+3]+'.nc')\n",
    "    q6 = xr.open_dataarray('/g/data/k10/lr0203/SpecHum/September/qSEP'+UTC[(j*6)+3]+'.nc')\n",
    "    q7 = xr.open_dataarray('/g/data/k10/lr0203/SpecHum/October/qOCT'+UTC[(j*6)+3]+'.nc')\n",
    "    q8 = xr.open_dataarray('/g/data/k10/lr0203/SpecHum/November/qNOV'+UTC[(j*6)+3]+'.nc')\n",
    "    q9 = xr.open_dataarray('/g/data/k10/lr0203/SpecHum/December/qDEC'+UTC[(j*6)+3]+'.nc')\n",
    "    q10 = xr.open_dataarray('/g/data/k10/lr0203/SpecHum/January/qJAN'+UTC[(j*6)+3]+'.nc')\n",
    "    q11 = xr.open_dataarray('/g/data/k10/lr0203/SpecHum/February/qFEB'+UTC[(j*6)+3]+'.nc')\n",
    "    q12 = xr.open_dataarray('/g/data/k10/lr0203/SpecHum/March/qMAR'+UTC[(j*6)+3]+'.nc')\n",
    "    q[j] = (q1+q2+q3+q4)/4\n",
    "    q[j+3] = (q5+q6+q7+q8)/4\n",
    "    q[j+6] = (q9+q10+q11+q12)/4\n",
    "for k in range(0,9):\n",
    "    beta=b[k]\n",
    "    if k == 0 or k == 3 or k == 6:\n",
    "        ax=ax.flatten()\n",
    "        ax[k].set_extent([110, 155, -30, -10], ccrs.PlateCarree())\n",
    "        lons, lats = np.meshgrid(qlon, qlat)\n",
    "        lon_grid = np.arange(110,155,5)\n",
    "        lat_grid = np.arange(-30,-10,5)\n",
    "        gl = ax[k].gridlines(draw_labels=True,xlocs=lon_grid,ylocs=lat_grid,\n",
    "                  x_inline=False,y_inline=False,color='k',linestyle='--',linewidth=0.4)\n",
    "        gl.top_labels = False\n",
    "        gl.right_labels = False\n",
    "        ax[k].set_title(time4h[k])\n",
    "        ax[k].set_title(abc[k], loc='left')\n",
    "        ep = ax[k].contourf(qlon, qlat, e[k],levels=[4e-5,6e-5,8e-5,10e-5,12e-5,14e-5],transform=ccrs.PlateCarree(), \n",
    "                        cmap='viridis_r',extend='max')\n",
    "        quiver_slices = (slice(None, None, 9), slice(None, None, 7))\n",
    "        # Q1=ax[k].quiver(lons[quiver_slices],lats[quiver_slices],ones[quiver_slices],ones[quiver_slices],angles=[((beta[quiver_slices])*180/np.pi)],width=0.0025, pivot='mid')\n",
    "        kw_clabels = {'fontsize': 11, 'inline': True, 'inline_spacing': 5, 'fmt': '%i',\n",
    "                          'rightside_up': True, 'use_clabeltext': True}\n",
    "        qcon = ax[k].contour(lons,lats,q[k],colors='black') #mslp contours\n",
    "        ax[k].clabel(qcon, **kw_clabels)\n",
    "        ax[k].coastlines()\n",
    "    else:\n",
    "        ax=ax.flatten()\n",
    "        ax[k].set_extent([110, 155, -30, -10], ccrs.PlateCarree())\n",
    "        lons, lats = np.meshgrid(qlon, qlat)\n",
    "        lon_grid = np.arange(110,155,5)\n",
    "        lat_grid = np.arange(-30,-10,5)\n",
    "        gl = ax[k].gridlines(draw_labels=True,xlocs=lon_grid,ylocs=lat_grid,\n",
    "                  x_inline=False,y_inline=False,color='k',linestyle='--',linewidth=0.4)\n",
    "        gl.top_labels = False\n",
    "        gl.right_labels = False\n",
    "        gl.left_labels = False\n",
    "        ax[k].set_title(time4h[k])\n",
    "        ax[k].set_title(abc[k], loc='left')\n",
    "        ep = ax[k].contourf(qlon, qlat, e[k],levels=[4e-5,6e-5,8e-5,10e-5,12e-5,14e-5],transform=ccrs.PlateCarree(), \n",
    "                        cmap='viridis_r',extend='max')\n",
    "        quiver_slices = (slice(None, None, 9), slice(None, None, 7))\n",
    "        # Q1=ax[k].quiver(lons[quiver_slices],lats[quiver_slices],ones[quiver_slices],ones[quiver_slices],angles=[((beta[quiver_slices])*180/np.pi)],width=0.0025, pivot='mid')\n",
    "        kw_clabels = {'fontsize': 11, 'inline': True, 'inline_spacing': 5, 'fmt': '%i',\n",
    "                          'rightside_up': True, 'use_clabeltext': True}\n",
    "        qcon = ax[k].contour(lons,lats,q[k],colors='black') #mslp contours\n",
    "        ax[k].clabel(qcon, **kw_clabels)\n",
    "        ax[k].coastlines()\n",
    "\n",
    "fig.subplots_adjust(bottom=0.3, top=0.9, left=0.1, right=0.9,\n",
    "                    wspace=0.02, hspace=0.3)\n",
    "# # Add a colorbar axis at the bottom of the graph\n",
    "cbar_ax = fig.add_axes([0.2, 0.2, 0.6, 0.02])\n",
    "\n",
    "# # Draw the colorbar\n",
    "cbar=fig.colorbar(ep,cax=cbar_ax,spacing='proportional',orientation='horizontal',label='Deformation')\n",
    "# # Add a big title at the top\n",
    "plt.suptitle('Mean E\\' and q\\n 1990-2020 at 925hPa',fontsize='xx-large')\n",
    "save_results_to = '/g/data/k10/lr0203/final-plt/'\n",
    "plt.savefig(save_results_to+'deformation.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8133731f-942d-4e91-a727-c4ee27bf7081",
   "metadata": {},
   "source": [
    "**Vertical cross section over 16S for potential temperature and specific humidity (Offshore dryline analysis)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2ca37a-803c-449b-b44c-8c267c0bd9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lowest 5km is about 840hPa which is lvl 30\n",
    "#500hpa starts at lvl 21\n",
    "spec_hum = [[] for x in range(6)]\n",
    "clip = [[] for x in range(6)]\n",
    "time4h = [\"0000\",\"0400\",\"0800\",\"1200\",\"1600\",\"2000\"]\n",
    "fig, ax = plt.subplots(3,2,figsize=(15,15))\n",
    "lontemp = xr.open_mfdataset('/g/data/rt52/era5/pressure-levels/reanalysis/t/2020/t_era5_oper_pl_2020*')['t'].loc[:,500:1000,-16,110:130]\n",
    "lattemp = xr.open_mfdataset('/g/data/rt52/era5/pressure-levels/reanalysis/t/2020/t_era5_oper_pl_2020*')['t'].loc[:,500:1000,-10:-30,117]\n",
    "lat = lattemp.latitude\n",
    "lvl = lattemp.level\n",
    "lon = lontemp.longitude\n",
    "\n",
    "for j in range(0,6):\n",
    "    # data = xr.open_dataarray('/g/data/k10/lr0203/16S-110-130E/q/May/Data/V16-110-130qMAY'+UTC[j*4]+'.nc')\n",
    "    data = xr.open_dataarray('/g/data/k10/lr0203/16S-110-130E/theta/May/Data/V16-110-130thetaMAY'+UTC[j*4]+'.nc')\n",
    "    umean = xr.open_dataarray('/g/data/k10/lr0203/16S-110-130E/u/May/Data/V16-110-130uMAY'+UTC[j*4]+'.nc')\n",
    "    wmean = xr.open_dataarray('/g/data/k10/lr0203/16S-110-130E/w/May/Data/V16-110-130wMAY'+UTC[j*4]+'.nc')\n",
    "    u=umean\n",
    "    w=(wmean)/-11.76 #converts into m/s\n",
    "    cel = data-273.15\n",
    "    # spec_hum[j] = data*1000\n",
    "    clip[j]=np.clip(cel,26,48)\n",
    "    ax=ax.flatten()\n",
    "    x, y = np.meshgrid(lon, lvl)\n",
    "    grad = ax[j].contourf(lon,lvl, clip[j],8, cmap='coolwarm',extend='both',vmin=27,vmax=47)\n",
    "    quiver_slices = (slice(None, None, 2), slice(None, None, 6))\n",
    "    Q = ax[j].quiver(x[quiver_slices], y[quiver_slices], u[quiver_slices],100*w[quiver_slices])\n",
    "    ax[j].invert_yaxis()\n",
    "    ax[j].set_xlabel('Longitude ($^\\circ$)')\n",
    "    ax[j].set_ylabel('Pressure (hPa)')\n",
    "    ax[j].set_title(time4h[j]+'UTC')\n",
    "ax=ax.flatten()\n",
    "x, y = np.meshgrid(lon, lvl)\n",
    "grad1 = ax[1].contourf(lon,lvl, clip[1],8, cmap='coolwarm',extend='both',vmin=27,vmax=47)\n",
    "quiver_slices = (slice(None, None, 2), slice(None, None, 6))\n",
    "Q = ax[1].quiver(x[quiver_slices], y[quiver_slices], u[quiver_slices],100*w[quiver_slices])\n",
    "plt.quiverkey(Q, 0.81, 0.92, 5, r'$5 \\frac{m}{s}$', labelpos='E',\n",
    "           coordinates='figure',angle = 180, labelsep=0.3)\n",
    "\n",
    "# ax[1].invert_yaxis()\n",
    "ax[1].set_xlabel('Longitude ($^\\circ$)')\n",
    "ax[1].set_ylabel('Pressure (hPa)')\n",
    "ax[1].set_title(time4h[5]+'UTC')\n",
    "\n",
    "\n",
    "\n",
    "# Adjust the location of the subplots on the page to make room for the colorbar\n",
    "fig.subplots_adjust(bottom=0.3, top=0.9, left=0.1, right=0.9,\n",
    "                    wspace=0.2, hspace=0.4)\n",
    "# # Add a colorbar axis at the bottom of the graph\n",
    "cbar_ax = fig.add_axes([0.2, 0.2, 0.6, 0.02])\n",
    "\n",
    "# # Draw the colorbar\n",
    "cbar=fig.colorbar(grad,cax=cbar_ax,spacing='proportional',orientation='horizontal',label='Potential Temperature ($^\\circ$C)')\n",
    "\n",
    "# # Add a big title at the top\n",
    "plt.suptitle('Vertical circulation along 16$^\\circ$S \\n May 1990-2020',fontsize='xx-large')\n",
    "save_results_to = '/g/data/k10/lr0203/final-plt/16S-110-130E/'\n",
    "plt.savefig(save_results_to+'thetauwMAY4h-90-20.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2ea20b-f9c2-4891-917c-aeba3fc3afa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = xr.open_dataarray('/g/data/k10/lr0203/16S-110-130E/q/June/V16-110-130qJUN0800.nc')\n",
    "u = xr.open_dataarray('/g/data/k10/lr0203/16S-110-130E/u/June/V16-110-130uJUN0800.nc')\n",
    "w = xr.open_dataarray('/g/data/k10/lr0203/16S-110-130E/w/June/V16-110-130wJUN0800.nc')\n",
    "qmean = q.mean(dim='time')\n",
    "umean = u.mean(dim='time')\n",
    "wmean = w.mean(dim='time')\n",
    "lon = q.longitude\n",
    "lvl = q.level\n",
    "u1=umean\n",
    "w1=(wmean)/-11.76 #converts into m/s\n",
    "# cel = data-273.15\n",
    "spec_hum = qmean*1000\n",
    "plt.figure(figsize=(10,5))\n",
    "x, y = np.meshgrid(lon, lvl)\n",
    "grad = plt.contourf(lon,lvl, spec_hum,8, cmap='BrBG',extend='both')\n",
    "quiver_slices = (slice(None, None, 2), slice(None, None, 6))\n",
    "Q = plt.quiver(x[quiver_slices], y[quiver_slices], u1[quiver_slices],100*w1[quiver_slices])\n",
    "plt.colorbar(grad, orientation='horizontal',label='Specific Humidity (g$kg^{-1}$)',pad=0.15,fraction=0.05)\n",
    "plt.gca().invert_yaxis()\n",
    "plt.xlabel('Longitude ($^\\circ$)')\n",
    "plt.ylabel('Pressure (hPa)')\n",
    "plt.title('Vertical cross section along 16S\\nJUNE 0800UTC 1990-2020')\n",
    "save_results_to = '/g/data/k10/lr0203/final-plt/16S-110-130E/'\n",
    "plt.savefig(save_results_to+'JUN0800q.jpg')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30f40c1-d776-4bfe-b0a4-66830dc4fd8f",
   "metadata": {},
   "source": [
    "**Vertical cross section over 117E for specific humidity and potential temperature (Heat low analysis)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c9a948d-6f5f-4455-918d-6d87d28614ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lowest 5km is about 840hPa which is lvl 30\n",
    "#500hpa starts at lvl 21\n",
    "spec_hum = [[] for x in range(6)]\n",
    "clip = [[] for x in range(6)]\n",
    "time4h = [\"0000\",\"0400\",\"0800\",\"1200\",\"1600\",\"2000\"]\n",
    "fig, ax = plt.subplots(3,2,figsize=(15,15))\n",
    "lontemp = xr.open_mfdataset('/g/data/rt52/era5/pressure-levels/reanalysis/t/2020/t_era5_oper_pl_2020*')['t'].loc[:,500:1000,-16,110:130]\n",
    "lattemp = xr.open_mfdataset('/g/data/rt52/era5/pressure-levels/reanalysis/t/2020/t_era5_oper_pl_2020*')['t'].loc[:,500:1000,-10:-30,117]\n",
    "lat = lattemp.latitude\n",
    "lvl = lattemp.level\n",
    "lon = lontemp.longitude\n",
    "\n",
    "for j in range(0,6):\n",
    "    data = xr.open_dataarray('/g/data/k10/lr0203/117E-10-30S/q/December/Data/V117-10-30qDEC'+UTC[j*4]+'.nc')\n",
    "    # data = xr.open_dataarray('/g/data/k10/lr0203/117E-10-30S/theta/December/Data/V117-10-30thetaDEC'+UTC[j*4]+'.nc')\n",
    "    vmean = xr.open_dataarray('/g/data/k10/lr0203/117E-10-30S/v/December/Data/V117-10-30vDEC'+UTC[j*4]+'.nc')\n",
    "    wmean = xr.open_dataarray('/g/data/k10/lr0203/117E-10-30S/w/December/Data/V117-10-30wDEC'+UTC[j*4]+'.nc')\n",
    "    v=vmean\n",
    "    w=(wmean)/-11.76 #converts into m/s\n",
    "    # cel = data-273.15\n",
    "    spec_hum[j] = data*1000\n",
    "    clip[j]=np.clip(cel,26,48)\n",
    "    ax=ax.flatten()\n",
    "    x, y = np.meshgrid(lat, lvl)\n",
    "    grad = ax[j].contourf(lat,lvl, spec_hum[j],8, cmap='BrBG',extend='both')\n",
    "    quiver_slices = (slice(None, None, 2), slice(None, None, 6))\n",
    "    Q = ax[j].quiver(x[quiver_slices], y[quiver_slices], v[quiver_slices],100*w[quiver_slices])\n",
    "    ax[j].invert_yaxis()\n",
    "    ax[j].set_xlabel('Latitude ($^\\circ$)')\n",
    "    ax[j].set_ylabel('Pressure (hPa)')\n",
    "    ax[j].set_title(time4h[j]+'UTC')\n",
    "ax=ax.flatten()\n",
    "x, y = np.meshgrid(lat, lvl)\n",
    "grad1 = ax[1].contourf(lat,lvl, spec_hum[1],8, cmap='BrBG',extend='both')\n",
    "quiver_slices = (slice(None, None, 2), slice(None, None, 6))\n",
    "Q = ax[1].quiver(x[quiver_slices], y[quiver_slices], v[quiver_slices],100*w[quiver_slices])\n",
    "plt.quiverkey(Q, 0.81, 0.92, 2, r'$2 \\frac{m}{s}$', labelpos='E',\n",
    "           coordinates='figure',angle = 0, labelsep=0.1)\n",
    "\n",
    "# ax[1].invert_yaxis()\n",
    "ax[1].set_xlabel('Latitude ($^\\circ$)')\n",
    "ax[1].set_ylabel('Pressure (hPa)')\n",
    "ax[1].set_title(time4h[5]+'UTC')\n",
    "\n",
    "\n",
    "\n",
    "# Adjust the location of the subplots on the page to make room for the colorbar\n",
    "fig.subplots_adjust(bottom=0.3, top=0.9, left=0.1, right=0.9,\n",
    "                    wspace=0.2, hspace=0.4)\n",
    "# # Add a colorbar axis at the bottom of the graph\n",
    "cbar_ax = fig.add_axes([0.2, 0.2, 0.6, 0.02])\n",
    "\n",
    "# # Draw the colorbar\n",
    "cbar=fig.colorbar(grad,cax=cbar_ax,spacing='proportional',orientation='horizontal',label='Specific Humidity (g/Kg)')\n",
    "\n",
    "# # Add a big title at the top\n",
    "plt.suptitle('Vertical circulation along 117$^\\circ$E \\n DEC 1990-2020',fontsize='xx-large')\n",
    "save_results_to = '/g/data/k10/lr0203/final-plt/117E-10-30S/'\n",
    "plt.savefig(save_results_to+'quwDEC4h-90-20.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a89dde-5d3f-430f-bcca-c612c054d36a",
   "metadata": {},
   "source": [
    "# Start Monsoon analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f0a72c74-da2f-4a55-9aa1-904d55dad07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# traching the dryline progression through the monsoon period\n",
    "febdaily = [[] for x in range(31)]\n",
    "meanfebdaily = [[] for x in range(28)]\n",
    "meandecdaily = [[] for x in range(31)]\n",
    "meanjandaily = [[] for x in range(31)]\n",
    "meanmardaily = [[] for x in range(31)]\n",
    "for i in range(0,24): #hour looop\n",
    "    decgradq = xr.open_dataarray('/g/data/k10/lr0203/gradq/December/gradqfull/gradqfullDEC'+UTC[i]+'.nc')\n",
    "    jangradq = xr.open_dataarray('/g/data/k10/lr0203/gradq/January/gradqfull/gradqfullJAN'+UTC[i]+'.nc')\n",
    "    febgradq = xr.open_dataarray('/g/data/k10/lr0203/gradq/February/gradqfull/gradqfullFEB'+UTC[i]+'.nc')\n",
    "    margradq = xr.open_dataarray('/g/data/k10/lr0203/gradq/March/gradqfull/gradqfullMAR'+UTC[i]+'.nc')\n",
    "    mtime  = list(np.arange(0,121))\n",
    "    for j in range(0,31): #month length\n",
    "        decdaily = decgradq[j::31]\n",
    "        jandaily = jangradq[j::31]\n",
    "        mardaily = margradq[j::31]\n",
    "        meandecdaily[j] = decdaily.mean(dim='time')\n",
    "        meanjandaily[j] = jandaily.mean(dim='time')\n",
    "        meanmardaily[j] = mardaily.mean(dim='time')\n",
    "    febyearly =[febgradq[0:28],febgradq[28:56],febgradq[56:85],febgradq[85:113],febgradq[113:141],febgradq[141:169],febgradq[169:198],\n",
    "                febgradq[198:226],febgradq[226:254],febgradq[254:282],febgradq[282:311],febgradq[311:339],febgradq[339:367],febgradq[367:395],\n",
    "               febgradq[395:424],febgradq[424:452],febgradq[452:480],febgradq[480:508],febgradq[508:537],febgradq[537:565],febgradq[565:593],\n",
    "                febgradq[593:621],febgradq[621:650],febgradq[650:678],febgradq[678:706],febgradq[706:734],febgradq[734:763],febgradq[763:791],\n",
    "                febgradq[791:819],febgradq[819:847],febgradq[847:876]]\n",
    "    for k in range(0,28):\n",
    "        for m in range(0,31): #year loop\n",
    "            febdaily[m] = febyearly[m][k]\n",
    "        meanfebdaily[k] = np.mean(febdaily,axis=0)\n",
    "    monsoondaily = np.concatenate([meandecdaily,meanjandaily,meanfebdaily,meanmardaily],axis=0)\n",
    "    xr.DataArray(monsoondaily,dims=[\"time\",\"latitude\",\"longitude\"],coords=dict(time=mtime,latitude=qlat,longitude=qlon)).to_netcdf(path='/g/data/k10/lr0203/Monsoon/monsoon_daily/monsoondaily'+UTC[i]+'.nc')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77204724-aeea-4028-8841-501cc5c591f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9c234565-b449-4cc3-bb69-ad289ab6db2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'10/01'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6b1519e7-dc3c-4cd2-8fcd-c9a10202196d",
   "metadata": {},
   "source": [
    "# Start monsoon code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37d05493-db26-4f6f-8995-5c0cce8fb48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------First attempt at monsoon code--------------------------------------------------------------------------------------------------\n",
    "#define the monsoon rainfall box from 10-20S 120-150E\n",
    "#calculate total rainfall that occurs in DJFM climatology period\n",
    "# traching the dryline progression through the monsoon period\n",
    "monsoondate = ['01/12','02/12','03/12','04/12','05/12','06/12','07/12','08/12','09/12','10/12','11/12','12/12','13/12','14/12','15/12','16/12','17/12','18/12',\n",
    "               '19/12','20/12','21/12','22/12','23/12','24/12','25/12','26/12','27/12','28/12','29/12','30/12','31/12','01/01','02/01','03/01','04/01','05/01',\n",
    "               '06/01','07/01','08/01','09/01','10/01','11/01','12/01','13/01','14/01','15/01','16/01','17/01','18/01','19/01','20/01','21/01','22/01','23/01',\n",
    "               '24/01','25/01','26/01','27/01','28/01','29/01','30/01','31/01','01/02','02/02','03/02','04/02','05/02','06/02','07/02','08/02','09/02','10/02',\n",
    "               '11/02','12/02','13/02','14/02','15/02','16/02','17/02','18/02','19/02','20/02','21/02','22/02','23/02','24/02','25/02','26/02','27/02','28/02',\n",
    "               '01/03','02/03','03/03','04/03','05/03','06/03','07/03','08/03','09/03','10/03','11/03','12/03','13/03','14/03','15/03','16/03','17/03','18/03',\n",
    "               '19/03','20/03','21/03','22/03','23/03','24/03','25/03','26/03','27/03','28/03','29/03','30/03','31/03']\n",
    "febdaily = [[] for x in range(31)]\n",
    "meanfebdaily = [[] for x in range(28)]\n",
    "meandecdaily = [[] for x in range(31)]\n",
    "meanjandaily = [[] for x in range(31)]\n",
    "meanmardaily = [[] for x in range(31)]\n",
    "for i in range(0,24): #hour looop\n",
    "    decgradq = xr.open_dataarray('/g/data/k10/lr0203/MTPR/December/MTPRdaily/MTPRdailyDEC'+UTC[i]+'.nc')\n",
    "    jangradq = xr.open_dataarray('/g/data/k10/lr0203/MTPR/January/MTPRdaily/MTPRdailyJAN'+UTC[i]+'.nc')\n",
    "    febgradq = xr.open_dataarray('/g/data/k10/lr0203/MTPR/February/MTPRdaily/MTPRdailyFEB'+UTC[i]+'.nc')\n",
    "    margradq = xr.open_dataarray('/g/data/k10/lr0203/MTPR/March/MTPRdaily/MTPRdailyMAR'+UTC[i]+'.nc')\n",
    "    mlat = decgradq.latitude\n",
    "    mlon = decgradq.longitude\n",
    "    # mtime  = list(np.arange(0,121))\n",
    "    for j in range(0,31): #month length\n",
    "        decdaily = decgradq[j::31]\n",
    "        jandaily = jangradq[j::31]\n",
    "        mardaily = margradq[j::31]\n",
    "        meandecdaily[j] = decdaily.mean(dim='time')\n",
    "        meanjandaily[j] = jandaily.mean(dim='time')\n",
    "        meanmardaily[j] = mardaily.mean(dim='time')\n",
    "    febyearly =[febgradq[0:28],febgradq[28:56],febgradq[56:85],febgradq[85:113],febgradq[113:141],febgradq[141:169],febgradq[169:198],\n",
    "                febgradq[198:226],febgradq[226:254],febgradq[254:282],febgradq[282:311],febgradq[311:339],febgradq[339:367],febgradq[367:395],\n",
    "                febgradq[395:424],febgradq[424:452],febgradq[452:480],febgradq[480:508],febgradq[508:537],febgradq[537:565],febgradq[565:593],\n",
    "                febgradq[593:621],febgradq[621:650],febgradq[650:678],febgradq[678:706],febgradq[706:734],febgradq[734:763],febgradq[763:791],\n",
    "                febgradq[791:819],febgradq[819:847],febgradq[847:876]]\n",
    "    for k in range(0,28):\n",
    "        for m in range(0,31): #year loop\n",
    "            febdaily[m] = febyearly[m][k]\n",
    "        meanfebdaily[k] = np.mean(febdaily,axis=0)\n",
    "    monsoondaily = np.concatenate([meandecdaily,meanjandaily,meanfebdaily,meanmardaily],axis=0)\n",
    "    xr.DataArray(monsoondaily,dims=[\"time\",\"latitude\",\"longitude\"],coords=dict(time=monsoondate,latitude=mlat,longitude=mlon)).to_netcdf(path='/g/data/k10/lr0203/Monsoon/monsoon_daily_pcp/monsoondailypcp'+UTC[i]+'.nc')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "091411cf-b2f5-4202-b19c-a104d4690348",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "from dask.diagnostics import ProgressBar\n",
    "import matplotlib.pyplot as plt\n",
    "monsoondate = ['01/12','02/12','03/12','04/12','05/12','06/12','07/12','08/12','09/12','10/12','11/12','12/12','13/12','14/12','15/12','16/12','17/12','18/12',\n",
    "               '19/12','20/12','21/12','22/12','23/12','24/12','25/12','26/12','27/12','28/12','29/12','30/12','31/12','01/01','02/01','03/01','04/01','05/01',\n",
    "               '06/01','07/01','08/01','09/01','10/01','11/01','12/01','13/01','14/01','15/01','16/01','17/01','18/01','19/01','20/01','21/01','22/01','23/01',\n",
    "               '24/01','25/01','26/01','27/01','28/01','29/01','30/01','31/01','01/02','02/02','03/02','04/02','05/02','06/02','07/02','08/02','09/02','10/02',\n",
    "               '11/02','12/02','13/02','14/02','15/02','16/02','17/02','18/02','19/02','20/02','21/02','22/02','23/02','24/02','25/02','26/02','27/02','28/02',\n",
    "               '01/03','02/03','03/03','04/03','05/03','06/03','07/03','08/03','09/03','10/03','11/03','12/03','13/03','14/03','15/03','16/03','17/03','18/03',\n",
    "               '19/03','20/03','21/03','22/03','23/03','24/03','25/03','26/03','27/03','28/03','29/03','30/03','31/03']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d291be04-7286-4895-86e4-b52fbb63155b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in range(1990,2021):\n",
    "    print(year)\n",
    "    year_string=str(year)\n",
    "    mtpr=xr.open_mfdataset('/g/data/rt52/era5/single-levels/reanalysis/mtpr/'+year_string+'/mtpr_era5_oper_sfc_'+year_string+'[01][123]*')\n",
    "    box_av_mtpr_year=mtpr['mtpr'].loc[:,-10:-20,120:150].mean(dim=['latitude','longitude']).resample(time='1D').mean()*86400 #86400 converts rainrates from kg m^-2 s^-1 to mm/day\n",
    "    if year==1990:\n",
    "        box_av_mtpr=box_av_mtpr_year\n",
    "    else:\n",
    "        box_av_mtpr=xr.concat([box_av_mtpr,box_av_mtpr_year],dim='time')\n",
    "with ProgressBar():\n",
    "    box_av_mtpr=box_av_mtpr.compute()\n",
    "\n",
    "xr.DataArray(box_av_mtpr).to_netcdf(path='/g/data/k10/lr0203/Monsoon/box_av_mtpr.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9982cae6-80b6-4db4-811a-11aacd2a32b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "box_av_mtpr = xr.open_dataarray('/g/data/k10/lr0203/Monsoon/box_av_mtpr.nc')\n",
    "clim=box_av_mtpr.groupby(\"time.dayofyear\").mean()\n",
    "monsoonclim=np.concatenate([clim[335:365].data,clim[0:90].data])\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(monsoonclim)\n",
    "plt.title('Mean rainfall rate over monsoon period 1990-2020')\n",
    "plt.ylabel('Rainfall rate (mm/day)')\n",
    "plt.xticks([0,20,40,60,80,100,120],['01/12','21/12','10/01','30/01','19/02','11/03','31/03'])\n",
    "plt.show()\n",
    "save_results_to = '/g/data/k10/lr0203/Monsoon/plots/'\n",
    "plt.savefig(save_results_to+'Mean_monsoon_pcp.png', dpi=300, bbox_inches='tight')\n",
    "# xr.DataArray(monsoonclim).to_netcdf(path='/g/data/k10/lr0203/Monsoon/moncoonclim.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54aa0da9-dc98-4099-a39c-1a317f8c4ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "monsoon_day=np.zeros(len(box_av_mtpr),dtype=int)\n",
    "for m in range(len(box_av_mtpr)):\n",
    "    if box_av_mtpr[m]['time.month']==12:\n",
    "        monsoon_day[m]=box_av_mtpr[m]['time.day']\n",
    "    else:\n",
    "        monsoon_day[m]=box_av_mtpr[m]['time.dayofyear']+31\n",
    "xr.DataArray(monsoon_day).to_netcdf(path='/g/data/k10/lr0203/Monsoon/monsoon_day.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6558d1f3-917d-4bde-90ca-e6b61221111c",
   "metadata": {},
   "outputs": [],
   "source": [
    "upper_quartile=np.zeros(120)\n",
    "lower_quartile=np.zeros(120)\n",
    "for n in range(1,121):\n",
    "    upper_quartile[n-1]=box_av_mtpr[monsoon_day==n].quantile(q=.75)\n",
    "    lower_quartile[n-1]=box_av_mtpr[monsoon_day==n].quantile(q=.25)\n",
    "xr.DataArray(upper_quartile).to_netcdf(path='/g/data/k10/lr0203/Monsoon/upper_quantile.nc')\n",
    "xr.DataArray(lower_quartile).to_netcdf(path='/g/data/k10/lr0203/Monsoon/lower_quantile.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef8dd89-0ff5-4582-9ae6-6484f3dea65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "box_av_mtpr = xr.open_dataarray('/g/data/k10/lr0203/Monsoon/box_av_mtpr.nc')\n",
    "upper_quartile = xr.open_dataarray('/g/data/k10/lr0203/Monsoon/upper_quantile.nc')\n",
    "lower_quartile = xr.open_dataarray('/g/data/k10/lr0203/Monsoon/lower_quantile.nc')\n",
    "# monsoonclim = xr.open_dataarray('/g/data/k10/lr0203/Monsoon/moncoonclim.nc')\n",
    "clim=box_av_mtpr.groupby(\"time.dayofyear\").mean()\n",
    "monsoonclim=np.concatenate([clim[335:365].data,clim[0:90].data])\n",
    "plt.figure(figsize=(10,5))\n",
    "# plt.figure(1)\n",
    "plt.plot(upper_quartile,c='r')\n",
    "plt.plot(monsoonclim,'k')\n",
    "plt.plot(lower_quartile,c='b')\n",
    "plt.ylabel('Rainfall rate (mm/day)')\n",
    "plt.title('Mean rainfall rate for monsoon period 1990-2020')\n",
    "plt.legend(['Upper quantile (>75%)','Mean rainfall rate', 'Lower quantile (<25%)'])\n",
    "plt.xticks([0,20,40,60,80,100,120],['01/12','21/12','10/01','30/01','19/02','11/03','31/03'])\n",
    "plt.show()\n",
    "# save_results_to = '/g/data/k10/lr0203/Monsoon/plots/'\n",
    "# plt.savefig(save_results_to+'Mean_quantile_monsoon_pcp.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdad18f-9cd1-49d2-a3f2-c948ee645a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "upper_quartile=np.zeros(24)\n",
    "lower_quartile=np.zeros(24)\n",
    "for n in range(24):\n",
    "    upper_quartile[n]=box_av_mtpr[np.isin(monsoon_day,range(5*n+1,5*n+6))].quantile(q=.75)\n",
    "    lower_quartile[n]=box_av_mtpr[np.isin(monsoon_day,range(5*n+1,5*n+6))].quantile(q=.25)\n",
    "clim=box_av_mtpr.groupby(\"time.dayofyear\").mean()\n",
    "monsoonclim=np.concatenate([clim[335:365].data,clim[0:90].data])\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(np.arange(2,120,5),upper_quartile,c='r')\n",
    "plt.plot(monsoonclim,'k')\n",
    "plt.plot(np.arange(2,120,5),lower_quartile,c='b')\n",
    "plt.ylabel('Rainfall rate (mm/day)')\n",
    "plt.legend(['Upper quantile (>75%)','Mean rainfall rate', 'Lower quantile (<25%)'])\n",
    "\n",
    "plt.title('Mean rainfall rate for monsoon period smoothed over pentads 1990-2020')\n",
    "plt.xticks([0,20,40,60,80,100,120],['01/12','21/12','10/01','30/01','19/02','11/03','31/03'])\n",
    "plt.show()\n",
    "# xr.DataArray(upper_quartile).to_netcdf(path='/g/data/k10/lr0203/Monsoon/pen_upper_quantile.nc')\n",
    "# xr.DataArray(lower_quartile).to_netcdf(path='/g/data/k10/lr0203/Monsoon/pen_lower_quantile.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b375ce-c7de-4341-8c9d-28890a43a7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "box_av_mtpr = xr.open_dataarray('/g/data/k10/lr0203/Monsoon/box_av_mtpr.nc')\n",
    "upper_quartile = xr.open_dataarray('/g/data/k10/lr0203/Monsoon/pen_upper_quantile.nc')\n",
    "lower_quartile = xr.open_dataarray('/g/data/k10/lr0203/Monsoon/pen_lower_quantile.nc')\n",
    "monsoonclim = xr.open_dataarray('/g/data/k10/lr0203/Monsoon/moncoonclim.nc')\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(box_av_mtpr.loc['2015-12-01':'2016-03-31'].data,c='k')\n",
    "plt.plot(monsoonclim)\n",
    "plt.plot(np.arange(2,120,5),upper_quartile,c='r')\n",
    "plt.plot(np.arange(2,120,5),lower_quartile,c='r')\n",
    "plt.ylabel('Rainfall rate (mm/day)')\n",
    "plt.xticks([0,20,40,60,80,100,120],['01/12','21/12','10/01','30/01','19/02','11/03','31/03'])\n",
    "plt.title(\"2015-2016 Monsoon rainfall compared to climatology\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30486eb6-13c7-4c3b-91c4-46583341ef62",
   "metadata": {},
   "source": [
    "**Concat variables into strings for length of monsoon period Dec-Mar**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006a760f-0aa3-4aee-b19e-5cb9f28e3809",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(8,24): #hour looop\n",
    "    decgradq = xr.open_dataarray('/g/data/k10/lr0203/gradq/December/gradqfull/new_gradqfullDEC'+UTC[i]+'.nc')\n",
    "    jangradq = xr.open_dataarray('/g/data/k10/lr0203/gradq/January/gradqfull/new_gradqfullJAN'+UTC[i]+'.nc')\n",
    "    febgradq = xr.open_dataarray('/g/data/k10/lr0203/gradq/February/gradqfull/new_gradqfullFEB'+UTC[i]+'.nc')\n",
    "    margradq = xr.open_dataarray('/g/data/k10/lr0203/gradq/March/gradqfull/new_gradqfullMAR'+UTC[i]+'.nc')\n",
    "    for j in range(0,31): #month length\n",
    "        decdaily = decgradq[(j*31):(j*31)+31]\n",
    "        jandaily = jangradq[(j*31):(j*31)+31]\n",
    "        mardaily = margradq[(j*31):(j*31)+31]\n",
    "        febyearly = [febgradq[0:28],febgradq[28:56],febgradq[56:85],febgradq[85:113],febgradq[113:141],febgradq[141:169],febgradq[169:198],\n",
    "                    febgradq[198:226],febgradq[226:254],febgradq[254:282],febgradq[282:311],febgradq[311:339],febgradq[339:367],febgradq[367:395],\n",
    "                    febgradq[395:424],febgradq[424:452],febgradq[452:480],febgradq[480:508],febgradq[508:537],febgradq[537:565],febgradq[565:593],\n",
    "                    febgradq[593:621],febgradq[621:650],febgradq[650:678],febgradq[678:706],febgradq[706:734],febgradq[734:763],febgradq[763:791],\n",
    "                    febgradq[791:819],febgradq[819:847],febgradq[847:876]]\n",
    "        monsoon = xr.concat([decdaily,jandaily,febyearly[j],mardaily],dim='time')\n",
    "        if j == 0:\n",
    "            monsoon_yearly = monsoon\n",
    "        else:\n",
    "            monsoon_yearly = xr.concat([monsoon_yearly,monsoon],dim='time')\n",
    "    xr.DataArray(monsoon_yearly).to_netcdf(path='/g/data/k10/lr0203/Monsoon/new_monsoonyearly'+UTC[i]+'.nc')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ad80673-8d58-49c4-933f-e6d08fd6aa1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(15,16): #hour looop\n",
    "    dectheta = xr.open_dataarray('/g/data/k10/lr0203/theta/December/Full_data/thetafullDEC'+UTC[i]+'.nc')\n",
    "    jantheta = xr.open_dataarray('/g/data/k10/lr0203/theta/January/Full_data/thetafullJAN'+UTC[i]+'.nc')\n",
    "    febgradq = xr.open_dataarray('/g/data/k10/lr0203/theta/February/Full_data/thetafullFEB'+UTC[i]+'.nc')\n",
    "    martheta = xr.open_dataarray('/g/data/k10/lr0203/theta/March/Full_data/thetafullMAR'+UTC[i]+'.nc')\n",
    "    for j in range(0,31): #month length\n",
    "        decdaily = dectheta[(j*31):(j*31)+31]\n",
    "        jandaily = jantheta[(j*31):(j*31)+31]\n",
    "        mardaily = martheta[(j*31):(j*31)+31]\n",
    "        febyearly = [febgradq[0:28],febgradq[28:56],febgradq[56:85],febgradq[85:113],febgradq[113:141],febgradq[141:169],febgradq[169:198],\n",
    "                    febgradq[198:226],febgradq[226:254],febgradq[254:282],febgradq[282:311],febgradq[311:339],febgradq[339:367],febgradq[367:395],\n",
    "                    febgradq[395:424],febgradq[424:452],febgradq[452:480],febgradq[480:508],febgradq[508:537],febgradq[537:565],febgradq[565:593],\n",
    "                    febgradq[593:621],febgradq[621:650],febgradq[650:678],febgradq[678:706],febgradq[706:734],febgradq[734:763],febgradq[763:791],\n",
    "                    febgradq[791:819],febgradq[819:847],febgradq[847:876]]\n",
    "        monsoon = xr.concat([decdaily,jandaily,febyearly[j],mardaily],dim='time')\n",
    "        if j == 0:\n",
    "            monsoon_yearly = monsoon\n",
    "        else:\n",
    "            monsoon_yearly = xr.concat([monsoon_yearly,monsoon],dim='time')\n",
    "    xr.DataArray(monsoon_yearly).to_netcdf(path='/g/data/k10/lr0203/Monsoon/theta_monsoonyearly'+UTC[i]+'.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7a2b194-2a7c-4126-9a64-f77472b3aa2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3,4): #hour looop\n",
    "    dectheta = xr.open_dataarray('/g/data/k10/lr0203/Frontogenesis/Fn/December/Fn_Fronto/Fn_FrontoDEC'+UTC[i]+'.nc')\n",
    "    jantheta = xr.open_dataarray('/g/data/k10/lr0203/Frontogenesis/Fn/January/Fn_Fronto/Fn_FrontoJAN'+UTC[i]+'.nc')\n",
    "    febgradq = xr.open_dataarray('/g/data/k10/lr0203/Frontogenesis/Fn/February/Fn_Fronto/Fn_FrontoFEB'+UTC[i]+'.nc')\n",
    "    martheta = xr.open_dataarray('/g/data/k10/lr0203/Frontogenesis/Fn/March/Fn_Fronto/Fn_FrontoMAR'+UTC[i]+'.nc')\n",
    "    for j in range(0,31): #month length\n",
    "        decdaily = dectheta[(j*31):(j*31)+31]\n",
    "        jandaily = jantheta[(j*31):(j*31)+31]\n",
    "        mardaily = martheta[(j*31):(j*31)+31]\n",
    "        febyearly = [febgradq[0:28],febgradq[28:56],febgradq[56:85],febgradq[85:113],febgradq[113:141],febgradq[141:169],febgradq[169:198],\n",
    "                    febgradq[198:226],febgradq[226:254],febgradq[254:282],febgradq[282:311],febgradq[311:339],febgradq[339:367],febgradq[367:395],\n",
    "                    febgradq[395:424],febgradq[424:452],febgradq[452:480],febgradq[480:508],febgradq[508:537],febgradq[537:565],febgradq[565:593],\n",
    "                    febgradq[593:621],febgradq[621:650],febgradq[650:678],febgradq[678:706],febgradq[706:734],febgradq[734:763],febgradq[763:791],\n",
    "                    febgradq[791:819],febgradq[819:847],febgradq[847:876]]\n",
    "        monsoon = xr.concat([decdaily,jandaily,febyearly[j],mardaily],dim='time')\n",
    "        if j == 0:\n",
    "            monsoon_yearly = monsoon\n",
    "        else:\n",
    "            monsoon_yearly = xr.concat([monsoon_yearly,monsoon],dim='time')\n",
    "    xr.DataArray(monsoon_yearly).to_netcdf(path='/g/data/k10/lr0203/Monsoon/Fn_monsoonyearly'+UTC[i]+'.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "224a4201-e375-4c79-a6ed-cb49eba5d099",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(15,16): #hour looop\n",
    "    dectheta = xr.open_dataarray('/g/data/k10/lr0203/SpecHum/December/qgfull/qgDEC'+UTC[i]+'.nc')*1000\n",
    "    jantheta = xr.open_dataarray('/g/data/k10/lr0203/SpecHum/January/qgfull/qgJAN'+UTC[i]+'.nc')*1000\n",
    "    febgradq = xr.open_dataarray('/g/data/k10/lr0203/SpecHum/February/qgfull/qgFEB'+UTC[i]+'.nc')*1000\n",
    "    martheta = xr.open_dataarray('/g/data/k10/lr0203/SpecHum/March/qgfull/qgMAR'+UTC[i]+'.nc')*1000\n",
    "    for j in range(0,31): #month length\n",
    "        decdaily = dectheta[(j*31):(j*31)+31]\n",
    "        jandaily = jantheta[(j*31):(j*31)+31]\n",
    "        mardaily = martheta[(j*31):(j*31)+31]\n",
    "        febyearly = [febgradq[0:28],febgradq[28:56],febgradq[56:85],febgradq[85:113],febgradq[113:141],febgradq[141:169],febgradq[169:198],\n",
    "                    febgradq[198:226],febgradq[226:254],febgradq[254:282],febgradq[282:311],febgradq[311:339],febgradq[339:367],febgradq[367:395],\n",
    "                    febgradq[395:424],febgradq[424:452],febgradq[452:480],febgradq[480:508],febgradq[508:537],febgradq[537:565],febgradq[565:593],\n",
    "                    febgradq[593:621],febgradq[621:650],febgradq[650:678],febgradq[678:706],febgradq[706:734],febgradq[734:763],febgradq[763:791],\n",
    "                    febgradq[791:819],febgradq[819:847],febgradq[847:876]]\n",
    "        monsoon = xr.concat([decdaily,jandaily,febyearly[j],mardaily],dim='time')\n",
    "        if j == 0:\n",
    "            monsoon_yearly = monsoon\n",
    "        else:\n",
    "            monsoon_yearly = xr.concat([monsoon_yearly,monsoon],dim='time')\n",
    "    xr.DataArray(monsoon_yearly).to_netcdf(path='/g/data/k10/lr0203/Monsoon/q_monsoonyearly'+UTC[i]+'.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc779953-57c3-4680-baec-a57d7fd7d2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(15,16): #hour looop\n",
    "    dectheta = xr.open_dataarray('/g/data/k10/lr0203/Frontogenesis/Fn/December/D/DDEC'+UTC[i]+'.nc')\n",
    "    jantheta = xr.open_dataarray('/g/data/k10/lr0203/Frontogenesis/Fn/January/D/DJAN'+UTC[i]+'.nc')\n",
    "    febgradq = xr.open_dataarray('/g/data/k10/lr0203/Frontogenesis/Fn/February/D/DFEB'+UTC[i]+'.nc')\n",
    "    martheta = xr.open_dataarray('/g/data/k10/lr0203/Frontogenesis/Fn/March/D/DMAR'+UTC[i]+'.nc')\n",
    "    for j in range(0,31): #month length\n",
    "        decdaily = dectheta[(j*31):(j*31)+31]\n",
    "        jandaily = jantheta[(j*31):(j*31)+31]\n",
    "        mardaily = martheta[(j*31):(j*31)+31]\n",
    "        febyearly = [febgradq[0:28],febgradq[28:56],febgradq[56:85],febgradq[85:113],febgradq[113:141],febgradq[141:169],febgradq[169:198],\n",
    "                    febgradq[198:226],febgradq[226:254],febgradq[254:282],febgradq[282:311],febgradq[311:339],febgradq[339:367],febgradq[367:395],\n",
    "                    febgradq[395:424],febgradq[424:452],febgradq[452:480],febgradq[480:508],febgradq[508:537],febgradq[537:565],febgradq[565:593],\n",
    "                    febgradq[593:621],febgradq[621:650],febgradq[650:678],febgradq[678:706],febgradq[706:734],febgradq[734:763],febgradq[763:791],\n",
    "                    febgradq[791:819],febgradq[819:847],febgradq[847:876]]\n",
    "        monsoon = xr.concat([decdaily,jandaily,febyearly[j],mardaily],dim='time')\n",
    "        if j == 0:\n",
    "            monsoon_yearly = monsoon\n",
    "        else:\n",
    "            monsoon_yearly = xr.concat([monsoon_yearly,monsoon],dim='time')\n",
    "    xr.DataArray(monsoon_yearly).to_netcdf(path='/g/data/k10/lr0203/Monsoon/D_monsoonyearly'+UTC[i]+'.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb7e92d4-734f-45b2-bf4a-7adba3f7ac3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3,4): #hour looop\n",
    "    dectheta = xr.open_dataarray('/g/data/k10/lr0203/Frontogenesis/Fn/December/Eprime/EprimeDEC'+UTC[i]+'.nc')\n",
    "    jantheta = xr.open_dataarray('/g/data/k10/lr0203/Frontogenesis/Fn/January/Eprime/EprimeJAN'+UTC[i]+'.nc')\n",
    "    febgradq = xr.open_dataarray('/g/data/k10/lr0203/Frontogenesis/Fn/February/Eprime/EprimeFEB'+UTC[i]+'.nc')\n",
    "    martheta = xr.open_dataarray('/g/data/k10/lr0203/Frontogenesis/Fn/March/Eprime/EprimeMAR'+UTC[i]+'.nc')\n",
    "    for j in range(0,31): #month length\n",
    "        decdaily = dectheta[(j*31):(j*31)+31]\n",
    "        jandaily = jantheta[(j*31):(j*31)+31]\n",
    "        mardaily = martheta[(j*31):(j*31)+31]\n",
    "        febyearly = [febgradq[0:28],febgradq[28:56],febgradq[56:85],febgradq[85:113],febgradq[113:141],febgradq[141:169],febgradq[169:198],\n",
    "                    febgradq[198:226],febgradq[226:254],febgradq[254:282],febgradq[282:311],febgradq[311:339],febgradq[339:367],febgradq[367:395],\n",
    "                    febgradq[395:424],febgradq[424:452],febgradq[452:480],febgradq[480:508],febgradq[508:537],febgradq[537:565],febgradq[565:593],\n",
    "                    febgradq[593:621],febgradq[621:650],febgradq[650:678],febgradq[678:706],febgradq[706:734],febgradq[734:763],febgradq[763:791],\n",
    "                    febgradq[791:819],febgradq[819:847],febgradq[847:876]]\n",
    "        monsoon = xr.concat([decdaily,jandaily,febyearly[j],mardaily],dim='time')\n",
    "        if j == 0:\n",
    "            monsoon_yearly = monsoon\n",
    "        else:\n",
    "            monsoon_yearly = xr.concat([monsoon_yearly,monsoon],dim='time')\n",
    "    xr.DataArray(monsoon_yearly).to_netcdf(path='/g/data/k10/lr0203/Monsoon/Eprime_monsoonyearly'+UTC[i]+'.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2dc70496-c081-43ab-8079-d27dfc6d0bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(15,16): #hour looop\n",
    "    decgradq = xr.open_dataarray('/g/data/k10/lr0203/Winds/uageo/December/uageo_full/uageofullDEC'+UTC[i]+'.nc')\n",
    "    jangradq = xr.open_dataarray('/g/data/k10/lr0203/Winds/uageo/January/uageo_full/uageofullJAN'+UTC[i]+'.nc')\n",
    "    febgradq = xr.open_dataarray('/g/data/k10/lr0203/Winds/uageo/February/uageo_full/uageofullFEB'+UTC[i]+'.nc')\n",
    "    margradq = xr.open_dataarray('/g/data/k10/lr0203/Winds/uageo/March/uageo_full/uageofullMAR'+UTC[i]+'.nc')\n",
    "    for j in range(0,31): #month length\n",
    "        decdaily = decgradq[(j*31):(j*31)+31]\n",
    "        jandaily = jangradq[(j*31):(j*31)+31]\n",
    "        mardaily = margradq[(j*31):(j*31)+31]\n",
    "        febyearly = [febgradq[0:28],febgradq[28:56],febgradq[56:85],febgradq[85:113],febgradq[113:141],febgradq[141:169],febgradq[169:198],\n",
    "                    febgradq[198:226],febgradq[226:254],febgradq[254:282],febgradq[282:311],febgradq[311:339],febgradq[339:367],febgradq[367:395],\n",
    "                    febgradq[395:424],febgradq[424:452],febgradq[452:480],febgradq[480:508],febgradq[508:537],febgradq[537:565],febgradq[565:593],\n",
    "                    febgradq[593:621],febgradq[621:650],febgradq[650:678],febgradq[678:706],febgradq[706:734],febgradq[734:763],febgradq[763:791],\n",
    "                    febgradq[791:819],febgradq[819:847],febgradq[847:876]]\n",
    "        monsoon = xr.concat([decdaily,jandaily,febyearly[j],mardaily],dim='time')\n",
    "        if j == 0:\n",
    "            monsoon_yearly = monsoon\n",
    "        else:\n",
    "            monsoon_yearly = xr.concat([monsoon_yearly,monsoon],dim='time')\n",
    "    xr.DataArray(monsoon_yearly).to_netcdf(path='/g/data/k10/lr0203/Monsoon/uageo_monsoonyearly'+UTC[i]+'.nc')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6757cc15-4bb1-48eb-a66e-c15e0e2da85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(15,16): #hour looop\n",
    "    decgradq = xr.open_dataarray('/g/data/k10/lr0203/Winds/vageo/December/vageo_full/vageofullDEC'+UTC[i]+'.nc')\n",
    "    jangradq = xr.open_dataarray('/g/data/k10/lr0203/Winds/vageo/January/vageo_full/vageofullJAN'+UTC[i]+'.nc')\n",
    "    febgradq = xr.open_dataarray('/g/data/k10/lr0203/Winds/vageo/February/vageo_full/vageofullFEB'+UTC[i]+'.nc')\n",
    "    margradq = xr.open_dataarray('/g/data/k10/lr0203/Winds/vageo/March/vageo_full/vageofullMAR'+UTC[i]+'.nc')\n",
    "    for j in range(0,31): #month length\n",
    "        decdaily = decgradq[(j*31):(j*31)+31]\n",
    "        jandaily = jangradq[(j*31):(j*31)+31]\n",
    "        mardaily = margradq[(j*31):(j*31)+31]\n",
    "        febyearly = [febgradq[0:28],febgradq[28:56],febgradq[56:85],febgradq[85:113],febgradq[113:141],febgradq[141:169],febgradq[169:198],\n",
    "                    febgradq[198:226],febgradq[226:254],febgradq[254:282],febgradq[282:311],febgradq[311:339],febgradq[339:367],febgradq[367:395],\n",
    "                    febgradq[395:424],febgradq[424:452],febgradq[452:480],febgradq[480:508],febgradq[508:537],febgradq[537:565],febgradq[565:593],\n",
    "                    febgradq[593:621],febgradq[621:650],febgradq[650:678],febgradq[678:706],febgradq[706:734],febgradq[734:763],febgradq[763:791],\n",
    "                    febgradq[791:819],febgradq[819:847],febgradq[847:876]]\n",
    "        monsoon = xr.concat([decdaily,jandaily,febyearly[j],mardaily],dim='time')\n",
    "        if j == 0:\n",
    "            monsoon_yearly = monsoon\n",
    "        else:\n",
    "            monsoon_yearly = xr.concat([monsoon_yearly,monsoon],dim='time')\n",
    "    xr.DataArray(monsoon_yearly).to_netcdf(path='/g/data/k10/lr0203/Monsoon/vageo_monsoonyearly'+UTC[i]+'.nc')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aeb509f-1033-403a-83ed-17b21ac41912",
   "metadata": {},
   "source": [
    "**Isolate monsoon burst dates and slice variables for only burst periods**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f19185-af58-42a6-b1ea-3fe6411a20cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "monsoon_burst=np.zeros(len(box_av_mtpr),dtype=bool)\n",
    "monsoon_day = xr.open_dataarray('/g/data/k10/lr0203/Monsoon/monsoon_day.nc')\n",
    "for m in range(len(box_av_mtpr)):\n",
    "    if monsoon_day[m]>120:\n",
    "        monsoon_burst[m]=False\n",
    "    else:\n",
    "        monsoon_burst[m]=(box_av_mtpr[m]>upper_quartile[int((monsoon_day[m]-1)/5)])\n",
    "monsoon_burst_dates=box_av_mtpr.time[monsoon_burst]\n",
    "print(monsoon_burst_dates)\n",
    "# xr.DataArray(monsoon_burst_dates).to_netcdf(path='/g/data/k10/lr0203/Monsoon/monsoon_burst_dates.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2503c840-75c9-448d-b506-1023089425f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = xr.open_dataarray('/g/data/k10/lr0203/Monsoon/monsoon_burst_dates.nc')\n",
    "test = xr.open_dataarray('/g/data/k10/lr0203/Monsoon/new_monsoon_yearly/new_monsoonyearly0000.nc')\n",
    "for i in range(0,936):\n",
    "    v = np.where(test.time == dates.time[i])\n",
    "    if i == 0:\n",
    "        burst = v[0]\n",
    "    else:\n",
    "        burst = np.concatenate([burst,v[0]],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3933d1-cce1-4273-b899-6463d4c26d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(15,16):\n",
    "    theta = xr.open_dataarray('/g/data/k10/lr0203/Monsoon/theta_monsoonyearly'+UTC[i]+'.nc')\n",
    "    uageo = xr.open_dataarray('/g/data/k10/lr0203/Monsoon/uageo_monsoonyearly'+UTC[i]+'.nc')\n",
    "    vageo = xr.open_dataarray('/g/data/k10/lr0203/Monsoon/vageo_monsoonyearly'+UTC[i]+'.nc')\n",
    "    Ep = xr.open_dataarray('/g/data/k10/lr0203/Monsoon/Eprime_monsoonyearly'+UTC[i]+'.nc')\n",
    "    Fn = xr.open_dataarray('/g/data/k10/lr0203/Monsoon/Fn_monsoonyearly'+UTC[i]+'.nc')\n",
    "    D = xr.open_dataarray('/g/data/k10/lr0203/Monsoon/D_monsoonyearly'+UTC[i]+'.nc')\n",
    "    q = xr.open_dataarray('/g/data/k10/lr0203/Monsoon/q_monsoonyearly'+UTC[i]+'.nc')\n",
    "    burst_theta = theta[burst]\n",
    "    burst_theta_mean = burst_theta.mean(dim='time')\n",
    "    xr.DataArray(burst_theta_mean).to_netcdf(path='/g/data/k10/lr0203/Monsoon/monsoon_burst/thetaburstdata'+UTC[i]+'.nc')\n",
    "    burst_uageo = uageo[burst]\n",
    "    burst_uageo_mean = burst_uageo.mean(dim='time')\n",
    "    xr.DataArray(burst_uageo_mean).to_netcdf(path='/g/data/k10/lr0203/Monsoon/monsoon_burst/uageoburstdata'+UTC[i]+'.nc')\n",
    "    burst_vageo = vageo[burst]\n",
    "    burst_vageo_mean = burst_vageo.mean(dim='time')\n",
    "    xr.DataArray(burst_vageo_mean).to_netcdf(path='/g/data/k10/lr0203/Monsoon/monsoon_burst/vageoburstdata'+UTC[i]+'.nc')\n",
    "    burst_Ep = Ep[burst]\n",
    "    burst_Ep_mean = burst_Ep.mean(dim='time')\n",
    "    xr.DataArray(burst_Ep_mean).to_netcdf(path='/g/data/k10/lr0203/Monsoon/monsoon_burst/Epburstdata'+UTC[i]+'.nc')\n",
    "    burst_Fn = Fn[burst]\n",
    "    burst_Fn_mean = burst_Fn.mean(dim='time')\n",
    "    xr.DataArray(burst_Fn_mean).to_netcdf(path='/g/data/k10/lr0203/Monsoon/monsoon_burst/Fnburstdata'+UTC[i]+'.nc')\n",
    "    burst_D = D[burst]\n",
    "    burst_D_mean = burst_D.mean(dim='time')\n",
    "    xr.DataArray(burst_D_mean).to_netcdf(path='/g/data/k10/lr0203/Monsoon/monsoon_burst/Dburstdata'+UTC[i]+'.nc')\n",
    "    burst_q = q[burst]\n",
    "    burst_q_mean = burst_q.mean(dim='time')\n",
    "    xr.DataArray(burst_q_mean).to_netcdf(path='/g/data/k10/lr0203/Monsoon/monsoon_burst/qburstdata'+UTC[i]+'.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4199e2c-aa20-4dd0-b424-1324d243ce7e",
   "metadata": {},
   "source": [
    "**Isolate monsoon break dates and slice variables for only break periods**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e697881-4508-4854-b98a-c2fc39f10fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "monsoon_day = xr.open_dataarray('/g/data/k10/lr0203/Monsoon/monsoon_day.nc')\n",
    "monsoon_break=np.zeros(len(box_av_mtpr),dtype=bool)\n",
    "for m in range(len(box_av_mtpr)):\n",
    "    if monsoon_day[m]>120:\n",
    "        monsoon_break[m]=False\n",
    "    else:\n",
    "        monsoon_break[m]=(box_av_mtpr[m]<lower_quartile[int((monsoon_day[m]-1)/5)])\n",
    "monsoon_break_dates=box_av_mtpr.time[monsoon_break]\n",
    "print(monsoon_break_dates)\n",
    "xr.DataArray(monsoon_break_dates).to_netcdf(path='/g/data/k10/lr0203/Monsoon/monsoon_break_dates.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b2bc7787-b457-4e06-8bcd-8cfb050d134a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = xr.open_dataarray('/g/data/k10/lr0203/Monsoon/monsoon_break_dates.nc')\n",
    "test = xr.open_dataarray('/g/data/k10/lr0203/Monsoon/new_monsoon_yearly/new_monsoonyearly0000.nc')\n",
    "for i in range(0,936):\n",
    "    v = np.where(test.time == dates.time[i])\n",
    "    if i == 0:\n",
    "        breaks = v[0]\n",
    "    else:\n",
    "        breaks = np.concatenate([breaks,v[0]],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "44a8bf3d-93df-438f-bf47-bea5d9dd74cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3,4):\n",
    "    test = xr.open_dataarray('/g/data/k10/lr0203/Monsoon/new_monsoon_yearly/new_monsoonyearly'+UTC[i]+'.nc')\n",
    "    break_time = test[breaks]\n",
    "    break_time_mean = break_time.mean(dim='time')\n",
    "    xr.DataArray(break_time_mean).to_netcdf(path='/g/data/k10/lr0203/Monsoon/monsoon_break/breakdata'+UTC[i]+'.nc')\n",
    "    theta = xr.open_dataarray('/g/data/k10/lr0203/Monsoon/theta_monsoonyearly'+UTC[i]+'.nc')\n",
    "    uageo = xr.open_dataarray('/g/data/k10/lr0203/Monsoon/uageo_monsoonyearly'+UTC[i]+'.nc')\n",
    "    vageo = xr.open_dataarray('/g/data/k10/lr0203/Monsoon/vageo_monsoonyearly'+UTC[i]+'.nc')\n",
    "    Ep = xr.open_dataarray('/g/data/k10/lr0203/Monsoon/Eprime_monsoonyearly'+UTC[i]+'.nc')\n",
    "    Fn = xr.open_dataarray('/g/data/k10/lr0203/Monsoon/Fn_monsoonyearly'+UTC[i]+'.nc')\n",
    "    D = xr.open_dataarray('/g/data/k10/lr0203/Monsoon/D_monsoonyearly'+UTC[i]+'.nc')\n",
    "    q = xr.open_dataarray('/g/data/k10/lr0203/Monsoon/q_monsoonyearly'+UTC[i]+'.nc')\n",
    "    break_theta = theta[breaks]\n",
    "    break_theta_mean = break_theta.mean(dim='time')\n",
    "    xr.DataArray(break_theta_mean).to_netcdf(path='/g/data/k10/lr0203/Monsoon/monsoon_break/thetabreakdata'+UTC[i]+'.nc')\n",
    "    break_uageo = uageo[breaks]\n",
    "    break_uageo_mean = break_uageo.mean(dim='time')\n",
    "    xr.DataArray(break_uageo_mean).to_netcdf(path='/g/data/k10/lr0203/Monsoon/monsoon_break/uageobreakdata'+UTC[i]+'.nc')\n",
    "    break_vageo = vageo[breaks]\n",
    "    break_vageo_mean = break_vageo.mean(dim='time')\n",
    "    xr.DataArray(break_vageo_mean).to_netcdf(path='/g/data/k10/lr0203/Monsoon/monsoon_break/vageobreakdata'+UTC[i]+'.nc')\n",
    "    break_Ep = Ep[breaks]\n",
    "    break_Ep_mean = break_Ep.mean(dim='time')\n",
    "    xr.DataArray(break_Ep_mean).to_netcdf(path='/g/data/k10/lr0203/Monsoon/monsoon_break/Epbreakdata'+UTC[i]+'.nc')\n",
    "    break_Fn = Fn[breaks]\n",
    "    break_Fn_mean = break_Fn.mean(dim='time')\n",
    "    xr.DataArray(break_Fn_mean).to_netcdf(path='/g/data/k10/lr0203/Monsoon/monsoon_break/Fnbreakdata'+UTC[i]+'.nc')\n",
    "    break_D = D[breaks]\n",
    "    break_D_mean = break_D.mean(dim='time')\n",
    "    xr.DataArray(break_D_mean).to_netcdf(path='/g/data/k10/lr0203/Monsoon/monsoon_break/Dbreakdata'+UTC[i]+'.nc')\n",
    "    break_q = q[breaks]\n",
    "    break_q_mean = break_q.mean(dim='time')\n",
    "    xr.DataArray(break_q_mean).to_netcdf(path='/g/data/k10/lr0203/Monsoon/monsoon_break/qbreakdata'+UTC[i]+'.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc42f5f-b437-4123-99a1-03e6fe995ec3",
   "metadata": {},
   "source": [
    "**Plot monsoon data for burst and break periods**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c9bf3f-fe0f-487b-a1d0-d05d58ffdb97",
   "metadata": {},
   "source": [
    "**Mean Monsoon specific humidity gradient, potential temperature and ageostrophic winds 4-panel**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "506d5a77-7d0d-465e-978d-d496784ba959",
   "metadata": {},
   "outputs": [],
   "source": [
    "#seasonal combine example\n",
    "gradq = [[] for x in range(4)]\n",
    "theta = [[] for x in range(4)]\n",
    "uageo = [[] for x in range(4)]\n",
    "vageo = [[] for x in range(4)]\n",
    "time4h = [\"1PM AEST Monsoon Burst\",\"1PM AEST Monsoon Break\",\"1AM AEST Monsoon Burst\",\"1AM AEST Monsoon Break\"]\n",
    "abc = [\"a)\",\"b)\",\"c)\",\"d)\"]\n",
    "fig, ax = plt.subplots(2,2,subplot_kw={'projection': ccrs.PlateCarree()},figsize=(15,10))\n",
    "\n",
    "gradq[0] = xr.open_dataarray('/g/data/k10/lr0203/Monsoon/monsoon_burst/burstdata'+UTC[3]+'.nc')\n",
    "gradq[1] = xr.open_dataarray('/g/data/k10/lr0203/Monsoon/monsoon_break/breakdata'+UTC[3]+'.nc')\n",
    "gradq[2] = xr.open_dataarray('/g/data/k10/lr0203/Monsoon/monsoon_burst/burstdata'+UTC[15]+'.nc')\n",
    "gradq[3] = xr.open_dataarray('/g/data/k10/lr0203/Monsoon/monsoon_break/breakdata'+UTC[15]+'.nc')\n",
    "\n",
    "theta[0] = xr.open_dataarray('/g/data/k10/lr0203/Monsoon/monsoon_burst/thetaburstdata'+UTC[3]+'.nc')\n",
    "theta[1] = xr.open_dataarray('/g/data/k10/lr0203/Monsoon/monsoon_break/thetabreakdata'+UTC[3]+'.nc')\n",
    "theta[2] = xr.open_dataarray('/g/data/k10/lr0203/Monsoon/monsoon_burst/thetaburstdata'+UTC[15]+'.nc')\n",
    "theta[3] = xr.open_dataarray('/g/data/k10/lr0203/Monsoon/monsoon_break/thetabreakdata'+UTC[15]+'.nc')\n",
    "\n",
    "uageo[0] = xr.open_dataarray('/g/data/k10/lr0203/Monsoon/monsoon_burst/uageoburstdata'+UTC[3]+'.nc')\n",
    "uageo[1] = xr.open_dataarray('/g/data/k10/lr0203/Monsoon/monsoon_break/uageobreakdata'+UTC[3]+'.nc')\n",
    "uageo[2] = xr.open_dataarray('/g/data/k10/lr0203/Monsoon/monsoon_burst/uageoburstdata'+UTC[15]+'.nc')\n",
    "uageo[3] = xr.open_dataarray('/g/data/k10/lr0203/Monsoon/monsoon_break/uageobreakdata'+UTC[15]+'.nc')\n",
    "\n",
    "vageo[0] = xr.open_dataarray('/g/data/k10/lr0203/Monsoon/monsoon_burst/vageoburstdata'+UTC[3]+'.nc')\n",
    "vageo[1] = xr.open_dataarray('/g/data/k10/lr0203/Monsoon/monsoon_break/vageobreakdata'+UTC[3]+'.nc')\n",
    "vageo[2] = xr.open_dataarray('/g/data/k10/lr0203/Monsoon/monsoon_burst/vageoburstdata'+UTC[15]+'.nc')\n",
    "vageo[3] = xr.open_dataarray('/g/data/k10/lr0203/Monsoon/monsoon_break/vageobreakdata'+UTC[15]+'.nc')\n",
    "\n",
    "for k in range(0,4):\n",
    "    if k == 0 or k == 2:\n",
    "        ax=ax.flatten()\n",
    "        ax[k].set_extent([110, 155, -30, -10], ccrs.PlateCarree())\n",
    "        lon_grid = np.arange(110,155,5)\n",
    "        lat_grid = np.arange(-30,-10,5)\n",
    "        gl = ax[k].gridlines(draw_labels=True,xlocs=lon_grid,ylocs=lat_grid,\n",
    "                  x_inline=False,y_inline=False,color='k',linestyle='--',linewidth=0.4)\n",
    "        gl.top_labels = False\n",
    "        gl.right_labels = False\n",
    "        lons, lats = np.meshgrid(qlon, qlat)\n",
    "        u=uageo[k]\n",
    "        v=vageo[k]\n",
    "        quiver_slices = (slice(None, None, 9), slice(None, None, 7))\n",
    "        grad = ax[k].contourf(lons, lats, gradq[k],levels=[1.25e-5,1.5e-5,1.75e-5,2e-5,2.5e-5,3e-5], cmap='Blues',extend='max')\n",
    "        Q1=ax[k].quiver(lons[quiver_slices],lats[quiver_slices],u[quiver_slices],v[quiver_slices],width=0.0025)\n",
    "        kw_clabels = {'fontsize': 11, 'inline': True, 'inline_spacing': 5, 'fmt': '%i',\n",
    "                          'rightside_up': True, 'use_clabeltext': True}\n",
    "        # mslp = ax[k].contour(qlon,qlat,theta[k], colors='black') #mslp contours\n",
    "        # ax[k].clabel(mslp, **kw_clabels)\n",
    "        ax[k].set_title(time4h[k])\n",
    "        ax[k].set_title(abc[k], loc='left')\n",
    "        ax[k].coastlines()\n",
    "    else:\n",
    "        ax=ax.flatten()\n",
    "        ax[k].set_extent([110, 155, -30, -10], ccrs.PlateCarree())\n",
    "        lon_grid = np.arange(110,155,5)\n",
    "        lat_grid = np.arange(-30,-10,5)\n",
    "        gl = ax[k].gridlines(draw_labels=True,xlocs=lon_grid,ylocs=lat_grid,\n",
    "                  x_inline=False,y_inline=False,color='k',linestyle='--',linewidth=0.4)\n",
    "        gl.top_labels = False\n",
    "        gl.right_labels = False\n",
    "        gl.left_labels = False\n",
    "        lons, lats = np.meshgrid(qlon, qlat)\n",
    "        u=uageo[k]\n",
    "        v=vageo[k]\n",
    "        quiver_slices = (slice(None, None, 9), slice(None, None, 7))\n",
    "        grad = ax[k].contourf(lons, lats, gradq[k],levels=[1.25e-5,1.5e-5,1.75e-5,2e-5,2.5e-5,3e-5], cmap='Blues',extend='max')\n",
    "        Q1=ax[k].quiver(lons[quiver_slices],lats[quiver_slices],u[quiver_slices],v[quiver_slices],width=0.0025)\n",
    "        kw_clabels = {'fontsize': 11, 'inline': True, 'inline_spacing': 5, 'fmt': '%i',\n",
    "                          'rightside_up': True, 'use_clabeltext': True}\n",
    "        # mslp = ax[k].contour(qlon,qlat,theta[k], colors='black') #mslp contours\n",
    "        # ax[k].clabel(mslp, **kw_clabels)\n",
    "        ax[k].set_title(time4h[k])\n",
    "        ax[k].set_title(abc[k], loc='left')\n",
    "        ax[k].coastlines()       \n",
    "ax[1].quiverkey(Q1, 0.81, 0.92, 3, r'$3 \\frac{m}{s}$', labelpos='E',\n",
    "                   coordinates='figure',angle = 180, labelsep=0.3)\n",
    "# Adjust the location of the subplots on the page to make room for the colorbar\n",
    "fig.subplots_adjust(bottom=0.3, top=0.9, left=0.1, right=0.9,\n",
    "                    wspace=0.02, hspace=0.3)\n",
    "# # Add a colorbar axis at the bottom of the graph\n",
    "cbar_ax = fig.add_axes([0.2, 0.2, 0.6, 0.02])\n",
    "\n",
    "# # Draw the colorbar\n",
    "cbar=fig.colorbar(grad,cax=cbar_ax,orientation='horizontal',label='Specific Humidity Gradient (g $Kg^{-1} m^{-1}$)')\n",
    "\n",
    "# # Add a big title at the top\n",
    "plt.suptitle('Mean |q|,  and Ageostrophic Winds for monsoon burst and break periods \\n 1990-2020 at 925hPa',fontsize='xx-large')\n",
    "# save_results_to = '/g/data/k10/lr0203/final-plt/'\n",
    "# plt.savefig(save_results_to+'monsoonbrustxbreak.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98438a20-9a9c-4a02-b6fd-9fb0a234c407",
   "metadata": {},
   "source": [
    "**Mean monsoon specific humidity frontogenesis, convergence, deformation and specific humidity 4-panel**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e448bd8-0166-450b-9ff6-03d58bccd676",
   "metadata": {},
   "outputs": [],
   "source": [
    "#seasonal combine example\n",
    "Fn = [[] for x in range(4)]\n",
    "Ep = [[] for x in range(4)]\n",
    "D = [[] for x in range(4)]\n",
    "q = [[] for x in range(4)]\n",
    "time4h = [\"1PM AEST Monsoon Burst\",\"1PM AEST Monsoon Break\",\"1AM AEST Monsoon Burst\",\"1AM AEST Monsoon Break\"]\n",
    "abc = [\"a)\",\"b)\",\"c)\",\"d)\"]\n",
    "fig, ax = plt.subplots(2,2,subplot_kw={'projection': ccrs.PlateCarree()},figsize=(15,10))\n",
    "\n",
    "Fn[0] = xr.open_dataarray('/g/data/k10/lr0203/Monsoon/monsoon_burst/Fnburstdata'+UTC[3]+'.nc')\n",
    "Fn[1] = xr.open_dataarray('/g/data/k10/lr0203/Monsoon/monsoon_break/Fnbreakdata'+UTC[3]+'.nc')\n",
    "Fn[2] = xr.open_dataarray('/g/data/k10/lr0203/Monsoon/monsoon_burst/Fnburstdata'+UTC[15]+'.nc')\n",
    "Fn[3] = xr.open_dataarray('/g/data/k10/lr0203/Monsoon/monsoon_break/Fnbreakdata'+UTC[15]+'.nc')\n",
    "\n",
    "Ep[0] = xr.open_dataarray('/g/data/k10/lr0203/Monsoon/monsoon_burst/Epburstdata'+UTC[3]+'.nc')\n",
    "Ep[1] = xr.open_dataarray('/g/data/k10/lr0203/Monsoon/monsoon_break/Epbreakdata'+UTC[3]+'.nc')\n",
    "Ep[2] = xr.open_dataarray('/g/data/k10/lr0203/Monsoon/monsoon_burst/Epburstdata'+UTC[15]+'.nc')\n",
    "Ep[3] = xr.open_dataarray('/g/data/k10/lr0203/Monsoon/monsoon_break/Epbreakdata'+UTC[15]+'.nc')\n",
    "\n",
    "D[0] = xr.open_dataarray('/g/data/k10/lr0203/Monsoon/monsoon_burst/Dburstdata'+UTC[3]+'.nc')\n",
    "D[1] = xr.open_dataarray('/g/data/k10/lr0203/Monsoon/monsoon_break/Dbreakdata'+UTC[3]+'.nc')\n",
    "D[2] = xr.open_dataarray('/g/data/k10/lr0203/Monsoon/monsoon_burst/Dburstdata'+UTC[15]+'.nc')\n",
    "D[3] = xr.open_dataarray('/g/data/k10/lr0203/Monsoon/monsoon_break/Dbreakdata'+UTC[15]+'.nc')\n",
    "\n",
    "q[0] = xr.open_dataarray('/g/data/k10/lr0203/Monsoon/monsoon_burst/qburstdata'+UTC[3]+'.nc')\n",
    "q[1] = xr.open_dataarray('/g/data/k10/lr0203/Monsoon/monsoon_break/qbreakdata'+UTC[3]+'.nc')\n",
    "q[2] = xr.open_dataarray('/g/data/k10/lr0203/Monsoon/monsoon_burst/qburstdata'+UTC[15]+'.nc')\n",
    "q[3] = xr.open_dataarray('/g/data/k10/lr0203/Monsoon/monsoon_break/qbreakdata'+UTC[15]+'.nc')\n",
    "for k in range(0,4):\n",
    "    if k == 0 or k == 2:\n",
    "        ax=ax.flatten()\n",
    "        ax[k].set_extent([110, 155, -30, -10], ccrs.PlateCarree())\n",
    "        lon_grid = np.arange(110,155,5)\n",
    "        lat_grid = np.arange(-30,-10,5)\n",
    "        gl = ax[k].gridlines(draw_labels=True,xlocs=lon_grid,ylocs=lat_grid,\n",
    "                  x_inline=False,y_inline=False,color='k',linestyle='--',linewidth=0.4)\n",
    "        gl.top_labels = False\n",
    "        gl.right_labels = False\n",
    "        lons, lats = np.meshgrid(qlon, qlat)\n",
    "        grad = ax[k].contourf(lons, lats, Fn[k], levels=[-9e-10,-7.5e-10,-6e-10,-4.5e-10,-3e-10,-1.5e-10,0],transform=ccrs.PlateCarree(), \n",
    "                                colors=['saddlebrown','sienna','chocolate','darkorange','orange','navajowhite','white'],extend='min')\n",
    "        kw_clabels = {'fontsize': 11, 'inline': True, 'inline_spacing': 5, 'fmt': '%i',\n",
    "                          'rightside_up': True, 'use_clabeltext': True}\n",
    "        ep = ax[k].contour(lons,lats,Ep[k], levels=[0.00005],colors='blue') #mslp contours\n",
    "        conv = ax[k].contour(lons,lats,D[k],levels=[-0.00001], linestyles='solid',colors='green') #mslp contour\n",
    "        mslp = ax[k].contour(lons,lats,q[k], colors='black') #mslp contours\n",
    "        ax[k].clabel(mslp, **kw_clabels)\n",
    "        \n",
    "        ax[k].set_title(time4h[k])\n",
    "        ax[k].set_title(abc[k], loc='left')\n",
    "        ax[k].coastlines()\n",
    "    else:\n",
    "        ax=ax.flatten()\n",
    "        ax[k].set_extent([110, 155, -30, -10], ccrs.PlateCarree())\n",
    "        lon_grid = np.arange(110,155,5)\n",
    "        lat_grid = np.arange(-30,-10,5)\n",
    "        gl = ax[k].gridlines(draw_labels=True,xlocs=lon_grid,ylocs=lat_grid,\n",
    "                  x_inline=False,y_inline=False,color='k',linestyle='--',linewidth=0.4)\n",
    "        gl.top_labels = False\n",
    "        gl.right_labels = False\n",
    "        gl.left_labels = False\n",
    "        lons, lats = np.meshgrid(qlon, qlat)\n",
    "        grad = ax[k].contourf(lons, lats, Fn[k], levels=[-9e-10,-7.5e-10,-6e-10,-4.5e-10,-3e-10,-1.5e-10,0],transform=ccrs.PlateCarree(), \n",
    "                                colors=['saddlebrown','sienna','chocolate','darkorange','orange','navajowhite','white'],extend='min')\n",
    "        kw_clabels = {'fontsize': 11, 'inline': True, 'inline_spacing': 5, 'fmt': '%i',\n",
    "                          'rightside_up': True, 'use_clabeltext': True}\n",
    "        ep = ax[k].contour(lons,lats,Ep[k], levels=[0.00005],colors='blue') #mslp contours\n",
    "        conv = ax[k].contour(lons,lats,D[k],levels=[-0.00001], linestyles='solid',colors='green') #mslp contour\n",
    "        mslp = ax[k].contour(lons,lats,q[k], colors='black') #mslp contours\n",
    "        ax[k].clabel(mslp, **kw_clabels)\n",
    "        ax[k].set_title(time4h[k])\n",
    "        ax[k].set_title(abc[k], loc='left')\n",
    "        ax[k].coastlines()       \n",
    "\n",
    "# Adjust the location of the subplots on the page to make room for the colorbar\n",
    "fig.subplots_adjust(bottom=0.3, top=0.9, left=0.1, right=0.9,\n",
    "                    wspace=0.02, hspace=0.3)\n",
    "# # Add a colorbar axis at the bottom of the graph\n",
    "cbar_ax = fig.add_axes([0.2, 0.2, 0.6, 0.02])\n",
    "\n",
    "# # Draw the colorbar\n",
    "cbar=fig.colorbar(grad,cax=cbar_ax,orientation='horizontal',label='Specific Humidity Gradient (g $Kg^{-1} m^{-1}$)')\n",
    "\n",
    "# # Add a big title at the top\n",
    "plt.suptitle('Mean Fn, Deformation, Convergence and q for monsoon burst and break periods \\n 1990-2020 at 925hPa',fontsize='xx-large')\n",
    "save_results_to = '/g/data/k10/lr0203/final-plt/'\n",
    "plt.savefig(save_results_to+'Fn_monsoon.jpg')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
